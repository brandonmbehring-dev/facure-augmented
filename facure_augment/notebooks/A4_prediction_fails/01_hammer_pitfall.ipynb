{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Prediction Fails: The Hammer Pitfall\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition)\n",
    "2. [Formal Treatment](#formal)\n",
    "3. [Numeric Demonstration](#numeric)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Interview Appendix](#interview)\n",
    "6. [References](#references)\n",
    "\n",
    "---\n",
    "\n",
    "**Appendix A4 | Notebook 1 of 3**\n",
    "\n",
    "This notebook explores why predictive ML fails for causal optimization problems,\n",
    "using coupon value optimization as the key example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent to path for imports\n",
    "module_path = str(Path.cwd().parent.parent)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "\n",
    "from facure_augment.common import *\n",
    "set_notebook_style()\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Intuition {#intuition}\n",
    "\n",
    "### When All You Have is a Hammer...\n",
    "\n",
    "The ML revolution made predictive modeling accessible:\n",
    "\n",
    "```python\n",
    "model = MachineLearningModel()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "**The Problem**: When everything looks like a prediction problem, causal questions get misframed.\n",
    "\n",
    "### Two Fundamentally Different Questions\n",
    "\n",
    "| Question Type | Prediction | Causal Optimization |\n",
    "|--------------|------------|---------------------|\n",
    "| Goal | Estimate $E[Y|X]$ | Maximize $Y$ by changing $T$ |\n",
    "| Example | \"What will sales be?\" | \"How should I set price to maximize profit?\" |\n",
    "| ML helps? | Yes | **Often hurts** |\n",
    "\n",
    "### The Coupon Problem\n",
    "\n",
    "**Scenario**: Streaming company wants to optimize coupon values (0, 5, 10, 15 BRL).\n",
    "\n",
    "**Naive approach**: Build ML model to predict customer value, then personalize coupons by predicted band.\n",
    "\n",
    "**The twist**: This approach performs *worse* than giving everyone the same coupon!\n",
    "\n",
    "> **Key insight**: Predicting $Y$ is not the same as estimating $\\frac{\\partial Y}{\\partial T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment {#formal}\n",
    "\n",
    "### 2.1 The Optimization Problem\n",
    "\n",
    "We want to find $T^*$ that maximizes expected outcome:\n",
    "\n",
    "$$T^* = \\arg\\max_T E[Y|T]$$\n",
    "\n",
    "For personalization, we want:\n",
    "\n",
    "$$T^*(x) = \\arg\\max_T E[Y|T, X=x]$$\n",
    "\n",
    "### 2.2 Why Prediction Doesn't Help\n",
    "\n",
    "**Prediction estimates**: $\\hat{Y} = f(X, T)$\n",
    "\n",
    "**Optimization needs**: $\\frac{\\partial Y}{\\partial T} = g(X, T)$\n",
    "\n",
    "**The problem**: Good prediction of $Y$ doesn't imply good estimation of $\\frac{\\partial Y}{\\partial T}$.\n",
    "\n",
    "### 2.3 Prediction Partitions Flatten Elasticities\n",
    "\n",
    "When we partition by predicted $\\hat{Y}$:\n",
    "\n",
    "1. Within each partition, $\\hat{Y}$ is approximately constant\n",
    "2. If $\\hat{Y} \\approx Y$, then $Y$ varies little within partition\n",
    "3. With little $Y$ variation, we can't estimate $\\frac{\\partial Y}{\\partial T}$\n",
    "\n",
    "**Result**: The response curve **flattens** within each prediction band.\n",
    "\n",
    "### 2.4 Personalization Requirements\n",
    "\n",
    "Personalization is beneficial **only when**:\n",
    "1. Multiple treatment options exist ($T \\in \\{0, 5, 10, 15\\}$)\n",
    "2. No single treatment is universally optimal\n",
    "3. Different subgroups have different optimal treatments\n",
    "\n",
    "**Key**: We need to identify subgroups by their *treatment response*, not their *predicted outcome*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration {#numeric}\n",
    "\n",
    "### Data Generating Process\n",
    "\n",
    "We simulate a coupon experiment with controlled DGP so we can observe counterfactuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltv_with_coupons(coupons=None, seed=12):\n",
    "    \"\"\"Generate customer lifetime value data with coupon treatment effects.\n",
    "    \n",
    "    This DGP has nonlinear treatment effects: coupons interact with age\n",
    "    and income to affect purchase frequency and transaction values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coupons : array-like, optional\n",
    "        Coupon values for each customer. If None, generates based on age.\n",
    "    seed : int\n",
    "        Random seed for reproducibility.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    transactions : pd.DataFrame\n",
    "        Daily transaction values with customer acquisition cost.\n",
    "    customer_features : pd.DataFrame\n",
    "        Customer attributes including assigned coupon values.\n",
    "    \"\"\"\n",
    "    n = 10000\n",
    "    t = 30  # days\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Customer features\n",
    "    age = 18 + np.random.poisson(10, n)\n",
    "    income = 500 + np.random.exponential(2000, size=n).astype(int)\n",
    "    region = np.random.choice(np.random.lognormal(4, size=50), size=n)\n",
    "    \n",
    "    # Default coupons: correlated with age (confounding)\n",
    "    if coupons is None:\n",
    "        coupons = np.clip(np.random.normal((age - 18), 0.01, size=n) // 5 * 5, 0, 15)\n",
    "    \n",
    "    assert len(coupons) == n\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Treatment effect on purchase frequency\n",
    "    freq_mu = 0.5 * coupons * age + age\n",
    "    freq_mu = (freq_mu - 150) / 30 + 2\n",
    "    freq = np.random.lognormal(freq_mu.astype(int))\n",
    "    \n",
    "    # Churn timing (income-dependent)\n",
    "    churn = np.random.poisson((income - 500) / 2000 + 22, n)\n",
    "    \n",
    "    # Alive indicator per day\n",
    "    ones = np.ones((n, t))\n",
    "    alive = (np.cumsum(ones, axis=1) <= churn.reshape(n, 1)).astype(int)\n",
    "    buy = np.random.binomial(1, ((1 / (freq + 1)).reshape(n, 1) * ones))\n",
    "    \n",
    "    # Customer acquisition cost (region-dependent)\n",
    "    cacq = -1 * abs(np.random.normal(region, 2, size=n).astype(int))\n",
    "    \n",
    "    # Treatment effect on transaction values\n",
    "    transaction_mu = 0.1 + (((income - 500) / 900) * (coupons / 8)) + coupons / 9\n",
    "    transaction_mu = np.clip(transaction_mu, 0, 5)\n",
    "    transaction_mu = np.tile(transaction_mu.reshape(-1, 1), t)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    transactions = np.random.lognormal(transaction_mu, size=(n, t)).astype(int) * buy * alive\n",
    "    \n",
    "    # Build DataFrames\n",
    "    trans_dict = {\"customer_id\": range(n), \"cacq\": cacq}\n",
    "    for day in range(t):\n",
    "        trans_dict[f\"day_{day}\"] = transactions[:, day]\n",
    "    data = pd.DataFrame(trans_dict)\n",
    "    \n",
    "    # Encode regions\n",
    "    encoded = {value: index for index, value in\n",
    "               enumerate(np.random.permutation(np.unique(region)))}\n",
    "    \n",
    "    customer_features = pd.DataFrame({\n",
    "        'customer_id': range(n),\n",
    "        'region': region,\n",
    "        'income': income,\n",
    "        'coupons': coupons,\n",
    "        'age': age\n",
    "    }).replace({'region': encoded}).astype(int)\n",
    "    \n",
    "    return data, customer_features\n",
    "\n",
    "\n",
    "def process_data(transactions, customer_data):\n",
    "    \"\"\"Compute net value per customer including coupon cost.\"\"\"\n",
    "    profitable = (transactions[['customer_id']]\n",
    "                  .assign(net_value=transactions.drop(columns='customer_id').sum(axis=1)))\n",
    "    \n",
    "    return (customer_data\n",
    "            .merge(profitable, on='customer_id')\n",
    "            .assign(net_value=lambda d: d['net_value'] - d['coupons']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate baseline data\n",
    "transactions, customer_features = ltv_with_coupons()\n",
    "customer_features = process_data(transactions, customer_features)\n",
    "\n",
    "print(f\"Customers: {len(customer_features):,}\")\n",
    "print(f\"Features: {customer_features.columns.tolist()}\")\n",
    "customer_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupon Distribution (Non-Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check coupon distribution\n",
    "coupon_dist = customer_features.groupby('coupons')['customer_id'].count()\n",
    "print(\"Coupon Value Distribution:\")\n",
    "print(coupon_dist)\n",
    "\n",
    "# Check correlation with age (confounding)\n",
    "print(f\"\\nCorrelation with age: {customer_features['coupons'].corr(customer_features['age']):.3f}\")\n",
    "print(\"(Higher coupons given to older customers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Policy: Give Everyone 5 BRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net value by coupon value in observed data\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "coupon_means = customer_features.groupby('coupons')['net_value'].mean()\n",
    "colors = [COLORS['green'] if v > 0 else COLORS['red'] for v in coupon_means.values]\n",
    "bars = ax.bar(coupon_means.index.astype(str), coupon_means.values, color=colors, alpha=0.7)\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "ax.set_xlabel('Coupon Value (BRL)')\n",
    "ax.set_ylabel('Average Net Value')\n",
    "ax.set_title('Net Value by Coupon Value (Observed Data)')\n",
    "\n",
    "# Annotate values\n",
    "for bar, val in zip(bars, coupon_means.values):\n",
    "    ax.annotate(f'{val:.0f}', (bar.get_x() + bar.get_width()/2, val),\n",
    "                ha='center', va='bottom' if val > 0 else 'top')\n",
    "\n",
    "apply_tufte_style(ax)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best observed coupon value: {coupon_means.idxmax()} BRL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate simple policy: give everyone 5 BRL coupons\n",
    "simple_policy = 5 * np.ones(len(customer_features))\n",
    "\n",
    "trans_simple, feat_simple = ltv_with_coupons(simple_policy)\n",
    "feat_simple = process_data(trans_simple, feat_simple)\n",
    "\n",
    "simple_policy_gain = feat_simple['net_value'].mean()\n",
    "\n",
    "print(f\"Simple Policy (5 BRL for all):\")\n",
    "print(f\"  Average net value: {simple_policy_gain:.2f} BRL/customer\")\n",
    "print(f\"  Total value: {simple_policy_gain * len(feat_simple):,.0f} BRL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Based Policy: Personalization Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_bands(train_set, features, target, model_params, n_bands, seed=1):\n",
    "    \"\"\"Train predictive model and create band assignment function.\n",
    "    \n",
    "    Returns a function that predicts net_value and assigns to bands.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Train ML model\n",
    "    reg = GradientBoostingRegressor(**model_params)\n",
    "    reg.fit(train_set[features], train_set[target])\n",
    "    \n",
    "    # Fit bands (quantiles of predictions)\n",
    "    bands = pd.qcut(reg.predict(train_set[features]), q=n_bands, retbins=True)[1]\n",
    "    \n",
    "    def predict(test_set):\n",
    "        predictions = reg.predict(test_set[features])\n",
    "        pred_bands = np.digitize(predictions, bands, right=False)\n",
    "        return test_set.assign(\n",
    "            predictions=predictions,\n",
    "            pred_bands=np.clip(pred_bands, 1, n_bands)\n",
    "        )\n",
    "    \n",
    "    return predict\n",
    "\n",
    "\n",
    "# Train predictive model\n",
    "train, test = train_test_split(customer_features, test_size=0.3, random_state=1)\n",
    "\n",
    "model_params = {\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_split': 10,\n",
    "    'learning_rate': 0.01,\n",
    "    'loss': 'squared_error'\n",
    "}\n",
    "\n",
    "features = ['region', 'income', 'age']\n",
    "target = 'net_value'\n",
    "\n",
    "model = model_bands(train, features, target, model_params, n_bands=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictive performance\n",
    "train_preds = model(train)\n",
    "test_preds = model(test)\n",
    "\n",
    "train_r2 = r2_score(train['net_value'], train_preds['predictions'])\n",
    "test_r2 = r2_score(test['net_value'], test_preds['predictions'])\n",
    "\n",
    "print(f\"Predictive Performance:\")\n",
    "print(f\"  Train R²: {train_r2:.3f}\")\n",
    "print(f\"  Test R²:  {test_r2:.3f}\")\n",
    "print(f\"\\nThe model is reasonably good at predicting net_value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize net_value by band and coupon value\n",
    "all_with_bands = model(customer_features)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Compute means by band and coupon\n",
    "band_coupon_means = all_with_bands.groupby(['pred_bands', 'coupons'])['net_value'].mean().unstack()\n",
    "\n",
    "x = np.arange(len(band_coupon_means))\n",
    "width = 0.2\n",
    "\n",
    "coupon_colors = {0: COLORS['red'], 5: COLORS['blue'], 10: COLORS['green'], 15: COLORS['orange']}\n",
    "\n",
    "for i, coupon in enumerate([0, 5, 10, 15]):\n",
    "    if coupon in band_coupon_means.columns:\n",
    "        ax.bar(x + i*width, band_coupon_means[coupon], width, \n",
    "               label=f'{coupon} BRL', color=coupon_colors[coupon], alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Prediction Band')\n",
    "ax.set_ylabel('Average Net Value')\n",
    "ax.set_title('Net Value by Prediction Band and Coupon Value\\n(Optimal coupon varies by band)')\n",
    "ax.set_xticks(x + 1.5*width)\n",
    "ax.set_xticklabels(band_coupon_means.index)\n",
    "ax.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "ax.legend(title='Coupon Value')\n",
    "apply_tufte_style(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build personalized policy based on model bands\n",
    "pred_bands = (model(customer_features)\n",
    "              .groupby(['pred_bands', 'coupons'])[['net_value']].mean()\n",
    "              .reset_index())\n",
    "\n",
    "# Find best coupon per band (rank by net_value)\n",
    "pred_bands['max_net'] = (pred_bands.groupby('pred_bands')[['net_value']]\n",
    "                         .rank(ascending=False))\n",
    "\n",
    "best_coupons_per_band = pred_bands.query('max_net==1')[['pred_bands', 'coupons']]\n",
    "\n",
    "print(\"Optimal Coupon by Prediction Band:\")\n",
    "print(best_coupons_per_band.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply personalized policy\n",
    "coupons_per_id = (model(customer_features)\n",
    "                  .drop(columns=['coupons'])\n",
    "                  .merge(best_coupons_per_band, on='pred_bands')\n",
    "                  [['customer_id', 'coupons']]\n",
    "                  .sort_values('customer_id'))\n",
    "\n",
    "# Evaluate personalized policy\n",
    "trans_model, feat_model = ltv_with_coupons(\n",
    "    coupons_per_id['coupons'].values\n",
    ")\n",
    "feat_model = process_data(trans_model, feat_model)\n",
    "\n",
    "model_policy_gain = feat_model['net_value'].mean()\n",
    "\n",
    "print(f\"\\nModel-Based Personalized Policy:\")\n",
    "print(f\"  Average net value: {model_policy_gain:.2f} BRL/customer\")\n",
    "print(f\"  Total value: {model_policy_gain * len(feat_model):,.0f} BRL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Shocking Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare policies\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution comparison\n",
    "ax = axes[0]\n",
    "ax.hist(feat_model['net_value'], bins=50, alpha=0.6, label='Model Policy', color=COLORS['red'])\n",
    "ax.hist(feat_simple['net_value'], bins=50, alpha=0.6, label='Simple Policy', color=COLORS['green'])\n",
    "ax.axvline(model_policy_gain, color=COLORS['red'], linestyle='--', linewidth=2)\n",
    "ax.axvline(simple_policy_gain, color=COLORS['green'], linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Net Value')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Customer Net Value by Policy')\n",
    "ax.legend()\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "# Bar comparison\n",
    "ax = axes[1]\n",
    "policies = ['Simple\\n(5 BRL for all)', 'Model-Based\\n(Personalized)']\n",
    "gains = [simple_policy_gain, model_policy_gain]\n",
    "colors = [COLORS['green'], COLORS['red']]\n",
    "bars = ax.bar(policies, gains, color=colors, alpha=0.7)\n",
    "\n",
    "for bar, gain in zip(bars, gains):\n",
    "    ax.annotate(f'{gain:.1f}', (bar.get_x() + bar.get_width()/2, gain),\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Average Net Value (BRL/customer)')\n",
    "ax.set_title('Policy Comparison: Simple WINS!')\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"RESULT: Model-based policy is WORSE by {simple_policy_gain - model_policy_gain:.2f} BRL/customer!\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "★ Insight ─────────────────────────────────────────────────────\n",
    "The ML model has good predictive power (R² ≈ 0.50), yet the\n",
    "personalized policy UNDERPERFORMS a trivial \"same for everyone\" policy.\n",
    "\n",
    "This is not a bug—it's a fundamental mismatch:\n",
    "- ML predicts Y (outcome level)\n",
    "- Optimization needs ∂Y/∂T (treatment effect)\n",
    "\n",
    "Good prediction ≠ Good optimization guidance.\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation {#implementation}\n",
    "\n",
    "### Why This Happens: The Core Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the flattening effect\n",
    "# Within each band, compute the \"elasticity\" of net_value to coupons\n",
    "\n",
    "def compute_band_elasticities(df, band_col='pred_bands'):\n",
    "    \"\"\"Compute approximate treatment effect within each band.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for band in sorted(df[band_col].unique()):\n",
    "        band_data = df[df[band_col] == band]\n",
    "        \n",
    "        # Simple elasticity: change in net_value per unit coupon\n",
    "        if len(band_data['coupons'].unique()) > 1:\n",
    "            # Regression of net_value on coupons within band\n",
    "            if band_data['coupons'].std() > 0:\n",
    "                slope = np.cov(band_data['coupons'], band_data['net_value'])[0,1] / np.var(band_data['coupons'])\n",
    "                y_variance = band_data['net_value'].std()\n",
    "            else:\n",
    "                slope = 0\n",
    "                y_variance = 0\n",
    "        else:\n",
    "            slope = 0\n",
    "            y_variance = 0\n",
    "            \n",
    "        results.append({\n",
    "            'band': band,\n",
    "            'elasticity': slope,\n",
    "            'y_variance': y_variance,\n",
    "            'n': len(band_data)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Compare elasticities: overall vs within bands\n",
    "overall_elasticity = (np.cov(customer_features['coupons'], customer_features['net_value'])[0,1] / \n",
    "                      np.var(customer_features['coupons']))\n",
    "\n",
    "band_elasticities = compute_band_elasticities(all_with_bands)\n",
    "\n",
    "print(f\"Overall elasticity (∂Y/∂T): {overall_elasticity:.3f}\")\n",
    "print(f\"\\nWithin-band elasticities:\")\n",
    "print(band_elasticities[['band', 'elasticity', 'y_variance']].to_string(index=False))\n",
    "print(f\"\\nAverage within-band elasticity: {band_elasticities['elasticity'].mean():.3f}\")\n",
    "print(f\"\\nThe elasticities are FLATTENED within bands!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the flattening\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall response curve\n",
    "ax = axes[0]\n",
    "coupon_response = customer_features.groupby('coupons')['net_value'].agg(['mean', 'std'])\n",
    "ax.errorbar(coupon_response.index, coupon_response['mean'], \n",
    "            yerr=coupon_response['std']/10, fmt='o-', color=COLORS['blue'],\n",
    "            capsize=5, markersize=10, linewidth=2)\n",
    "ax.set_xlabel('Coupon Value (BRL)')\n",
    "ax.set_ylabel('Mean Net Value')\n",
    "ax.set_title('Overall Response Curve\\n(Clear curvature exists)')\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "# Within-band response curves (sample bands)\n",
    "ax = axes[1]\n",
    "sample_bands = [2, 5, 8]\n",
    "for band in sample_bands:\n",
    "    band_data = all_with_bands[all_with_bands['pred_bands'] == band]\n",
    "    band_response = band_data.groupby('coupons')['net_value'].mean()\n",
    "    ax.plot(band_response.index, band_response.values, 'o-', \n",
    "            label=f'Band {band}', markersize=8, linewidth=2, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Coupon Value (BRL)')\n",
    "ax.set_ylabel('Mean Net Value')\n",
    "ax.set_title('Within-Band Response Curves\\n(Flattened - less variation)')\n",
    "ax.legend()\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Key Equation\n",
    "\n",
    "**What we want**: Estimate $\\frac{\\partial Y}{\\partial T}$ to find optimal $T$\n",
    "\n",
    "**What prediction gives us**: Partitions where $Y$ is constant\n",
    "\n",
    "**The consequence**: When $Y$ doesn't vary, $\\frac{\\partial Y}{\\partial T} \\approx 0$\n",
    "\n",
    "$$\\text{Good } \\hat{Y} \\Rightarrow \\text{Low Var}(Y|\\text{band}) \\Rightarrow \\text{Flat } \\frac{\\partial Y}{\\partial T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary = pd.DataFrame({\n",
    "    'Approach': ['Simple Policy', 'Model-Based Policy'],\n",
    "    'Description': ['5 BRL for everyone', 'Personalize by predicted band'],\n",
    "    'Net Value/Customer': [simple_policy_gain, model_policy_gain],\n",
    "    'Relative Performance': ['Baseline', f'{(model_policy_gain/simple_policy_gain - 1)*100:.1f}%']\n",
    "})\n",
    "\n",
    "print(\"Policy Comparison Summary:\")\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix {#interview}\n",
    "\n",
    "### Q1: Why can't ML prediction be used to optimize business decisions?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Key distinction**:\n",
    "\n",
    "| Question | Prediction | Optimization |\n",
    "|----------|------------|-------------|\n",
    "| Goal | $E[Y|X]$ | $\\arg\\max_T E[Y|T]$ |\n",
    "| Requires | Correlation | Causal effect |\n",
    "| ML optimizes | Forecast accuracy | Wrong objective |\n",
    "\n",
    "**Why prediction fails**:\n",
    "1. Good prediction → partitions where Y is constant\n",
    "2. Constant Y → no variance to estimate treatment effects\n",
    "3. No treatment effect → can't identify optimal treatment\n",
    "\n",
    "**Correct approach**: Estimate treatment effects $\\frac{\\partial Y}{\\partial T}$ directly using causal inference methods (A/B tests, instrumental variables, difference-in-differences).\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q2: A data scientist proposes predicting customer LTV and giving larger discounts to predicted high-value customers. What's wrong with this approach?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**The flaw**: Predicted high-value customers are high-value *regardless* of discounts.\n",
    "\n",
    "**What we want**: Identify customers whose value *increases most* with discounts (high elasticity).\n",
    "\n",
    "**The disconnect**:\n",
    "- High predicted LTV ≠ High response to treatment\n",
    "- May be giving discounts to customers who would buy anyway\n",
    "- Missing customers with low baseline but high treatment sensitivity\n",
    "\n",
    "**Better approach**: Estimate CATE (Conditional Average Treatment Effect):\n",
    "$$\\tau(x) = E[Y_1 - Y_0 | X = x]$$\n",
    "\n",
    "Target customers with high $\\tau(x)$, not high $\\hat{Y}(x)$.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q3: When might a predictive model actually help with a causal optimization problem?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "Prediction can help when:\n",
    "\n",
    "1. **Treatment is random** (no confounding)\n",
    "   - Conditioning on prediction doesn't block treatment path\n",
    "   - Can still estimate within-partition treatment effects\n",
    "\n",
    "2. **Monotonic relationship** between $Y$ and $\\frac{\\partial Y}{\\partial T}$\n",
    "   - Example: Customers with low baseline satisfaction have high sensitivity to service improvements\n",
    "   - Partitioning by predicted Y also partitions by elasticity\n",
    "\n",
    "3. **Variance reduction** (not personalization)\n",
    "   - Good predictions reduce outcome variance\n",
    "   - More precise ATE estimates (not CATE)\n",
    "\n",
    "**Key caveat**: Even when helpful, prediction is not optimal. Purpose-built causal models (T-learner, X-learner, R-learner) will outperform.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q4: Explain the \"flattening\" phenomenon in one sentence.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "\"When you group data by predicted outcome, within-group outcome variation shrinks, and with it your ability to estimate how treatments affect outcomes.\"\n",
    "\n",
    "Mathematical form:\n",
    "$$\\hat{Y} \\approx Y \\Rightarrow \\text{Var}(Y|\\text{partition}) \\to 0 \\Rightarrow \\frac{\\partial Y}{\\partial T} \\approx 0$$\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q5: How would you properly solve the coupon optimization problem?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Step 1**: Frame as causal question\n",
    "- Treatment: Coupon value $T \\in \\{0, 5, 10, 15\\}$\n",
    "- Outcome: Net customer value $Y$\n",
    "- Goal: Estimate $E[Y|do(T=t)]$ for each $t$\n",
    "\n",
    "**Step 2**: Choose identification strategy\n",
    "- Randomized experiment (gold standard)\n",
    "- Or: Use existing data with causal methods (if confounders observed)\n",
    "\n",
    "**Step 3**: Estimate heterogeneous effects\n",
    "- Use CATE estimators: T-learner, X-learner, Causal Forest\n",
    "- Target: $\\tau(x) = E[Y(t_1) - Y(t_0) | X=x]$\n",
    "\n",
    "**Step 4**: Personalize based on estimated effects\n",
    "- Assign treatment with highest expected value\n",
    "- $T^*(x) = \\arg\\max_t \\hat{E}[Y|do(T=t), X=x]$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References {#references}\n",
    "\n",
    "[^1]: Athey, S., & Imbens, G. (2016). Recursive partitioning for heterogeneous causal effects. \n",
    "      *PNAS*, 113(27), 7353-7360.\n",
    "\n",
    "[^2]: Chernozhukov, V., et al. (2018). Double/Debiased Machine Learning for Treatment and \n",
    "      Structural Parameters. *Econometrics Journal*, 21, C1-C68.\n",
    "\n",
    "[^3]: Facure, M. (2022). *Causal Inference for the Brave and True*, Appendix: When Prediction Fails.\n",
    "\n",
    "[^4]: Mullainathan, S., & Spiess, J. (2017). Machine Learning: An Applied Econometric Approach.\n",
    "      *Journal of Economic Perspectives*, 31(2), 87-106."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
