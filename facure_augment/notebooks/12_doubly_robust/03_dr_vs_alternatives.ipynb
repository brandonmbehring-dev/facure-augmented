{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# DR vs Alternative Methods\n",
    "\n",
    "**Chapter 12, Section 3**\n",
    "\n",
    "This notebook compares doubly robust estimation with other approaches and provides practical guidance.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition) - Method comparison overview\n",
    "2. [Formal Treatment](#formal) - AIPW connection\n",
    "3. [Numeric Demonstration](#numeric) - Head-to-head comparison\n",
    "4. [Implementation](#implementation) - When to use what\n",
    "5. [Interview Appendix](#interview) - Practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from facure_augment.common import *\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Set notebook style\n",
    "set_notebook_style()\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "### Method Landscape\n",
    "\n",
    "| Method | Models Needed | Robustness | Efficiency | Transparency |\n",
    "|--------|---------------|------------|------------|-------------|\n",
    "| Outcome Regression | Outcome only | Single model | High (if correct) | Medium |\n",
    "| IPTW | PS only | Single model | Variable | High |\n",
    "| PS Matching | PS only | Single model | Lower | High |\n",
    "| **Doubly Robust** | Both | Double | High | Lower |\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "- **Outcome Regression**: Simple relationships, good overlap\n",
    "- **IPTW**: Transparent weighting, moderate overlap\n",
    "- **PS Matching**: Maximum transparency, good overlap\n",
    "- **Doubly Robust**: Model uncertainty, need insurance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mindset data\n",
    "mindset = load_facure_data(\"learning_mindset.csv\")\n",
    "\n",
    "covariates = [\n",
    "    'success_expect', 'ethnicity', 'gender', 'frst_in_family',\n",
    "    'school_mindset', 'school_achievement', 'school_ethnic_minority',\n",
    "    'school_poverty', 'school_size'\n",
    "]\n",
    "\n",
    "X = mindset[covariates].values\n",
    "T = mindset['intervention'].values\n",
    "Y = mindset['achievement_score'].values\n",
    "\n",
    "print(f\"Data: {len(mindset)} students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Treatment\n",
    "\n",
    "### AIPW Connection\n",
    "\n",
    "**Augmented IPW (AIPW)** is equivalent to the DR estimator:\n",
    "\n",
    "$$\\hat{\\tau}_{AIPW} = \\hat{\\tau}_{IPW} + \\text{Augmentation}$$\n",
    "\n",
    "Where the augmentation uses outcome model predictions to \"stabilize\" the IPW estimate.\n",
    "\n",
    "### Efficiency Bound\n",
    "\n",
    "When both models are correct, DR achieves the **semiparametric efficiency bound**:\n",
    "\n",
    "$$V_{DR}^* = E\\left[\\frac{\\sigma_1^2(X)}{e(X)} + \\frac{\\sigma_0^2(X)}{1-e(X)} + (\\mu_1(X) - \\mu_0(X) - \\tau)^2\\right]$$\n",
    "\n",
    "This is the smallest possible variance among all regular estimators.\n",
    "\n",
    "### Comparison of Variance\n",
    "\n",
    "Under correct specification:\n",
    "- $V_{DR} \\leq V_{IPTW}$ (always)\n",
    "- $V_{DR} \\leq V_{OR}$ (when outcome model has error)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement all estimators\n",
    "\n",
    "def outcome_regression_ate(X, T, Y):\n",
    "    \"\"\"Pure outcome regression.\"\"\"\n",
    "    mu1 = LinearRegression().fit(X[T==1], Y[T==1]).predict(X)\n",
    "    mu0 = LinearRegression().fit(X[T==0], Y[T==0]).predict(X)\n",
    "    ate = (mu1 - mu0).mean()\n",
    "    se = (mu1 - mu0).std() / np.sqrt(len(Y))\n",
    "    return ate, se\n",
    "\n",
    "def iptw_ate(X, T, Y):\n",
    "    \"\"\"Hajek IPTW estimator.\"\"\"\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(X, T).predict_proba(X)[:, 1]\n",
    "    mu1 = np.sum(T * Y / ps) / np.sum(T / ps)\n",
    "    mu0 = np.sum((1 - T) * Y / (1 - ps)) / np.sum((1 - T) / (1 - ps))\n",
    "    ate = mu1 - mu0\n",
    "    # Bootstrap SE would be proper, using simple approx here\n",
    "    se = np.sqrt(np.var(Y[T==1])/(T.sum()) + np.var(Y[T==0])/((1-T).sum()))\n",
    "    return ate, se\n",
    "\n",
    "def ps_matching_ate(X, T, Y):\n",
    "    \"\"\"PS matching with replacement.\"\"\"\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(X, T).predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Find nearest PS match for each treated\n",
    "    treated_idx = np.where(T == 1)[0]\n",
    "    control_idx = np.where(T == 0)[0]\n",
    "    \n",
    "    ps_control = ps[control_idx].reshape(-1, 1)\n",
    "    nn = NearestNeighbors(n_neighbors=1).fit(ps_control)\n",
    "    \n",
    "    matched_effects = []\n",
    "    for i in treated_idx:\n",
    "        _, match_idx = nn.kneighbors([[ps[i]]])\n",
    "        matched_control = control_idx[match_idx[0, 0]]\n",
    "        matched_effects.append(Y[i] - Y[matched_control])\n",
    "    \n",
    "    matched_effects = np.array(matched_effects)\n",
    "    ate = matched_effects.mean()\n",
    "    se = matched_effects.std() / np.sqrt(len(matched_effects))\n",
    "    return ate, se\n",
    "\n",
    "def doubly_robust_ate(X, T, Y):\n",
    "    \"\"\"Doubly robust estimator.\"\"\"\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(X, T).predict_proba(X)[:, 1]\n",
    "    mu1 = LinearRegression().fit(X[T==1], Y[T==1]).predict(X)\n",
    "    mu0 = LinearRegression().fit(X[T==0], Y[T==0]).predict(X)\n",
    "    \n",
    "    dr_i = (mu1 - mu0 + \n",
    "            T * (Y - mu1) / ps - \n",
    "            (1 - T) * (Y - mu0) / (1 - ps))\n",
    "    \n",
    "    ate = dr_i.mean()\n",
    "    se = dr_i.std() / np.sqrt(len(Y))\n",
    "    return ate, se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numeric Demonstration\n",
    "\n",
    "### Head-to-Head Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all estimators\n",
    "or_ate, or_se = outcome_regression_ate(X, T, Y)\n",
    "iptw_est, iptw_se = iptw_ate(X, T, Y)\n",
    "psm_ate, psm_se = ps_matching_ate(X, T, Y)\n",
    "dr_ate, dr_se = doubly_robust_ate(X, T, Y)\n",
    "\n",
    "# Naive for reference\n",
    "naive_ate = Y[T==1].mean() - Y[T==0].mean()\n",
    "\n",
    "print(\"METHOD COMPARISON ON MINDSET DATA:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Method':<25} {'ATE':>10} {'SE':>10} {'95% CI':>20}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Naive':<25} {naive_ate:>10.4f} {'--':>10} {'--':>20}\")\n",
    "print(f\"{'Outcome Regression':<25} {or_ate:>10.4f} {or_se:>10.4f} [{or_ate-1.96*or_se:.3f}, {or_ate+1.96*or_se:.3f}]\")\n",
    "print(f\"{'IPTW':<25} {iptw_est:>10.4f} {iptw_se:>10.4f} [{iptw_est-1.96*iptw_se:.3f}, {iptw_est+1.96*iptw_se:.3f}]\")\n",
    "print(f\"{'PS Matching':<25} {psm_ate:>10.4f} {psm_se:>10.4f} [{psm_ate-1.96*psm_se:.3f}, {psm_ate+1.96*psm_se:.3f}]\")\n",
    "print(f\"{'Doubly Robust':<25} {dr_ate:>10.4f} {dr_se:>10.4f} [{dr_ate-1.96*dr_se:.3f}, {dr_ate+1.96*dr_se:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, ax = create_tufte_figure(figsize=(10, 5))\n",
    "\n",
    "methods = ['Naive', 'Outcome Reg', 'IPTW', 'PS Matching', 'Doubly Robust']\n",
    "estimates = [naive_ate, or_ate, iptw_est, psm_ate, dr_ate]\n",
    "errors = [0, 1.96*or_se, 1.96*iptw_se, 1.96*psm_se, 1.96*dr_se]\n",
    "colors_list = [COLORS['gray'], COLORS['blue'], COLORS['red'], COLORS['orange'], COLORS['green']]\n",
    "\n",
    "y_pos = np.arange(len(methods))\n",
    "\n",
    "# Plot points with error bars\n",
    "for i, (est, err, color) in enumerate(zip(estimates, errors, colors_list)):\n",
    "    ax.errorbar(est, i, xerr=err if err > 0 else None, \n",
    "                fmt='o', color=color, markersize=10, capsize=5, capthick=2)\n",
    "\n",
    "ax.axvline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(methods)\n",
    "\n",
    "set_tufte_title(ax, \"Treatment Effect Estimates with 95% CI\")\n",
    "set_tufte_labels(ax, \"Estimated ATE\", \"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Bootstrap Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# Bootstrap to compare variability\nnp.random.seed(42)\nn_boot = 50  # Reduced for notebook execution speed\n\nboot_results = {\n    'Outcome Reg': [],\n    'IPTW': [],\n    'PS Matching': [],\n    'Doubly Robust': []\n}\n\nn = len(Y)\nfor _ in range(n_boot):\n    idx = np.random.choice(n, size=n, replace=True)\n    X_b, T_b, Y_b = X[idx], T[idx], Y[idx]\n    \n    boot_results['Outcome Reg'].append(outcome_regression_ate(X_b, T_b, Y_b)[0])\n    boot_results['IPTW'].append(iptw_ate(X_b, T_b, Y_b)[0])\n    boot_results['PS Matching'].append(ps_matching_ate(X_b, T_b, Y_b)[0])\n    boot_results['Doubly Robust'].append(doubly_robust_ate(X_b, T_b, Y_b)[0])\n\n# Summary\nprint(\"BOOTSTRAP VARIABILITY COMPARISON:\")\nprint(\"=\" * 60)\nprint(f\"{'Method':<20} {'Mean':>10} {'Std':>10} {'2.5%':>10} {'97.5%':>10}\")\nprint(\"-\" * 60)\nfor method, values in boot_results.items():\n    values = np.array(values)\n    print(f\"{method:<20} {values.mean():>10.4f} {values.std():>10.4f} \"\n          f\"{np.percentile(values, 2.5):>10.4f} {np.percentile(values, 97.5):>10.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bootstrap distributions\n",
    "fig, axes = create_tufte_figure(ncols=2, nrows=2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors_map = {\n",
    "    'Outcome Reg': COLORS['blue'],\n",
    "    'IPTW': COLORS['red'],\n",
    "    'PS Matching': COLORS['orange'],\n",
    "    'Doubly Robust': COLORS['green']\n",
    "}\n",
    "\n",
    "for ax, (method, values) in zip(axes, boot_results.items()):\n",
    "    values = np.array(values)\n",
    "    ax.hist(values, bins=30, color=colors_map[method], alpha=0.7, edgecolor='white')\n",
    "    ax.axvline(values.mean(), color='black', linestyle='--', linewidth=2)\n",
    "    set_tufte_title(ax, f\"{method} (SD: {values.std():.4f})\")\n",
    "    set_tufte_labels(ax, \"ATE Estimate\", \"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Decision Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WHEN TO USE EACH METHOD:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "OUTCOME REGRESSION:\n",
    "  Best when: Outcome model likely well-specified, good overlap\n",
    "  Advantages: Simple, interpretable coefficients\n",
    "  Risks: Extrapolation in poor overlap regions\n",
    "\n",
    "IPTW:\n",
    "  Best when: PS model reliable, need transparent weighting\n",
    "  Advantages: Explicit balance through weights\n",
    "  Risks: Unstable with extreme weights\n",
    "\n",
    "PS MATCHING:\n",
    "  Best when: Need maximum transparency, good overlap\n",
    "  Advantages: Clear \"who is compared to whom\"\n",
    "  Risks: Discards data, lower efficiency\n",
    "\n",
    "DOUBLY ROBUST:\n",
    "  Best when: Model uncertainty, need robustness\n",
    "  Advantages: Double protection, efficient when both correct\n",
    "  Risks: More complex, can still fail if both wrong\n",
    "\n",
    "PRACTICAL RECOMMENDATIONS:\n",
    "  1. Start with outcome regression as baseline\n",
    "  2. Check overlap with PS diagnostics\n",
    "  3. Use DR as primary estimate if unsure about model\n",
    "  4. Report multiple methods for robustness check\n",
    "  5. If estimates differ substantially, investigate why\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustness check summary\n",
    "all_estimates = [or_ate, iptw_est, psm_ate, dr_ate]\n",
    "estimate_range = max(all_estimates) - min(all_estimates)\n",
    "estimate_cv = np.std(all_estimates) / np.mean(all_estimates)\n",
    "\n",
    "print(\"ROBUSTNESS CHECK:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Estimate range: {estimate_range:.4f}\")\n",
    "print(f\"Coefficient of variation: {estimate_cv:.1%}\")\n",
    "print(f\"\\nAssessment: {'ROBUST - estimates agree' if estimate_cv < 0.2 else 'INVESTIGATE - estimates differ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1: When would you prefer doubly robust over simpler methods?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Use DR when**:\n",
    "1. You're uncertain about model specification (either PS or outcome)\n",
    "2. Stakes are high - need robustness as \"insurance\"\n",
    "3. You want to combine the strengths of both approaches\n",
    "4. Sample size allows fitting both models reliably\n",
    "\n",
    "**Consider simpler methods when**:\n",
    "1. You're confident in one model specification\n",
    "2. Transparency is paramount (matching is most interpretable)\n",
    "3. Sample size is small (fitting two models may overfit)\n",
    "4. Computation constraints exist\n",
    "\n",
    "**Best practice**: Report multiple methods and check consistency.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q2: What is the relationship between AIPW and DR?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Answer**: They are equivalent! AIPW = DR = \"augmented inverse probability weighting.\"\n",
    "\n",
    "**AIPW formulation**:\n",
    "$$\\hat{\\tau}_{AIPW} = \\underbrace{\\frac{1}{n}\\sum \\frac{T_iY_i}{\\hat{e}(X_i)} - \\frac{(1-T_i)Y_i}{1-\\hat{e}(X_i)}}_{\\text{IPW}} + \\underbrace{\\text{augmentation term}}_{\\text{uses outcome model}}$$\n",
    "\n",
    "**DR formulation**:\n",
    "$$\\hat{\\tau}_{DR} = \\underbrace{\\frac{1}{n}\\sum \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)}_{\\text{outcome model}} + \\underbrace{\\text{IPTW correction}}_{\\text{uses PS}}$$\n",
    "\n",
    "**Key insight**: Same estimator, different decompositions. AIPW starts with IPW and augments; DR starts with outcome model and corrects.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q3: How do you decide between IPTW and matching?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Favor IPTW when**:\n",
    "- Want to use full sample (more efficient)\n",
    "- Estimating ATE (matching typically estimates ATT)\n",
    "- PS model well-specified\n",
    "- No extreme propensity scores\n",
    "\n",
    "**Favor Matching when**:\n",
    "- Want maximum transparency (\"these units were compared\")\n",
    "- Estimating ATT\n",
    "- Extreme weights would dominate IPTW\n",
    "- Need intuitive explanation for non-technical audience\n",
    "\n",
    "**Trade-off summary**:\n",
    "- IPTW: More efficient, less transparent\n",
    "- Matching: Less efficient, more transparent\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[^1]: Facure, M. (2022). *Causal Inference for the Brave and True*, Chapter 12.\n",
    "\n",
    "[^2]: Lunceford, J. K., & Davidian, M. (2004). Stratification and weighting via the propensity score in estimation of causal treatment effects. *Statistics in Medicine*, 23(19), 2937-2960.\n",
    "\n",
    "[^3]: Glynn, A. N., & Quinn, K. M. (2010). An introduction to the augmented inverse propensity weighted estimator. *Political Analysis*, 18(1), 36-56.\n",
    "\n",
    "[^4]: Cross-reference: Double ML in `22_debiased_ml/` extends these ideas with machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}