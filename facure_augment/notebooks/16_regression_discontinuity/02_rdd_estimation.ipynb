{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 16.2 RDD Estimation: Kernels and Bandwidth\n",
    "\n",
    "**Chapter**: 16 - Regression Discontinuity Design  \n",
    "**Section**: 2 - Local Linear Regression  \n",
    "**Facure Source**: 16-Regression-Discontinuity-Design.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-09\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Facure's Intuition](#1-facures-intuition)\n",
    "   - 1.1 [The Bandwidth Tradeoff](#11-the-bandwidth-tradeoff)\n",
    "   - 1.2 [Kernel Weighting](#12-kernel-weighting)\n",
    "2. [Formal Treatment](#2-formal-treatment)\n",
    "   - 2.1 [Local Linear Regression](#21-local-linear-regression)\n",
    "   - 2.2 [The Triangular Kernel](#22-the-triangular-kernel)\n",
    "   - 2.3 [Optimal Bandwidth Selection](#23-optimal-bandwidth-selection)\n",
    "3. [Numeric Demonstration](#3-numeric-demonstration)\n",
    "   - 3.1 [Kernel Weighting in Action](#31-kernel-weighting-in-action)\n",
    "   - 3.2 [Bandwidth Sensitivity](#32-bandwidth-sensitivity)\n",
    "4. [Implementation](#4-implementation)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports via common module\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from facure_augment.common import (\n",
    "    np, pd, plt, sm, smf,\n",
    "    load_facure_data,\n",
    "    set_notebook_style,\n",
    "    ols_summary_table,\n",
    "    create_tufte_figure,\n",
    "    TUFTE_PALETTE,\n",
    ")\n",
    "\n",
    "set_notebook_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition\n",
    "\n",
    "> **Interview Relevance**: Bandwidth selection is the core practical challenge in RDD. Understanding the bias-variance tradeoff and kernel weighting shows methodological sophistication.\n",
    "\n",
    "### 1.1 The Bandwidth Tradeoff\n",
    "\n",
    "Facure presents the fundamental RDD dilemma:\n",
    "\n",
    "**Narrow bandwidth** (use only observations very close to cutoff):\n",
    "- ✓ More credible \"local randomization\"\n",
    "- ✓ Less bias from functional form misspecification\n",
    "- ✗ Few observations → high variance\n",
    "\n",
    "**Wide bandwidth** (use more observations):\n",
    "- ✓ More data → lower variance\n",
    "- ✗ Farther observations are less comparable\n",
    "- ✗ More sensitive to functional form assumptions\n",
    "\n",
    "### 1.2 Kernel Weighting\n",
    "\n",
    "Solution: **Weight observations by distance from cutoff.**\n",
    "\n",
    "Observations closer to the cutoff get more weight. This balances:\n",
    "- Using nearby observations (credibility)\n",
    "- Including more data (precision)\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Bandwidth controls the bias-variance tradeoff\n",
    "- Kernel weights make the transition smooth\n",
    "- No single \"correct\" bandwidth—sensitivity analysis is essential\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment\n",
    "\n",
    "### 2.1 Local Linear Regression\n",
    "\n",
    "The RDD estimator uses **local linear regression**: fit separate lines on each side of the cutoff.\n",
    "\n",
    "**Estimator**:\n",
    "\n",
    "$$\\hat{\\tau} = \\hat{\\mu}_+ - \\hat{\\mu}_-$$\n",
    "\n",
    "where $\\hat{\\mu}_+$ and $\\hat{\\mu}_-$ are the predicted values at the cutoff from regressions on each side.\n",
    "\n",
    "**Weighted Least Squares formulation**:\n",
    "\n",
    "$$\\min_{\\alpha, \\beta, \\tau, \\delta} \\sum_{i=1}^n K\\left(\\frac{R_i - c}{h}\\right) \\left[Y_i - \\alpha - \\beta(R_i - c) - \\tau D_i - \\delta D_i(R_i - c)\\right]^2$$\n",
    "\n",
    "where:\n",
    "- $K(\\cdot)$: Kernel function (weights)\n",
    "- $h$: Bandwidth\n",
    "- $R_i - c$: Centered running variable\n",
    "- $D_i = \\mathbf{1}\\{R_i \\geq c\\}$: Treatment indicator\n",
    "\n",
    "The coefficient $\\tau$ is the RDD estimate.\n",
    "\n",
    "### 2.2 The Triangular Kernel\n",
    "\n",
    "**Triangular kernel** (most common in RDD):\n",
    "\n",
    "$$K(u) = (1 - |u|) \\cdot \\mathbf{1}\\{|u| \\leq 1\\}$$\n",
    "\n",
    "**Properties**:\n",
    "- Weight = 1 at cutoff ($u = 0$)\n",
    "- Weight decreases linearly with distance\n",
    "- Weight = 0 at bandwidth boundary ($|u| = 1$)\n",
    "\n",
    "**Why triangular?**\n",
    "\n",
    "**Proposition (Cheng, Fan, and Marron, 1997)**: For boundary estimation (which RDD is), the triangular kernel is optimal in a minimax MSE sense among all kernels.\n",
    "\n",
    "**Proof sketch**:\n",
    "- RDD estimates at the boundary (cutoff)\n",
    "- At boundaries, kernels that put more weight on interior points dominate\n",
    "- Triangular kernel minimizes asymptotic MSE at boundaries\n",
    "\n",
    "### 2.3 Optimal Bandwidth Selection\n",
    "\n",
    "**The bias-variance tradeoff formally**:\n",
    "\n",
    "$$\\text{MSE}(\\hat{\\tau}) = \\text{Bias}^2(\\hat{\\tau}) + \\text{Var}(\\hat{\\tau})$$\n",
    "\n",
    "As bandwidth $h \\to 0$:\n",
    "- Bias → 0 (less extrapolation)\n",
    "- Variance → ∞ (fewer observations)\n",
    "\n",
    "As bandwidth $h \\to \\infty$:\n",
    "- Bias → large (global regression)\n",
    "- Variance → small (all data)\n",
    "\n",
    "**Imbens-Kalyanaraman (IK) Optimal Bandwidth**:\n",
    "\n",
    "$$h_{\\text{IK}} = C_K \\cdot \\left(\\frac{\\sigma^2(c)}{f(c) \\cdot (m''_+(c) - m''_-(c))^2}\\right)^{1/5} \\cdot n^{-1/5}$$\n",
    "\n",
    "where:\n",
    "- $\\sigma^2(c)$: Conditional variance at cutoff\n",
    "- $f(c)$: Density of running variable at cutoff\n",
    "- $m''_\\pm(c)$: Second derivatives of regression functions\n",
    "- $C_K$: Kernel-dependent constant\n",
    "\n",
    "**Practical note**: Use `rdrobust` package which implements Calonico-Cattaneo-Titiunik (CCT) bandwidth with robust bias correction.\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Triangular kernel is optimal for boundary estimation\n",
    "- Optimal bandwidth balances bias and variance\n",
    "- Always report sensitivity to bandwidth choice\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration\n",
    "\n",
    "### 3.1 Kernel Weighting in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MLDA data\n",
    "drinking = load_facure_data('drinking.csv')\n",
    "drinking['age_centered'] = drinking['agecell'] - 21\n",
    "drinking['above_21'] = (drinking['age_centered'] >= 0).astype(int)\n",
    "\n",
    "print(f\"Data: {len(drinking)} age cells\")\n",
    "print(f\"Age range: {drinking['agecell'].min():.1f} to {drinking['agecell'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular_kernel(distance, bandwidth):\n",
    "    \"\"\"Triangular kernel: K(u) = (1 - |u|) * I(|u| <= 1)\"\"\"\n",
    "    u = np.abs(distance) / bandwidth\n",
    "    weights = np.where(u <= 1, 1 - u, 0)\n",
    "    return weights\n",
    "\n",
    "def uniform_kernel(distance, bandwidth):\n",
    "    \"\"\"Uniform kernel: K(u) = 0.5 * I(|u| <= 1)\"\"\"\n",
    "    u = np.abs(distance) / bandwidth\n",
    "    weights = np.where(u <= 1, 0.5, 0)\n",
    "    return weights\n",
    "\n",
    "# Visualize kernel functions\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Panel 1: Kernel shapes\n",
    "ax = axes[0]\n",
    "u_vals = np.linspace(-1.5, 1.5, 200)\n",
    "\n",
    "ax.plot(u_vals, [triangular_kernel(u, 1) for u in u_vals], \n",
    "        color=TUFTE_PALETTE['effect'], linewidth=2.5, label='Triangular')\n",
    "ax.plot(u_vals, [uniform_kernel(u, 1) for u in u_vals], \n",
    "        color=TUFTE_PALETTE['secondary'], linewidth=2.5, linestyle='--', label='Uniform')\n",
    "ax.axvline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Distance from cutoff (u = (R - c) / h)')\n",
    "ax.set_ylabel('Kernel weight K(u)')\n",
    "ax.set_title('(a) Kernel Functions')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Panel 2: Weights applied to MLDA data\n",
    "ax = axes[1]\n",
    "bandwidth = 1.0  # 1 year\n",
    "\n",
    "weights = triangular_kernel(drinking['age_centered'], bandwidth)\n",
    "\n",
    "ax.scatter(drinking['age_centered'], weights, \n",
    "           c=TUFTE_PALETTE['effect'], s=50, alpha=0.7)\n",
    "ax.axvline(0, color='gray', linestyle='--', linewidth=1.5)\n",
    "ax.set_xlabel('Age (centered at 21)')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title(f'(b) Triangular Kernel Weights (h = {bandwidth} year)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nWith bandwidth h = {bandwidth} year:\")\n",
    "print(f\"  Observations with weight > 0: {(weights > 0).sum()} / {len(weights)}\")\n",
    "print(f\"  Max weight (at cutoff): {weights.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_local_linear(data, outcome, bandwidth, kernel='triangular'):\n",
    "    \"\"\"\n",
    "    Local linear RDD estimation with kernel weighting.\n",
    "    \n",
    "    Model: Y = α + β(R-c) + τD + δD(R-c) + ε\n",
    "    Weighted by kernel function.\n",
    "    \"\"\"\n",
    "    # Compute weights\n",
    "    if kernel == 'triangular':\n",
    "        weights = triangular_kernel(data['age_centered'], bandwidth)\n",
    "    else:\n",
    "        weights = uniform_kernel(data['age_centered'], bandwidth)\n",
    "    \n",
    "    # Filter to observations within bandwidth\n",
    "    in_bandwidth = weights > 0\n",
    "    data_bw = data[in_bandwidth].copy()\n",
    "    weights_bw = weights[in_bandwidth]\n",
    "    \n",
    "    # WLS regression\n",
    "    model = smf.wls(\n",
    "        f'{outcome} ~ age_centered * above_21',\n",
    "        data=data_bw,\n",
    "        weights=weights_bw\n",
    "    ).fit()\n",
    "    \n",
    "    return {\n",
    "        'estimate': model.params['above_21'],\n",
    "        'se': model.bse['above_21'],\n",
    "        'n_effective': in_bandwidth.sum(),\n",
    "        'bandwidth': bandwidth,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# Estimate with different bandwidths\n",
    "print(\"RDD ESTIMATES: Triangular Kernel\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Bandwidth':>10} {'Estimate':>12} {'SE':>10} {'95% CI':>25} {'N_eff':>8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "bandwidths = [0.5, 1.0, 1.5, 2.0, 3.0]\n",
    "results = []\n",
    "\n",
    "for h in bandwidths:\n",
    "    res = rdd_local_linear(drinking, 'all', h, 'triangular')\n",
    "    ci_low = res['estimate'] - 1.96 * res['se']\n",
    "    ci_high = res['estimate'] + 1.96 * res['se']\n",
    "    \n",
    "    print(f\"{h:>10.1f} {res['estimate']:>12.4f} {res['se']:>10.4f} [{ci_low:>9.4f}, {ci_high:>9.4f}] {res['n_effective']:>8}\")\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### 3.2 Bandwidth Sensitivity\n",
    "\n",
    "A critical RDD diagnostic: **How sensitive is the estimate to bandwidth choice?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandwidth sensitivity analysis\n",
    "bandwidth_range = np.linspace(0.3, 3.0, 30)\n",
    "sensitivity = []\n",
    "\n",
    "for h in bandwidth_range:\n",
    "    res = rdd_local_linear(drinking, 'all', h, 'triangular')\n",
    "    sensitivity.append({\n",
    "        'bandwidth': h,\n",
    "        'estimate': res['estimate'],\n",
    "        'se': res['se'],\n",
    "        'ci_low': res['estimate'] - 1.96 * res['se'],\n",
    "        'ci_high': res['estimate'] + 1.96 * res['se'],\n",
    "        'n_eff': res['n_effective']\n",
    "    })\n",
    "\n",
    "sens_df = pd.DataFrame(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bandwidth sensitivity\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Panel 1: Estimate by bandwidth\n",
    "ax = axes[0]\n",
    "ax.fill_between(sens_df['bandwidth'], sens_df['ci_low'], sens_df['ci_high'],\n",
    "                color=TUFTE_PALETTE['effect'], alpha=0.2)\n",
    "ax.plot(sens_df['bandwidth'], sens_df['estimate'], \n",
    "        color=TUFTE_PALETTE['effect'], linewidth=2.5)\n",
    "ax.axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "\n",
    "# Mark \"typical\" bandwidth\n",
    "typical_h = 1.0\n",
    "ax.axvline(typical_h, color=TUFTE_PALETTE['treatment'], linestyle='--', \n",
    "           linewidth=1.5, label=f'h = {typical_h} (reference)')\n",
    "\n",
    "ax.set_xlabel('Bandwidth (years)')\n",
    "ax.set_ylabel('RDD Estimate (mortality per 100k)')\n",
    "ax.set_title('(a) Estimate Sensitivity to Bandwidth')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Panel 2: Effective sample size\n",
    "ax = axes[1]\n",
    "ax.plot(sens_df['bandwidth'], sens_df['n_eff'], \n",
    "        color=TUFTE_PALETTE['secondary'], linewidth=2.5)\n",
    "ax.axvline(typical_h, color=TUFTE_PALETTE['treatment'], linestyle='--', linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('Bandwidth (years)')\n",
    "ax.set_ylabel('Effective Sample Size')\n",
    "ax.set_title('(b) Sample Size by Bandwidth')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare kernel types\n",
    "print(\"\\nKERNEL COMPARISON (h = 1.0)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for kernel in ['triangular', 'uniform']:\n",
    "    res = rdd_local_linear(drinking, 'all', 1.0, kernel)\n",
    "    print(f\"\\n{kernel.capitalize()} kernel:\")\n",
    "    print(f\"  Estimate: {res['estimate']:.4f}\")\n",
    "    print(f\"  SE:       {res['se']:.4f}\")\n",
    "    print(f\"  N_eff:    {res['n_effective']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": "**Key observations**:\n\n1. **Estimate varies with bandwidth**: Larger bandwidth → estimate changes (potential bias)\n2. **Precision varies with bandwidth**: Larger bandwidth → smaller SE (more data)\n3. **Triangular vs. Uniform**: Triangular is theoretically preferred; estimates are similar\n4. **Robustness**: If estimate is stable across reasonable bandwidths → more credible\n\n---\n\n## Additional Content: Bandwidth Selection Methods\n\n### IK vs CCT Bandwidth: When to Use Each\n\n**Imbens-Kalyanaraman (IK, 2012)**:\n- Minimizes **mean squared error** (MSE) of the point estimate\n- Balances bias² and variance\n- Standard choice for many years\n\n**Calonico-Cattaneo-Titiunik (CCT, 2014)**:\n- Accounts for **bias in inference**—CIs with IK bandwidth have wrong coverage\n- Provides **robust bias-corrected confidence intervals**\n- CCT bandwidth is typically 1.5-2× larger than IK\n- Currently the recommended approach\n\n**Practical guidance**:\n| Situation | Recommendation |\n|-----------|----------------|\n| Point estimate focus | IK bandwidth |\n| Inference/CI focus | CCT with robust bias correction |\n| Publication | CCT is now standard |\n| Sensitivity | Report both, plus 0.5×, 2× multipliers |\n\n### McCrary Test Limitations\n\nThe **McCrary (2008)** density test checks for manipulation at the cutoff. However:\n\n**⚠️ WARNING: Low Power Issue**\n\nThe McCrary test has **notoriously low power**, especially with:\n- Small sample sizes (n < 1000)\n- Running variables with discrete support\n- Moderate manipulation amounts\n\n**Key limitations**:\n1. **Failure to reject ≠ no manipulation**: The test may miss even substantial manipulation\n2. **Discrete running variables**: Test assumes continuous running variable; discrete data (e.g., test scores) requires different approach\n3. **Compound treatments**: Even without manipulation, density bunching may occur naturally\n\n**Recommendations**:\n- Report McCrary test but interpret cautiously\n- Conduct covariate balance tests at cutoff\n- Use placebo cutoffs to check for spurious discontinuities\n- Visual inspection is valuable but subjective\n\n```python\n# McCrary test with caution\nfrom causal_inference.rdd import mccrary_test\n\nresult = mccrary_test(running_var, cutoff=c)\nprint(f\"McCrary p-value: {result.pvalue:.4f}\")\nprint(\"⚠️ Note: McCrary test has low power. Non-rejection does not confirm validity.\")\n```\n\n★ Insight ─────────────────────────────────────\n- CCT bandwidth with robust CIs is now the standard\n- Always report sensitivity to bandwidth choice\n- McCrary test has low power—non-rejection is weak evidence\n- Combine McCrary with covariate balance tests and placebo cutoffs\n─────────────────────────────────────────────────"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation\n",
    "\n",
    "The `causal_inference_mastery` library provides RDD with optimal bandwidth:\n",
    "\n",
    "```python\n",
    "from causal_inference.rdd import sharp_rdd, RDDResult\n",
    "\n",
    "# Sharp RDD with CCT bandwidth\n",
    "result = sharp_rdd(\n",
    "    outcome=data['mortality'],\n",
    "    running_var=data['age'],\n",
    "    cutoff=21,\n",
    "    bandwidth='CCT',  # Calonico-Cattaneo-Titiunik\n",
    "    kernel='triangular',\n",
    "    polynomial=1,  # Local linear\n",
    "    robust_se=True  # Bias-corrected CI\n",
    ")\n",
    "\n",
    "print(f\"Optimal bandwidth: {result.bandwidth:.3f}\")\n",
    "print(f\"Estimate: {result.estimate:.4f}\")\n",
    "print(f\"Robust SE: {result.se_robust:.4f}\")\n",
    "print(f\"Robust 95% CI: [{result.ci_lower:.4f}, {result.ci_upper:.4f}]\")\n",
    "\n",
    "# Sensitivity analysis\n",
    "result.plot_sensitivity(bandwidth_range=[0.5, 2.0])\n",
    "```\n",
    "\n",
    "The production implementation includes:\n",
    "- IK and CCT optimal bandwidth selection\n",
    "- Bias-corrected robust standard errors\n",
    "- Covariate adjustment option\n",
    "- Automatic sensitivity plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1 (Meta E5, DS)**: *\"Why do we use a triangular kernel instead of uniform kernel in RDD?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Theoretical reason**: Triangular kernel is MSE-optimal for boundary estimation.\n",
    "\n",
    "**Intuition**:\n",
    "\n",
    "1. **RDD is boundary estimation**: We estimate at the cutoff, which is at the boundary of the support for each side\n",
    "\n",
    "2. **At boundaries, interior points are more informative**:\n",
    "   - For estimating the limit from the left at $c$, points at $c - \\epsilon$ are more useful than points at $c - h$\n",
    "   - Triangular kernel weights interior points more heavily\n",
    "\n",
    "3. **Formal result (Cheng, Fan, Marron 1997)**:\n",
    "   - Among all nonnegative kernel functions\n",
    "   - Triangular kernel minimizes the asymptotic MSE\n",
    "   - For boundary estimation specifically (not interior)\n",
    "\n",
    "4. **Practical difference**:\n",
    "   - Often small in practice\n",
    "   - Triangular is standard, provides theoretical optimality\n",
    "   - Uniform is simpler to explain but slightly less efficient\n",
    "\n",
    "**Key point**: It's about boundary estimation, not general kernel regression. At boundaries, triangular dominates.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q2 (Google L5, Quant)**: *\"How do you choose bandwidth in RDD? What's the tradeoff?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**The bias-variance tradeoff**:\n",
    "\n",
    "| Bandwidth | Bias | Variance | Credibility |\n",
    "|-----------|------|----------|-------------|\n",
    "| Narrow | Low | High | High (local randomization) |\n",
    "| Wide | High | Low | Lower (more extrapolation) |\n",
    "\n",
    "**Bandwidth selection methods**:\n",
    "\n",
    "1. **Imbens-Kalyanaraman (IK)**:\n",
    "   - MSE-optimal bandwidth\n",
    "   - Balances bias² and variance\n",
    "   - Standard in economics\n",
    "\n",
    "2. **Calonico-Cattaneo-Titiunik (CCT)**:\n",
    "   - Accounts for bias in coverage\n",
    "   - Provides robust bias-corrected CIs\n",
    "   - Currently preferred method\n",
    "\n",
    "3. **Cross-validation**:\n",
    "   - Leave-one-out prediction error\n",
    "   - Data-driven but can overfit\n",
    "\n",
    "**Best practice**:\n",
    "1. Report main results with CCT optimal bandwidth\n",
    "2. Show sensitivity: 0.5h, h, 1.5h, 2h\n",
    "3. If results flip sign across reasonable bandwidths → be cautious\n",
    "4. Never \"shop\" for bandwidth that gives desired result\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q3 (Amazon L6, Econ)**: *\"Your RDD estimate is 5.0 with h=1 and 8.0 with h=2. What do you conclude?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**This is a red flag for specification sensitivity.**\n",
    "\n",
    "**Possible explanations**:\n",
    "\n",
    "1. **Functional form misspecification**:\n",
    "   - True relationship is nonlinear\n",
    "   - Linear approximation worsens with wider bandwidth\n",
    "   - **Fix**: Try higher-order polynomial, or stick with narrow bandwidth\n",
    "\n",
    "2. **Heterogeneous effects**:\n",
    "   - Effect differs for observations far from cutoff\n",
    "   - Wider bandwidth includes different populations\n",
    "   - **Interpretation**: Local effect (h=1) differs from global\n",
    "\n",
    "3. **Confounding far from cutoff**:\n",
    "   - Continuity assumption holds near cutoff but breaks down farther away\n",
    "   - Narrow bandwidth more credible\n",
    "\n",
    "**What to report**:\n",
    "1. Acknowledge the sensitivity explicitly\n",
    "2. Trust narrower bandwidth (more credible local randomization)\n",
    "3. Report both, explain why they differ\n",
    "4. Consider whether research question is about local or broader effect\n",
    "\n",
    "**Key point**: Sensitivity to bandwidth suggests the estimate is fragile. Don't hide this—address it transparently.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 16: \"Regression Discontinuity Design.\"\n",
    "\n",
    "[^2]: Imbens, G. W. and Kalyanaraman, K. (2012). Optimal Bandwidth Choice for the Regression Discontinuity Estimator. *Review of Economic Studies*, 79(3), 933-959.\n",
    "\n",
    "[^3]: Calonico, S., Cattaneo, M. D., and Titiunik, R. (2014). Robust Nonparametric Confidence Intervals for Regression-Discontinuity Designs. *Econometrica*, 82(6), 2295-2326.\n",
    "\n",
    "[^4]: Cheng, M.-Y., Fan, J., and Marron, J. S. (1997). On Automatic Boundary Corrections. *Annals of Statistics*, 25(4), 1691-1708.\n",
    "\n",
    "[^5]: Cattaneo, M. D., Idrobo, N., and Titiunik, R. (2020). *A Practical Introduction to Regression Discontinuity Designs: Foundations*. Cambridge University Press.\n",
    "\n",
    "---\n",
    "\n",
    "**Precision Improvement:**\n",
    "- You said: \"Build RDD estimation notebook\"\n",
    "- Concise: \"Build 02_rdd_estimation.ipynb\"\n",
    "- Precise: `/facure_augment 16.2 --kernel-weighting --bandwidth-selection --sensitivity`\n",
    "- Pattern: [build] [target] [content-flags]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}