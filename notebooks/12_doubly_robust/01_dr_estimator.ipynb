{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# The Doubly Robust Estimator\n",
    "\n",
    "**Chapter 12, Section 1**\n",
    "\n",
    "This notebook introduces the doubly robust (DR) estimator that combines propensity score weighting with outcome regression.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition) - Why combine two models?\n",
    "2. [Formal Treatment](#formal) - The DR formula\n",
    "3. [Numeric Demonstration](#numeric) - Mindset data application\n",
    "4. [Implementation](#implementation) - Step-by-step DR\n",
    "5. [Interview Appendix](#interview) - Practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from facure_augment.common import *\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# Set notebook style\n",
    "set_notebook_style()\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "### The Problem with Single-Model Approaches\n",
    "\n",
    "**IPTW** (propensity score only):\n",
    "- Requires correct PS model\n",
    "- Can be unstable with extreme weights\n",
    "- Doesn't use outcome information\n",
    "\n",
    "**Outcome Regression** (outcome model only):\n",
    "- Requires correct outcome model\n",
    "- Extrapolates in regions without data\n",
    "- Doesn't account for treatment selection\n",
    "\n",
    "### The Doubly Robust Solution\n",
    "\n",
    "**Key idea**: Combine both models for \"insurance\" - if either model is correct, you get consistent estimates.\n",
    "\n",
    "$$\\text{DR} = \\text{Outcome Model} + \\text{IPTW Correction}$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mindset data\n",
    "mindset = load_facure_data(\"learning_mindset.csv\")\n",
    "\n",
    "covariates = [\n",
    "    'success_expect', 'ethnicity', 'gender', 'frst_in_family',\n",
    "    'school_mindset', 'school_achievement', 'school_ethnic_minority',\n",
    "    'school_poverty', 'school_size'\n",
    "]\n",
    "\n",
    "X = mindset[covariates].values\n",
    "T = mindset['intervention'].values\n",
    "Y = mindset['achievement_score'].values\n",
    "\n",
    "print(f\"Data: {len(mindset)} students\")\n",
    "print(f\"Treatment rate: {T.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Treatment\n",
    "\n",
    "### The Doubly Robust Estimator\n",
    "\n",
    "**Definition**: The DR estimator for ATE is:\n",
    "\n",
    "$$\\hat{\\tau}_{DR} = \\frac{1}{n}\\sum_{i=1}^{n} \\left[ \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) + \\frac{T_i(Y_i - \\hat{\\mu}_1(X_i))}{\\hat{e}(X_i)} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}_0(X_i))}{1-\\hat{e}(X_i)} \\right]$$\n",
    "\n",
    "Where:\n",
    "- $\\hat{\\mu}_1(X)$: Predicted outcome under treatment\n",
    "- $\\hat{\\mu}_0(X)$: Predicted outcome under control\n",
    "- $\\hat{e}(X)$: Estimated propensity score\n",
    "\n",
    "### Decomposition\n",
    "\n",
    "The DR estimator has two parts:\n",
    "\n",
    "1. **Outcome model term**: $\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)$\n",
    "2. **IPTW correction term**: Adjusts for errors in outcome model\n",
    "\n",
    "### For ATT\n",
    "\n",
    "$$\\hat{\\tau}_{ATT}^{DR} = \\frac{1}{n_1}\\sum_{i:T_i=1} \\left[ Y_i - \\hat{\\mu}_0(X_i) - \\frac{(1-T_i)\\hat{e}(X_i)(Y_i - \\hat{\\mu}_0(X_i))}{(1-\\hat{e}(X_i))P(T=1)} \\right]$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_robust_ate(X, T, Y):\n",
    "    \"\"\"\n",
    "    Doubly Robust estimator for ATE.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : covariate matrix\n",
    "    T : treatment indicator\n",
    "    Y : outcome\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with ATE estimate and components\n",
    "    \"\"\"\n",
    "    n = len(Y)\n",
    "    \n",
    "    # Step 1: Estimate propensity scores\n",
    "    ps_model = LogisticRegression(C=1e6, max_iter=1000, solver='lbfgs')\n",
    "    ps_model.fit(X, T)\n",
    "    ps = ps_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Step 2: Estimate outcome models\n",
    "    # Model for treated: E[Y|X, T=1]\n",
    "    mu1_model = LinearRegression()\n",
    "    mu1_model.fit(X[T==1], Y[T==1])\n",
    "    mu1 = mu1_model.predict(X)\n",
    "    \n",
    "    # Model for control: E[Y|X, T=0]\n",
    "    mu0_model = LinearRegression()\n",
    "    mu0_model.fit(X[T==0], Y[T==0])\n",
    "    mu0 = mu0_model.predict(X)\n",
    "    \n",
    "    # Step 3: Compute DR estimator\n",
    "    # Outcome model component\n",
    "    outcome_component = mu1 - mu0\n",
    "    \n",
    "    # IPTW correction for treated\n",
    "    iptw_treated = T * (Y - mu1) / ps\n",
    "    \n",
    "    # IPTW correction for control\n",
    "    iptw_control = (1 - T) * (Y - mu0) / (1 - ps)\n",
    "    \n",
    "    # DR estimate for each unit\n",
    "    dr_i = outcome_component + iptw_treated - iptw_control\n",
    "    \n",
    "    # ATE is the average\n",
    "    ate = dr_i.mean()\n",
    "    se = dr_i.std() / np.sqrt(n)\n",
    "    \n",
    "    return {\n",
    "        'ate': ate,\n",
    "        'se': se,\n",
    "        'outcome_component': outcome_component.mean(),\n",
    "        'iptw_treated_component': iptw_treated.mean(),\n",
    "        'iptw_control_component': iptw_control.mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute DR estimate\n",
    "dr_result = doubly_robust_ate(X, T, Y)\n",
    "\n",
    "print(\"DOUBLY ROBUST ESTIMATE:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ATE: {dr_result['ate']:.4f} (SE: {dr_result['se']:.4f})\")\n",
    "print(f\"95% CI: [{dr_result['ate'] - 1.96*dr_result['se']:.4f}, {dr_result['ate'] + 1.96*dr_result['se']:.4f}]\")\n",
    "print(f\"\\nComponents:\")\n",
    "print(f\"  Outcome model: {dr_result['outcome_component']:.4f}\")\n",
    "print(f\"  IPTW treated:  {dr_result['iptw_treated_component']:.4f}\")\n",
    "print(f\"  IPTW control:  {dr_result['iptw_control_component']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numeric Demonstration\n",
    "\n",
    "### Comparison with Other Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare methods\n",
    "print(\"METHOD COMPARISON:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Naive difference in means\n",
    "naive = Y[T==1].mean() - Y[T==0].mean()\n",
    "print(f\"Naive (unadjusted):     {naive:.4f}\")\n",
    "\n",
    "# 2. OLS regression adjustment\n",
    "formula = 'achievement_score ~ intervention + ' + ' + '.join(covariates)\n",
    "ols = smf.ols(formula, data=mindset).fit()\n",
    "print(f\"Regression adjustment:  {ols.params['intervention']:.4f} (SE: {ols.bse['intervention']:.4f})\")\n",
    "\n",
    "# 3. IPTW\n",
    "ps_model = LogisticRegression(C=1e6, max_iter=1000, solver='lbfgs')\n",
    "ps_model.fit(X, T)\n",
    "ps = ps_model.predict_proba(X)[:, 1]\n",
    "mu1_iptw = np.sum(T * Y / ps) / np.sum(T / ps)\n",
    "mu0_iptw = np.sum((1 - T) * Y / (1 - ps)) / np.sum((1 - T) / (1 - ps))\n",
    "iptw_ate = mu1_iptw - mu0_iptw\n",
    "print(f\"IPTW (Hajek):           {iptw_ate:.4f}\")\n",
    "\n",
    "# 4. Doubly Robust\n",
    "print(f\"Doubly Robust:          {dr_result['ate']:.4f} (SE: {dr_result['se']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "fig, ax = create_tufte_figure(figsize=(10, 5))\n",
    "\n",
    "methods = ['Naive', 'Regression', 'IPTW', 'Doubly Robust']\n",
    "estimates = [naive, ols.params['intervention'], iptw_ate, dr_result['ate']]\n",
    "colors_list = [COLORS['gray'], COLORS['blue'], COLORS['red'], COLORS['green']]\n",
    "\n",
    "bars = ax.barh(methods, estimates, color=colors_list, alpha=0.7, height=0.6)\n",
    "\n",
    "# Add value labels\n",
    "for bar, est in zip(bars, estimates):\n",
    "    ax.text(est + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "            f'{est:.4f}', va='center', fontsize=10)\n",
    "\n",
    "ax.axvline(0, color='gray', linewidth=1, alpha=0.5)\n",
    "set_tufte_title(ax, \"Treatment Effect Estimates by Method\")\n",
    "set_tufte_labels(ax, \"Estimated ATE\", \"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Production-Ready DR Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_robust(df, X_cols, treatment_col, outcome_col, \n",
    "                  ps_model=None, outcome_model=None):\n",
    "    \"\"\"\n",
    "    Production doubly robust estimator.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with all variables\n",
    "    X_cols : list of covariate column names\n",
    "    treatment_col : name of treatment column\n",
    "    outcome_col : name of outcome column\n",
    "    ps_model : sklearn classifier (default: LogisticRegression)\n",
    "    outcome_model : sklearn regressor (default: LinearRegression)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with estimates and diagnostics\n",
    "    \"\"\"\n",
    "    X = df[X_cols].values\n",
    "    T = df[treatment_col].values\n",
    "    Y = df[outcome_col].values\n",
    "    n = len(Y)\n",
    "    \n",
    "    # Default models\n",
    "    if ps_model is None:\n",
    "        ps_model = LogisticRegression(C=1e6, max_iter=1000, solver='lbfgs')\n",
    "    if outcome_model is None:\n",
    "        outcome_model = LinearRegression()\n",
    "    \n",
    "    # Fit propensity score\n",
    "    from sklearn.base import clone\n",
    "    ps_fitted = clone(ps_model).fit(X, T)\n",
    "    ps = ps_fitted.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Fit outcome models\n",
    "    mu1_fitted = clone(outcome_model).fit(X[T==1], Y[T==1])\n",
    "    mu0_fitted = clone(outcome_model).fit(X[T==0], Y[T==0])\n",
    "    mu1 = mu1_fitted.predict(X)\n",
    "    mu0 = mu0_fitted.predict(X)\n",
    "    \n",
    "    # DR estimate\n",
    "    dr_i = (mu1 - mu0 + \n",
    "            T * (Y - mu1) / ps - \n",
    "            (1 - T) * (Y - mu0) / (1 - ps))\n",
    "    \n",
    "    ate = dr_i.mean()\n",
    "    se = dr_i.std() / np.sqrt(n)\n",
    "    \n",
    "    # Diagnostics\n",
    "    ps_range = (ps.min(), ps.max())\n",
    "    \n",
    "    return {\n",
    "        'ate': ate,\n",
    "        'se': se,\n",
    "        'ci_lower': ate - 1.96 * se,\n",
    "        'ci_upper': ate + 1.96 * se,\n",
    "        'n': n,\n",
    "        'n_treated': T.sum(),\n",
    "        'ps_range': ps_range,\n",
    "        'individual_effects': dr_i\n",
    "    }\n",
    "\n",
    "# Test the production function\n",
    "result = doubly_robust(mindset, covariates, 'intervention', 'achievement_score')\n",
    "\n",
    "print(\"PRODUCTION DR ESTIMATOR:\")\n",
    "print(f\"ATE: {result['ate']:.4f}\")\n",
    "print(f\"SE: {result['se']:.4f}\")\n",
    "print(f\"95% CI: [{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]\")\n",
    "print(f\"PS range: [{result['ps_range'][0]:.4f}, {result['ps_range'][1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap CI for more robust uncertainty\n",
    "def bootstrap_dr(df, X_cols, treatment_col, outcome_col, n_bootstrap=500):\n",
    "    \"\"\"Bootstrap confidence interval for DR estimator.\"\"\"\n",
    "    n = len(df)\n",
    "    bootstrap_ates = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        df_boot = df.iloc[idx]\n",
    "        \n",
    "        # Compute DR estimate\n",
    "        result = doubly_robust(df_boot, X_cols, treatment_col, outcome_col)\n",
    "        bootstrap_ates.append(result['ate'])\n",
    "    \n",
    "    bootstrap_ates = np.array(bootstrap_ates)\n",
    "    \n",
    "    return {\n",
    "        'ate': np.mean(bootstrap_ates),\n",
    "        'se_bootstrap': np.std(bootstrap_ates),\n",
    "        'ci_lower': np.percentile(bootstrap_ates, 2.5),\n",
    "        'ci_upper': np.percentile(bootstrap_ates, 97.5)\n",
    "    }\n",
    "\n",
    "# Run bootstrap (reduced iterations for notebook)\n",
    "np.random.seed(42)\n",
    "boot_result = bootstrap_dr(mindset, covariates, 'intervention', 'achievement_score', n_bootstrap=200)\n",
    "\n",
    "print(\"BOOTSTRAP RESULTS:\")\n",
    "print(f\"ATE: {boot_result['ate']:.4f}\")\n",
    "print(f\"Bootstrap SE: {boot_result['se_bootstrap']:.4f}\")\n",
    "print(f\"95% CI (percentile): [{boot_result['ci_lower']:.4f}, {boot_result['ci_upper']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": "---\n\n## Production Implementation\n\nThis method is implemented in the `causal_inference_mastery` library:\n\n```python\nfrom causal_inference.observational.doubly_robust import (\n    doubly_robust_ate,\n    doubly_robust_att,\n    aipw_estimator,\n    DoublyRobustResult\n)\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n\n# Basic DR estimator\nresult = doubly_robust_ate(\n    outcome=data['achievement_score'],\n    treatment=data['intervention'],\n    covariates=data[covariates],\n    ps_model=GradientBoostingClassifier(n_estimators=100),\n    outcome_model=GradientBoostingRegressor(n_estimators=100)\n)\nprint(f\"ATE: {result.ate:.4f}\")\nprint(f\"SE: {result.se:.4f}\")\nprint(f\"95% CI: [{result.ci_lower:.4f}, {result.ci_upper:.4f}]\")\n\n# AIPW (augmented IPW) with cross-fitting\naipw_result = aipw_estimator(\n    outcome=data['achievement_score'],\n    treatment=data['intervention'],\n    covariates=data[covariates],\n    cross_fit=True,\n    n_folds=5\n)\nprint(f\"AIPW estimate: {aipw_result.ate:.4f}\")\nprint(f\"Influence function SE: {aipw_result.se:.4f}\")\n```\n\n**Key differences from notebook demo**:\n- Production code implements AIPW with influence function-based standard errors\n- Cross-fitting to avoid regularization bias (DML-style)\n- Supports flexible ML models for both nuisance functions\n- Automatic model diagnostics (R², AUC)\n- Cross-validated with Julia implementation\n\n**See also**: `causal_inference_mastery/src/causal_inference/observational/doubly_robust.py`\n\n**External reference**: For production CATE with DR, see [econml.dr](https://github.com/py-why/EconML) which provides DRLearner for heterogeneous effects.\n\n---\n\n## Interview Appendix\n\n### Practice Questions\n\n**Q1: Write the doubly robust estimator formula.**\n\n<details>\n<summary>Solution</summary>\n\n**Formula**:\n\n$$\\hat{\\tau}_{DR} = \\frac{1}{n}\\sum_{i=1}^{n} \\left[ \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) + \\frac{T_i(Y_i - \\hat{\\mu}_1(X_i))}{\\hat{e}(X_i)} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}_0(X_i))}{1-\\hat{e}(X_i)} \\right]$$\n\n**Components**:\n- $\\hat{\\mu}_1(X), \\hat{\\mu}_0(X)$: Outcome models for treated and control\n- $\\hat{e}(X)$: Propensity score\n- First term: Outcome model prediction\n- Second and third terms: IPTW corrections for residuals\n\n**Intuition**: Start with outcome model, correct its errors using IPTW.\n\n</details>\n\n**Q2: Why do we need both an outcome model and a propensity score model?**\n\n<details>\n<summary>Solution</summary>\n\n**The problem**:\n- Outcome regression alone: Requires correct functional form\n- IPTW alone: Can have high variance with extreme weights\n\n**The solution**:\n- DR uses outcome model as \"base case\"\n- IPTW terms correct for any errors in outcome model\n- If outcome model is correct, IPTW terms are zero in expectation\n- If PS model is correct, IPTW provides consistent correction\n\n**Key insight**: Insurance against misspecification - only ONE model needs to be correct.\n\n</details>\n\n**Q3: What happens if both models are wrong?**\n\n<details>\n<summary>Solution</summary>\n\n**Short answer**: The DR estimator can still be biased.\n\n**Details**:\n- \"Double robustness\" ≠ \"always robust\"\n- If BOTH models are wrong, bias can accumulate\n- However, bias is typically smaller than single-model approaches\n- DR is \"locally efficient\" - achieves minimum variance when both models correct\n\n**Practical guidance**:\n1. Use flexible models (random forest, gradient boosting)\n2. Check sensitivity to model choice\n3. Cross-fit to avoid overfitting (DML approach)\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[^1]: Facure, M. (2022). *Causal Inference for the Brave and True*, Chapter 12.\n",
    "\n",
    "[^2]: Bang, H., & Robins, J. M. (2005). Doubly robust estimation in missing data and causal inference models. *Biometrics*, 61(4), 962-973.\n",
    "\n",
    "[^3]: Funk, M. J., et al. (2011). Doubly robust estimation of causal effects. *American Journal of Epidemiology*, 173(7), 761-767.\n",
    "\n",
    "[^4]: Cross-reference: `src/causal_inference/observational/doubly_robust.py` for production implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}