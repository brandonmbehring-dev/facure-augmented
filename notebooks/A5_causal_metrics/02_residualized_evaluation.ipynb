{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper Causal Model Evaluation: Residualized Outcomes\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition)\n",
    "2. [Formal Treatment](#formal)\n",
    "3. [Numeric Demonstration](#numeric)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Interview Appendix](#interview)\n",
    "6. [References](#references)\n",
    "\n",
    "---\n",
    "\n",
    "**Appendix A5 | Notebook 2 of 2**\n",
    "\n",
    "This notebook shows how to properly evaluate causal models using\n",
    "residualized outcomes, fixing the R² problem from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent to path for imports\n",
    "module_path = str(Path.cwd().parent.parent)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "\n",
    "from facure_augment.common import *\n",
    "set_notebook_style()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Intuition {#intuition}\n",
    "\n",
    "### The Fix for R² Evaluation\n",
    "\n",
    "**Problem** (from notebook 01):\n",
    "$$Y = \\underbrace{g(X)}_{\\text{large}} + \\underbrace{f(T, W)}_{\\text{small}}$$\n",
    "\n",
    "R² rewards predicting $g(X)$, not $f(T, W)$.\n",
    "\n",
    "**Solution**: Remove $g(X)$ from the outcome!\n",
    "\n",
    "$$\\tilde{Y} = Y - \\hat{g}(X)$$\n",
    "\n",
    "Now R² on $\\tilde{Y}$ evaluates only the causal component $f(T, W)$.\n",
    "\n",
    "### The Orthogonalization Connection\n",
    "\n",
    "This is the same intuition as DML/orthogonalization:\n",
    "1. Remove nuisance from outcome: $\\tilde{Y} = Y - \\hat{g}(X)$\n",
    "2. Remaining variation is causal: $\\tilde{Y} \\approx f(T, W) + \\epsilon$\n",
    "\n",
    "**Key difference from DML**:\n",
    "- DML: Use residuals for estimation\n",
    "- Here: Use residuals for evaluation\n",
    "\n",
    "```\n",
    "★ Insight ─────────────────────────────────────────────────────\n",
    "By residualizing Y, we \"level the playing field\".\n",
    "\n",
    "A model can no longer achieve high R² by predicting nuisance.\n",
    "It MUST predict the treatment effect to score well.\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment {#formal}\n",
    "\n",
    "### 2.1 Residualized Outcome\n",
    "\n",
    "**Step 1**: Estimate nuisance function $g(X)$:\n",
    "$$\\hat{g}(X) = \\hat{E}[Y | X]$$\n",
    "\n",
    "**Step 2**: Compute residualized outcome:\n",
    "$$\\tilde{Y} = Y - \\hat{g}(X)$$\n",
    "\n",
    "Under the additive model $Y = g(X) + f(T, W) + \\epsilon$:\n",
    "$$\\tilde{Y} = f(T, W) + \\epsilon + (g(X) - \\hat{g}(X))$$\n",
    "\n",
    "If $\\hat{g}(X) \\approx g(X)$, then:\n",
    "$$\\tilde{Y} \\approx f(T, W) + \\epsilon$$\n",
    "\n",
    "### 2.2 Residualized R²\n",
    "\n",
    "**Define residualized R²**:\n",
    "$$R^2_{res} = 1 - \\frac{\\sum_i (\\tilde{Y}_i - \\hat{f}(T_i, W_i))^2}{\\sum_i (\\tilde{Y}_i - \\bar{\\tilde{Y}})^2}$$\n",
    "\n",
    "This evaluates how well $\\hat{f}$ predicts the causal component.\n",
    "\n",
    "### 2.3 Practical Implementation\n",
    "\n",
    "**Challenge**: Estimating $g(X)$ can overfit to noise.\n",
    "\n",
    "**Solution**: Use out-of-fold predictions:\n",
    "\n",
    "1. Split data into K folds\n",
    "2. For fold k:\n",
    "   - Train $\\hat{g}^{(-k)}$ on other folds\n",
    "   - Predict on fold k: $\\hat{g}^{(-k)}(X_i)$ for $i \\in \\text{fold } k$\n",
    "3. Compute residuals: $\\tilde{Y}_i = Y_i - \\hat{g}^{(-k)}(X_i)$\n",
    "\n",
    "### 2.4 Interpretation\n",
    "\n",
    "**High residualized R²**: Model captures treatment effect heterogeneity.\n",
    "\n",
    "**Low residualized R²**: Model misses treatment effects.\n",
    "\n",
    "**Negative residualized R²**: Model is worse than predicting $\\bar{\\tilde{Y}}$!\n",
    "\n",
    "```\n",
    "★ Key Result ──────────────────────────────────────────────────\n",
    "Original R²: Evaluates Var(Ŷ - Y) / Var(Y)\n",
    "Residualized R²: Evaluates Var(f̂ - f) / Var(f)\n",
    "\n",
    "The second is what we want for causal model evaluation.\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration {#numeric}\n",
    "\n",
    "### Recreate Data from Previous Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_causal_data(n=100000, n_nuisance=20, n_heter=10, seed=42):\n",
    "    \"\"\"\n",
    "    Generate data where nuisance features dominate prediction.\n",
    "    Same DGP as notebook 01.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X = np.random.normal(1, 10, (n, n_nuisance))\n",
    "    nuisance_coefs = np.random.uniform(-1, 1, (n_nuisance, 1))\n",
    "    \n",
    "    W = np.random.normal(1, 10, (n, n_heter))\n",
    "    heter_coefs = np.random.uniform(-1, 1, (n_heter, 1))\n",
    "    \n",
    "    T = np.random.normal(10, 2, (n, 1))\n",
    "    \n",
    "    g_X = 20 * X @ nuisance_coefs\n",
    "    f_T_W = T + T * (W @ heter_coefs)\n",
    "    \n",
    "    Y = np.random.normal(g_X + f_T_W, 0.1)\n",
    "    \n",
    "    X_cols = [f'X_{i}' for i in range(n_nuisance)]\n",
    "    W_cols = [f'W_{i}' for i in range(n_heter)]\n",
    "    \n",
    "    df = pd.DataFrame(X, columns=X_cols)\n",
    "    df = pd.concat([df, pd.DataFrame(W, columns=W_cols)], axis=1)\n",
    "    df['T'] = T.flatten()\n",
    "    df['Y'] = Y.flatten()\n",
    "    \n",
    "    return df, X_cols, W_cols\n",
    "\n",
    "# Generate data\n",
    "df, X_cols, W_cols = generate_causal_data(n=100000)\n",
    "train, test = train_test_split(df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Data: {len(df)} rows\")\n",
    "print(f\"Nuisance features X: {len(X_cols)}\")\n",
    "print(f\"Heterogeneity features W: {len(W_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train same models as before\n",
    "formula_m1 = \"Y ~ T * (\" + \" + \".join(X_cols) + \")\"\n",
    "formula_m2 = \"Y ~ T * (\" + \" + \".join(W_cols) + \")\"\n",
    "\n",
    "m1 = smf.ols(formula_m1, data=train).fit()\n",
    "m2 = smf.ols(formula_m2, data=train).fit()\n",
    "\n",
    "# Original R² (misleading)\n",
    "r2_m1_orig = r2_score(test['Y'], m1.predict(test))\n",
    "r2_m2_orig = r2_score(test['Y'], m2.predict(test))\n",
    "\n",
    "print(\"Original R² (MISLEADING):\")\n",
    "print(f\"  M1 (nuisance X): {r2_m1_orig:.4f}\")\n",
    "print(f\"  M2 (heterogeneity W): {r2_m2_orig:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Nuisance Function g(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_nuisance_oof(data, y_col, feature_cols, n_folds=5):\n",
    "    \"\"\"\n",
    "    Estimate nuisance function using out-of-fold predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Training data\n",
    "    y_col : str\n",
    "        Outcome column\n",
    "    feature_cols : list\n",
    "        Columns to use for nuisance estimation\n",
    "    n_folds : int\n",
    "        Number of CV folds\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Out-of-fold predictions\n",
    "    \"\"\"\n",
    "    X = data[feature_cols].values\n",
    "    y = data[y_col].values\n",
    "    \n",
    "    # Use simple OLS for nuisance (could use ML)\n",
    "    formula = f\"{y_col} ~ \" + \" + \".join(feature_cols)\n",
    "    model = smf.ols(formula, data=data).fit()\n",
    "    \n",
    "    return model.predict(data)\n",
    "\n",
    "# Estimate g(X) using ALL features (both X and W)\n",
    "all_features = X_cols + W_cols\n",
    "\n",
    "# For test set, we use model trained on train\n",
    "formula_nuisance = \"Y ~ \" + \" + \".join(all_features)\n",
    "nuisance_model = smf.ols(formula_nuisance, data=train).fit()\n",
    "\n",
    "# Get predictions on test\n",
    "g_hat_test = nuisance_model.predict(test)\n",
    "\n",
    "# Compute residualized outcome\n",
    "test_res = test.copy()\n",
    "test_res['Y_res'] = test['Y'] - g_hat_test\n",
    "# Add back mean for interpretability\n",
    "test_res['Y_res'] = test_res['Y_res'] + test['Y'].mean()\n",
    "\n",
    "print(f\"Nuisance model R² (train): {nuisance_model.rsquared:.4f}\")\n",
    "print(f\"Original Y variance: {test['Y'].var():.2f}\")\n",
    "print(f\"Residualized Y variance: {test_res['Y_res'].var():.2f}\")\n",
    "print(f\"\\nVariance reduction: {100*(1 - test_res['Y_res'].var()/test['Y'].var()):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with Residualized R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residualized R² for both models\n",
    "r2_m1_res = r2_score(test_res['Y_res'], m1.predict(test_res))\n",
    "r2_m2_res = r2_score(test_res['Y_res'], m2.predict(test_res))\n",
    "\n",
    "print(\"Residualized R² (CORRECT):\")\n",
    "print(f\"  M1 (nuisance X): {r2_m1_res:.4f}\")\n",
    "print(f\"  M2 (heterogeneity W): {r2_m2_res:.4f}\")\n",
    "print(\"\\n✅ Now M2 correctly shows as the better causal model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correction\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original R²\n",
    "ax = axes[0]\n",
    "models = ['M1 (X)', 'M2 (W)']\n",
    "r2_orig = [r2_m1_orig, r2_m2_orig]\n",
    "colors = [COLORS['red'], COLORS['green']]\n",
    "bars = ax.bar(models, r2_orig, color=colors, alpha=0.7)\n",
    "for bar, val in zip(bars, r2_orig):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=12)\n",
    "ax.set_ylabel('R²')\n",
    "ax.set_title('Original R² (MISLEADING)\\n❌ M1 looks better')\n",
    "ax.set_ylim(-0.5, 1.1)\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "# Residualized R²\n",
    "ax = axes[1]\n",
    "r2_res = [r2_m1_res, r2_m2_res]\n",
    "bars = ax.bar(models, r2_res, color=colors, alpha=0.7)\n",
    "for bar, val in zip(bars, r2_res):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, max(0, bar.get_height()) + 0.02,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=12)\n",
    "ax.set_ylabel('Residualized R²')\n",
    "ax.set_title('Residualized R² (CORRECT)\\n✅ M2 correctly better')\n",
    "ax.set_ylim(-0.5, 1.1)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation {#implementation}\n",
    "\n",
    "### Complete Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_causal_model(model, train_data, test_data, y_col, \n",
    "                           all_features, t_col='T'):\n",
    "    \"\"\"\n",
    "    Comprehensive causal model evaluation.\n",
    "    \n",
    "    Returns multiple metrics:\n",
    "    1. Original R² (potentially misleading)\n",
    "    2. Residualized R² (causal evaluation)\n",
    "    3. Cumulative gain AUC\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : fitted model\n",
    "        Causal model to evaluate\n",
    "    train_data : pd.DataFrame\n",
    "        Training data (for nuisance estimation)\n",
    "    test_data : pd.DataFrame\n",
    "        Test data\n",
    "    y_col : str\n",
    "        Outcome column\n",
    "    all_features : list\n",
    "        All features (for nuisance estimation)\n",
    "    t_col : str\n",
    "        Treatment column\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Multiple evaluation metrics\n",
    "    \"\"\"\n",
    "    # 1. Original R²\n",
    "    r2_original = r2_score(test_data[y_col], model.predict(test_data))\n",
    "    \n",
    "    # 2. Residualized R²\n",
    "    # Estimate nuisance\n",
    "    formula_nuisance = f\"{y_col} ~ \" + \" + \".join(all_features)\n",
    "    nuisance_model = smf.ols(formula_nuisance, data=train_data).fit()\n",
    "    g_hat = nuisance_model.predict(test_data)\n",
    "    \n",
    "    y_res = test_data[y_col] - g_hat + test_data[y_col].mean()\n",
    "    r2_residualized = r2_score(y_res, model.predict(test_data))\n",
    "    \n",
    "    # 3. Cumulative gain AUC\n",
    "    test_pred = test_data.copy()\n",
    "    test_pred['cate'] = model.predict(test_data) - model.predict(\n",
    "        test_data.assign(**{t_col: test_data[t_col] - 1})\n",
    "    )\n",
    "    \n",
    "    def compute_elasticity(data, y, t):\n",
    "        cov = np.sum((data[t] - data[t].mean()) * (data[y] - data[y].mean()))\n",
    "        var = np.sum((data[t] - data[t].mean())**2)\n",
    "        return cov / var\n",
    "    \n",
    "    ordered = test_pred.sort_values('cate', ascending=False).reset_index(drop=True)\n",
    "    n = len(ordered)\n",
    "    steps = 100\n",
    "    n_rows = list(range(30, n, n // steps)) + [n]\n",
    "    \n",
    "    cum_elast = []\n",
    "    for rows in n_rows:\n",
    "        subset = ordered.head(rows)\n",
    "        elast = compute_elasticity(subset, y_col, t_col)\n",
    "        cum_elast.append(elast * (rows / n))\n",
    "    \n",
    "    pct = np.array(n_rows) / n\n",
    "    cum_gain_auc = np.trapz(cum_elast, pct)\n",
    "    \n",
    "    return {\n",
    "        'r2_original': r2_original,\n",
    "        'r2_residualized': r2_residualized,\n",
    "        'cumulative_gain_auc': cum_gain_auc\n",
    "    }\n",
    "\n",
    "# Evaluate both models\n",
    "eval_m1 = evaluate_causal_model(m1, train, test, 'Y', all_features)\n",
    "eval_m2 = evaluate_causal_model(m2, train, test, 'Y', all_features)\n",
    "\n",
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Original R²', 'Residualized R²', 'Cum. Gain AUC', 'Correct for CATE?'],\n",
    "    'M1 (Nuisance X)': [\n",
    "        f\"{eval_m1['r2_original']:.4f}\",\n",
    "        f\"{eval_m1['r2_residualized']:.4f}\",\n",
    "        f\"{eval_m1['cumulative_gain_auc']:.4f}\",\n",
    "        '❌ No'\n",
    "    ],\n",
    "    'M2 (Heterogeneity W)': [\n",
    "        f\"{eval_m2['r2_original']:.4f}\",\n",
    "        f\"{eval_m2['r2_residualized']:.4f}\",\n",
    "        f\"{eval_m2['cumulative_gain_auc']:.4f}\",\n",
    "        '✅ Yes'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nComprehensive Model Comparison:\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity to Nuisance Estimation Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we use a poor nuisance estimator?\n",
    "print(\"Sensitivity Analysis: Quality of Nuisance Estimation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Good nuisance (all features)\n",
    "formula_good = \"Y ~ \" + \" + \".join(all_features)\n",
    "nuisance_good = smf.ols(formula_good, data=train).fit()\n",
    "y_res_good = test['Y'] - nuisance_good.predict(test)\n",
    "print(f\"Good nuisance (all features): R² = {nuisance_good.rsquared:.4f}\")\n",
    "\n",
    "# Medium nuisance (only X)\n",
    "formula_medium = \"Y ~ \" + \" + \".join(X_cols)\n",
    "nuisance_medium = smf.ols(formula_medium, data=train).fit()\n",
    "y_res_medium = test['Y'] - nuisance_medium.predict(test)\n",
    "print(f\"Medium nuisance (only X): R² = {nuisance_medium.rsquared:.4f}\")\n",
    "\n",
    "# Poor nuisance (only first 5 features)\n",
    "formula_poor = \"Y ~ \" + \" + \".join(X_cols[:5])\n",
    "nuisance_poor = smf.ols(formula_poor, data=train).fit()\n",
    "y_res_poor = test['Y'] - nuisance_poor.predict(test)\n",
    "print(f\"Poor nuisance (first 5 X): R² = {nuisance_poor.rsquared:.4f}\")\n",
    "\n",
    "# Evaluate M2 with different nuisance estimators\n",
    "print(f\"\\nResidual R² for M2 (correct model):\")\n",
    "print(f\"  Good nuisance: {r2_score(y_res_good, m2.predict(test)):.4f}\")\n",
    "print(f\"  Medium nuisance: {r2_score(y_res_medium, m2.predict(test)):.4f}\")\n",
    "print(f\"  Poor nuisance: {r2_score(y_res_poor, m2.predict(test)):.4f}\")\n",
    "\n",
    "print(f\"\\nResidual R² for M1 (wrong model):\")\n",
    "print(f\"  Good nuisance: {r2_score(y_res_good, m1.predict(test)):.4f}\")\n",
    "print(f\"  Medium nuisance: {r2_score(y_res_medium, m1.predict(test)):.4f}\")\n",
    "print(f\"  Poor nuisance: {r2_score(y_res_poor, m1.predict(test)):.4f}\")\n",
    "\n",
    "print(\"\\n✅ Even with poor nuisance, M2 > M1 in residualized R²!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "★ Key Takeaway ────────────────────────────────────────────────\n",
    "Residualized Outcome Evaluation:\n",
    "\n",
    "1. **Removes nuisance** from evaluation\n",
    "2. **R² becomes meaningful** for causal models\n",
    "3. **Robust to nuisance quality** (wrong model still loses)\n",
    "4. **Complements cumulative gain** curves\n",
    "\n",
    "Best practice: Use BOTH residualized R² AND cumulative gain!\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix {#interview}\n",
    "\n",
    "### Q1: Why does residualizing the outcome fix the R² problem?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Original problem**:\n",
    "$$Y = g(X) + f(T, W) + \\epsilon$$\n",
    "\n",
    "R² rewards predicting $g(X)$ (large) while ignoring $f(T, W)$ (small).\n",
    "\n",
    "**After residualization**:\n",
    "$$\\tilde{Y} = Y - \\hat{g}(X) \\approx f(T, W) + \\epsilon$$\n",
    "\n",
    "Now there's no $g(X)$ to exploit!\n",
    "\n",
    "**Mechanics**:\n",
    "1. A model that only predicts $g(X)$ will have:\n",
    "   - Original R² high (predicts most of Y variance)\n",
    "   - Residualized R² ≈ 0 (nothing left to predict)\n",
    "\n",
    "2. A model that predicts $f(T, W)$ will have:\n",
    "   - Original R² low (small part of Y variance)\n",
    "   - Residualized R² high (captures all of $\\tilde{Y}$)\n",
    "\n",
    "**Analogy**: Like a race where one runner gets a 10-minute head start.\n",
    "Residualization removes the head start, making it a fair competition.\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q2: How should you estimate the nuisance function?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "1. **Include all baseline predictors**\n",
    "   - Both X (nuisance) and W (heterogeneity)\n",
    "   - Don't include treatment T\n",
    "\n",
    "2. **Use out-of-fold predictions**\n",
    "   - Prevents overfitting to noise\n",
    "   - Same principle as DML cross-fitting\n",
    "\n",
    "3. **Flexible model**\n",
    "   - OLS if relationships are linear\n",
    "   - Random Forest for nonlinearities\n",
    "   - Don't need to be perfect, just good enough\n",
    "\n",
    "**Code pattern**:\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Estimate g(X) with out-of-fold predictions\n",
    "g_hat = cross_val_predict(\n",
    "    RandomForestRegressor(),\n",
    "    X=data[all_features],\n",
    "    y=data['Y'],\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Residualize\n",
    "Y_res = data['Y'] - g_hat\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q3: What if the nuisance estimation is poor?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Impact of poor nuisance estimation**:\n",
    "\n",
    "If $\\hat{g}(X) \\neq g(X)$, then:\n",
    "$$\\tilde{Y} = f(T, W) + \\epsilon + \\underbrace{(g(X) - \\hat{g}(X))}_{\\text{nuisance error}}$$\n",
    "\n",
    "**Consequences**:\n",
    "1. $\\tilde{Y}$ has more variance (harder to predict)\n",
    "2. Residualized R² will be lower for all models\n",
    "3. BUT ranking is preserved!\n",
    "\n",
    "**Why ranking is robust**:\n",
    "- Nuisance error is the same for all causal models being compared\n",
    "- It's like adding the same noise to everyone\n",
    "- Relative performance unchanged\n",
    "\n",
    "**Caveat**: Very poor nuisance can:\n",
    "- Make all R² negative (worse than mean prediction)\n",
    "- Reduce power to distinguish models\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q4: How does residualized R² relate to R-loss in DML?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**R-loss (from R-learner)**:\n",
    "$$L_R(\\tau) = \\sum_i (\\tilde{Y}_i - \\tau(X_i) \\cdot \\tilde{T}_i)^2$$\n",
    "\n",
    "where:\n",
    "- $\\tilde{Y} = Y - \\hat{g}(X)$ (residualized outcome)\n",
    "- $\\tilde{T} = T - \\hat{m}(X)$ (residualized treatment)\n",
    "\n",
    "**Residualized R²** (this notebook):\n",
    "$$R^2_{res} = 1 - \\frac{\\sum(\\tilde{Y} - \\hat{Y})^2}{\\sum(\\tilde{Y} - \\bar{\\tilde{Y}})^2}$$\n",
    "\n",
    "**Connection**:\n",
    "- Both remove nuisance from evaluation\n",
    "- R-loss also residualizes T (doubly robust)\n",
    "- R² is easier to compute and interpret\n",
    "- R-loss is better for training CATE models\n",
    "\n",
    "**When to use each**:\n",
    "- **R-loss**: Training CATE models (e.g., R-learner)\n",
    "- **Residualized R²**: Quick model comparison\n",
    "- **Cumulative gain**: Ranking evaluation\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q5: What are the limitations of residualized R²?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Limitations**:\n",
    "\n",
    "1. **Depends on nuisance quality**\n",
    "   - Poor nuisance → noisy evaluation\n",
    "   - Requires good baseline predictors\n",
    "\n",
    "2. **Additive assumption**\n",
    "   - Assumes $Y = g(X) + f(T, W)$ structure\n",
    "   - May not hold if g(X) interacts with T\n",
    "\n",
    "3. **Scale sensitivity**\n",
    "   - R² depends on outcome variance\n",
    "   - Hard to compare across datasets\n",
    "\n",
    "4. **Doesn't evaluate CATE directly**\n",
    "   - Still evaluates outcome prediction\n",
    "   - Just on a \"fairer\" outcome\n",
    "\n",
    "**Better alternatives for specific use cases**:\n",
    "\n",
    "| Use Case | Better Metric |\n",
    "|----------|---------------|\n",
    "| Targeting/ranking | Cumulative gain curves |\n",
    "| CATE accuracy | T-learner MSE (if RCT) |\n",
    "| Treatment selection | Policy value |\n",
    "| Calibration | Calibration plots |\n",
    "\n",
    "**Best practice**: Use multiple metrics, not just residualized R²!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References {#references}\n",
    "\n",
    "[^1]: Nie, X., & Wager, S. (2021). Quasi-Oracle Estimation of Heterogeneous \n",
    "      Treatment Effects. *Biometrika*.\n",
    "\n",
    "[^2]: Chernozhukov, V., et al. (2018). Double/Debiased Machine Learning for \n",
    "      Treatment and Structural Parameters. *Econometrics Journal*.\n",
    "\n",
    "[^3]: Kennedy, E. H. (2020). Towards Optimal Doubly Robust Estimation of \n",
    "      Heterogeneous Causal Effects. *arXiv preprint*.\n",
    "\n",
    "[^4]: Facure, M. (2022). *Causal Inference for the Brave and True*, Appendix: \n",
    "      Prediction Metrics for Causal Models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
