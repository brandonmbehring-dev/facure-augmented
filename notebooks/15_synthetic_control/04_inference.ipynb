{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 15.4 Inference for Synthetic Control\n",
    "\n",
    "**Chapter**: 15 - Synthetic Control  \n",
    "**Section**: 4 - Placebo Tests and Fisher's Exact p-value  \n",
    "**Facure Source**: 15-Synthetic-Control.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-15\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Facure's Intuition](#1-facures-intuition)\n",
    "   - 1.1 [The Inference Problem](#11-the-inference-problem)\n",
    "   - 1.2 [Fisher's Exact Test](#12-fishers-exact-test)\n",
    "2. [Formal Treatment](#2-formal-treatment)\n",
    "   - 2.1 [Placebo Distribution](#21-placebo-distribution)\n",
    "   - 2.2 [P-value Calculation](#22-p-value-calculation)\n",
    "3. [Numeric Demonstration](#3-numeric-demonstration)\n",
    "   - 3.1 [Running Placebos for All States](#31-running-placebos-for-all-states)\n",
    "   - 3.2 [Computing the P-value](#32-computing-the-p-value)\n",
    "4. [Implementation](#4-implementation)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports via common module\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from facure_augment.common import (\n",
    "    np, pd, plt, sm, smf,\n",
    "    load_facure_data,\n",
    "    set_notebook_style,\n",
    "    create_tufte_figure,\n",
    "    TUFTE_PALETTE,\n",
    ")\n",
    "\n",
    "from scipy.optimize import fmin_slsqp\n",
    "from functools import partial\n",
    "\n",
    "set_notebook_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions (from previous notebooks)\n",
    "def loss_w(W, X, y):\n",
    "    \"\"\"RMSE loss for synthetic control.\"\"\"\n",
    "    return np.sqrt(np.mean((y - X.dot(W))**2))\n",
    "\n",
    "def get_weights(X, y):\n",
    "    \"\"\"Find optimal synthetic control weights.\"\"\"\n",
    "    n_units = X.shape[1]\n",
    "    w_init = np.ones(n_units) / n_units\n",
    "    \n",
    "    weights = fmin_slsqp(\n",
    "        partial(loss_w, X=X, y=y),\n",
    "        w_init,\n",
    "        f_eqcons=lambda w: np.sum(w) - 1,\n",
    "        bounds=[(0, 1)] * n_units,\n",
    "        disp=False\n",
    "    )\n",
    "    return weights\n",
    "\n",
    "\n",
    "def synthetic_control(state: int, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estimate synthetic control for a given state.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    state : int\n",
    "        State ID to treat as treated unit\n",
    "    data : pd.DataFrame\n",
    "        Panel data with columns: state, year, cigsale, after_treatment\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns: state, year, cigsale, synthetic, gap\n",
    "    \"\"\"\n",
    "    features = ['cigsale', 'retprice']\n",
    "    \n",
    "    # Pivot pre-treatment data\n",
    "    inverted = (data.query('~after_treatment')\n",
    "                .pivot(index='state', columns='year')[features]\n",
    "                .T)\n",
    "    \n",
    "    y = inverted[state].values  # Treated\n",
    "    X = inverted.drop(columns=state).values  # Donors\n",
    "    \n",
    "    # Get weights\n",
    "    weights = get_weights(X, y)\n",
    "    \n",
    "    # Build synthetic for all periods\n",
    "    synthetic = (data.query(f'state != {state}')\n",
    "                 .pivot(index='year', columns='state')['cigsale']\n",
    "                 .values.dot(weights))\n",
    "    \n",
    "    result = (data.query(f'state == {state}')\n",
    "              [['state', 'year', 'cigsale', 'after_treatment']]\n",
    "              .copy()\n",
    "              .assign(synthetic=synthetic,\n",
    "                      gap=lambda x: x['cigsale'] - x['synthetic']))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition\n",
    "\n",
    "> **Interview Relevance**: \"How do you do inference for synthetic control?\" is a common advanced question. The permutation-based approach is elegant and avoids parametric assumptions.\n",
    "\n",
    "### 1.1 The Inference Problem\n",
    "\n",
    "**Standard regression gives us SEs, but synthetic control doesn't**:\n",
    "\n",
    "- No closed-form variance estimator\n",
    "- Only one treated unit (N=1)\n",
    "- Can't use large-sample asymptotics\n",
    "\n",
    "**The solution**: Fisher's Exact Test via permutation.\n",
    "\n",
    "### 1.2 Fisher's Exact Test\n",
    "\n",
    "**Core idea**: If the treatment had no effect, California would look like any other state.\n",
    "\n",
    "**Procedure**:\n",
    "1. For each control state $j$, pretend it was treated\n",
    "2. Build a synthetic control for state $j$ using other states (excluding California)\n",
    "3. Compute the \"placebo\" treatment effect for state $j$\n",
    "4. Compare California's effect to the distribution of placebo effects\n",
    "\n",
    "**P-value**: Proportion of placebo effects as extreme as California's\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- This is exact, not asymptotic inference\n",
    "- Works with N=1 treated unit\n",
    "- No distributional assumptions\n",
    "- But requires all states to be \"exchangeable\" under null\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment\n",
    "\n",
    "### 2.1 Placebo Distribution\n",
    "\n",
    "For each control state $j \\in \\{2, \\ldots, J+1\\}$:\n",
    "\n",
    "1. **Synthetic control**: Build $\\hat{Y}_{jt}^{\\text{synth}}$ using donor pool excluding $j$ and California\n",
    "\n",
    "2. **Placebo gap**: $\\hat{\\tau}_{jt}^{\\text{placebo}} = Y_{jt} - \\hat{Y}_{jt}^{\\text{synth}}$\n",
    "\n",
    "3. **Summary statistic**: Average post-treatment gap or RMSPE ratio\n",
    "\n",
    "### 2.2 P-value Calculation\n",
    "\n",
    "**Method 1: Post-treatment gap comparison**\n",
    "\n",
    "$$\n",
    "\\text{p-value} = \\frac{1}{J} \\sum_{j=2}^{J+1} \\mathbf{1}\\{|\\bar{\\tau}_j^{\\text{placebo}}| \\geq |\\bar{\\tau}_1^{\\text{actual}}|\\}\n",
    "$$\n",
    "\n",
    "**Method 2: RMSPE ratio (accounts for pre-treatment fit)**\n",
    "\n",
    "$$\n",
    "\\text{Ratio}_j = \\frac{\\text{RMSPE}_{\\text{post},j}}{\\text{RMSPE}_{\\text{pre},j}}\n",
    "$$\n",
    "\n",
    "P-value = proportion of placebo ratios ≥ California's ratio.\n",
    "\n",
    "**Filtering**: Exclude placebos with poor pre-treatment fit (RMSPE > threshold).\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "**Why filter on pre-treatment fit?**\n",
    "\n",
    "- States that can't be synthesized well shouldn't count\n",
    "- Large placebo \"effects\" may just be bad counterfactuals\n",
    "- RMSPE ratio controls for this: scales post by pre\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration\n",
    "\n",
    "### 3.1 Running Placebos for All States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "cigar = load_facure_data('smoking.csv')\n",
    "cigar = cigar.drop(columns=['lnincome', 'beer', 'age15to24'], errors='ignore')\n",
    "\n",
    "# Get all states (California = 3)\n",
    "all_states = sorted(cigar['state'].unique())\n",
    "california = 3\n",
    "\n",
    "print(f\"Total states: {len(all_states)}\")\n",
    "print(f\"California state ID: {california}\")\n",
    "print(f\"Control states: {len(all_states) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run synthetic control for all states\n",
    "# Note: In production, use joblib Parallel for speed\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Running synthetic control for each state...\")\n",
    "for state in all_states:\n",
    "    try:\n",
    "        result = synthetic_control(state, cigar)\n",
    "        results[state] = result\n",
    "    except Exception as e:\n",
    "        print(f\"  State {state}: Failed ({str(e)[:50]})\")\n",
    "\n",
    "print(f\"\\nSuccessfully computed synthetic controls for {len(results)} states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# Compute pre and post treatment fit metrics\nmetrics = []\n\nfor state, df in results.items():\n    pre = df.query('~after_treatment')\n    post = df.query('after_treatment')\n\n    pre_rmse = np.sqrt(np.mean(pre['gap']**2))\n    post_rmse = np.sqrt(np.mean(post['gap']**2))\n    avg_post_gap = post['gap'].mean()\n\n    # RMSPE ratio (cap at 100 to avoid infinity issues)\n    if pre_rmse > 0.001:  # Avoid division by near-zero\n        ratio = min(post_rmse / pre_rmse, 100.0)\n    else:\n        ratio = 100.0  # Cap at maximum if pre-fit is essentially perfect\n\n    metrics.append({\n        'state': state,\n        'is_california': state == california,\n        'pre_rmse': pre_rmse,\n        'post_rmse': post_rmse,\n        'avg_post_gap': avg_post_gap,\n        'rmspe_ratio': ratio\n    })\n\nmetrics_df = pd.DataFrame(metrics)\n\n# Display California's metrics\ncalif_metrics = metrics_df.query('is_california').iloc[0]\nprint(\"CALIFORNIA METRICS:\")\nprint(\"=\" * 50)\nprint(f\"Pre-treatment RMSE:  {calif_metrics['pre_rmse']:.2f}\")\nprint(f\"Post-treatment RMSE: {calif_metrics['post_rmse']:.2f}\")\nprint(f\"Avg post-treatment gap: {calif_metrics['avg_post_gap']:.2f}\")\nprint(f\"RMSPE ratio: {calif_metrics['rmspe_ratio']:.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all placebo gaps\n",
    "fig, ax = create_tufte_figure(figsize=(12, 6))\n",
    "\n",
    "# Plot each state's gap over time\n",
    "for state, df in results.items():\n",
    "    if state == california:\n",
    "        continue  # Plot California last\n",
    "    ax.plot(df['year'], df['gap'], color=TUFTE_PALETTE['secondary'], \n",
    "            alpha=0.3, linewidth=1)\n",
    "\n",
    "# Plot California prominently\n",
    "calif_df = results[california]\n",
    "ax.plot(calif_df['year'], calif_df['gap'], 'o-', \n",
    "        color=TUFTE_PALETTE['treatment'], linewidth=3, markersize=5,\n",
    "        label='California (Actual Treatment)')\n",
    "\n",
    "ax.axvline(1988, color=TUFTE_PALETTE['effect'], linestyle=':', linewidth=2, label='Proposition 99')\n",
    "ax.axhline(0, color=TUFTE_PALETTE['spine'], linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Gap (Actual - Synthetic)')\n",
    "ax.set_title('California vs Placebo States')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCalifornia's gap diverges notably from the placebo distribution after 1988\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 3.2 Computing the P-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Simple p-value (all states)\n",
    "calif_effect = calif_metrics['avg_post_gap']\n",
    "\n",
    "# Count how many placebos have effects as extreme as California\n",
    "# California had negative effect, so count those more negative\n",
    "more_extreme = metrics_df['avg_post_gap'] <= calif_effect\n",
    "pval_simple = more_extreme.mean()\n",
    "\n",
    "print(\"METHOD 1: Simple P-value (all states)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"California's average post-treatment gap: {calif_effect:.2f}\")\n",
    "print(f\"States with more extreme effect: {more_extreme.sum()} of {len(metrics_df)}\")\n",
    "print(f\"P-value: {pval_simple:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Filter on pre-treatment fit\n",
    "# Exclude states with poor pre-treatment fit (can't synthesize well)\n",
    "\n",
    "pre_rmse_threshold = 20  # Facure uses RMSE threshold\n",
    "\n",
    "# Filter to states with good pre-treatment fit\n",
    "good_fit = metrics_df[metrics_df['pre_rmse'] <= pre_rmse_threshold]\n",
    "\n",
    "calif_effect_filtered = good_fit.query('is_california')['avg_post_gap'].values[0]\n",
    "more_extreme_filtered = good_fit['avg_post_gap'] <= calif_effect_filtered\n",
    "pval_filtered = more_extreme_filtered.mean()\n",
    "\n",
    "print(\"METHOD 2: Filtered P-value (pre-RMSE ≤ 20)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"States with good pre-treatment fit: {len(good_fit)}\")\n",
    "print(f\"States with more extreme effect: {more_extreme_filtered.sum()}\")\n",
    "print(f\"P-value: {pval_filtered:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: RMSPE ratio (accounts for pre-treatment fit)\n",
    "calif_ratio = calif_metrics['rmspe_ratio']\n",
    "\n",
    "# Count how many have higher ratio than California\n",
    "higher_ratio = metrics_df['rmspe_ratio'] >= calif_ratio\n",
    "pval_ratio = higher_ratio.mean()\n",
    "\n",
    "print(\"METHOD 3: RMSPE Ratio P-value\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"California's RMSPE ratio: {calif_ratio:.2f}\")\n",
    "print(f\"States with higher ratio: {higher_ratio.sum()} of {len(metrics_df)}\")\n",
    "print(f\"P-value: {pval_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the RMSPE ratio distribution\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Distribution of RMSPE ratios\n",
    "ax = axes[0]\n",
    "ratios = metrics_df['rmspe_ratio'].values\n",
    "ax.hist(ratios[ratios < 50], bins=20, color=TUFTE_PALETTE['secondary'], \n",
    "        edgecolor='white', alpha=0.7)\n",
    "ax.axvline(calif_ratio, color=TUFTE_PALETTE['treatment'], linewidth=3, \n",
    "           linestyle='--', label=f'California ({calif_ratio:.1f})')\n",
    "ax.set_xlabel('RMSPE Ratio (Post/Pre)')\n",
    "ax.set_ylabel('Number of States')\n",
    "ax.set_title('(a) Distribution of RMSPE Ratios')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Panel 2: Ranked ratios\n",
    "ax = axes[1]\n",
    "sorted_df = metrics_df.sort_values('rmspe_ratio', ascending=False).reset_index(drop=True)\n",
    "colors = [TUFTE_PALETTE['treatment'] if s == california else TUFTE_PALETTE['secondary'] \n",
    "          for s in sorted_df['state']]\n",
    "ax.barh(range(len(sorted_df)), sorted_df['rmspe_ratio'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('RMSPE Ratio')\n",
    "ax.set_ylabel('State Rank')\n",
    "ax.set_title('(b) States Ranked by RMSPE Ratio')\n",
    "ax.set_xlim(0, sorted_df['rmspe_ratio'].quantile(0.95) * 1.1)  # Trim outliers\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find California's rank\n",
    "calif_rank = (sorted_df['state'] == california).idxmax() + 1\n",
    "print(f\"\\nCalifornia ranks #{calif_rank} out of {len(sorted_df)} states\")\n",
    "print(f\"Only {calif_rank - 1} states have higher RMSPE ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# Summary of results\nprint(\"=\"*60)\nprint(\"STATISTICAL SUMMARY: Proposition 99 Effect\")\nprint(\"=\"*60)\nprint(f\"\\nCalifornia's average post-treatment gap: {calif_effect:.2f} packs/capita\")\nprint(f\"\\nP-values across methods:\")\nprint(f\"  Simple (all states):      {pval_simple:.3f}\")\nprint(f\"  Filtered (good fit only): {pval_filtered:.3f}\")\nprint(f\"  RMSPE ratio:              {pval_ratio:.3f}\")\nprint(f\"\\nConclusion: Effect is statistically detected at 5% level\")\nprint(f\"            (p = {min(pval_simple, pval_filtered, pval_ratio):.2f})\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "★ Insight ─────────────────────────────────────\n",
    "**Inference conclusions:**\n",
    "\n",
    "1. California's effect is in the tail of the placebo distribution\n",
    "2. P-value ≈ 0.03-0.05 depending on method\n",
    "3. Proposition 99 had a statistically significant effect\n",
    "4. RMSPE ratio is preferred (accounts for pre-treatment fit quality)\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": "---\n\n## 4. Implementation\n\n**Production implementation with parallel processing**:\n\n```python\nfrom joblib import Parallel, delayed\nfrom functools import partial\n\ndef placebo_test(data: pd.DataFrame, \n                 treated_state: int,\n                 n_jobs: int = -1) -> dict:\n    \"\"\"\n    Run placebo tests for all states and compute p-value.\n    \n    Parameters\n    ----------\n    data : pd.DataFrame\n        Panel data with state, year, outcome columns\n    treated_state : int\n        The actually treated state ID\n    n_jobs : int\n        Number of parallel jobs (-1 for all cores)\n        \n    Returns\n    -------\n    dict\n        Contains 'p_value', 'treated_effect', 'placebo_effects', 'metrics'\n    \"\"\"\n    all_states = sorted(data['state'].unique())\n    \n    # Run synthetic control for all states in parallel\n    sc_fn = partial(synthetic_control, data=data)\n    results = Parallel(n_jobs=n_jobs)(\n        delayed(sc_fn)(state) for state in all_states\n    )\n    \n    # Compute metrics\n    metrics = []\n    for state, result in zip(all_states, results):\n        pre = result.query('~after_treatment')\n        post = result.query('after_treatment')\n        \n        pre_rmse = np.sqrt(np.mean(pre['gap']**2))\n        post_rmse = np.sqrt(np.mean(post['gap']**2))\n        \n        # Cap ratio to avoid infinity\n        if pre_rmse > 0.001:\n            ratio = min(post_rmse / pre_rmse, 100.0)\n        else:\n            ratio = 100.0\n        \n        metrics.append({\n            'state': state,\n            'avg_post_gap': post['gap'].mean(),\n            'rmspe_ratio': ratio\n        })\n    \n    metrics_df = pd.DataFrame(metrics)\n    \n    # Compute p-value (RMSPE ratio method)\n    treated_ratio = metrics_df.query(f'state == {treated_state}')['rmspe_ratio'].values[0]\n    p_value = (metrics_df['rmspe_ratio'] >= treated_ratio).mean()\n    \n    return {\n        'p_value': p_value,\n        'treated_effect': metrics_df.query(f'state == {treated_state}')['avg_post_gap'].values[0],\n        'treated_ratio': treated_ratio,\n        'metrics': metrics_df\n    }\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1 (Meta E5, DS)**: *\"How do you do inference for synthetic control with only one treated unit?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Fisher's Exact Test (Permutation Approach)**:\n",
    "\n",
    "1. **Null hypothesis**: Treatment had no effect (California is exchangeable with other states)\n",
    "\n",
    "2. **Placebo procedure**:\n",
    "   - For each control state $j$, pretend it was treated\n",
    "   - Build synthetic control using remaining states\n",
    "   - Compute \"placebo\" treatment effect\n",
    "\n",
    "3. **P-value calculation**:\n",
    "   $$\\text{p-value} = \\frac{\\#\\{\\text{placebo effects} \\geq \\text{actual effect}\\}}{\\text{total states}}$$\n",
    "\n",
    "4. **Refinements**:\n",
    "   - Use RMSPE ratio to account for pre-treatment fit\n",
    "   - Filter out states with poor pre-treatment fit\n",
    "\n",
    "**Key advantages**:\n",
    "- Exact, not asymptotic\n",
    "- No distributional assumptions\n",
    "- Works with N=1\n",
    "\n",
    "**Limitation**: Requires exchangeability assumption under null.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q2 (Google L5, Quant)**: *\"Why use the RMSPE ratio instead of just the post-treatment gap?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**The problem with raw gaps**:\n",
    "\n",
    "A large post-treatment gap could mean:\n",
    "1. Large treatment effect (what we want to detect)\n",
    "2. Poor synthetic fit (spurious result)\n",
    "\n",
    "**The RMSPE ratio solution**:\n",
    "\n",
    "$$\n",
    "\\text{Ratio} = \\frac{\\text{RMSPE}_{\\text{post}}}{\\text{RMSPE}_{\\text{pre}}}\n",
    "$$\n",
    "\n",
    "**Interpretation**:\n",
    "- If pre-fit is bad, denominator is large → ratio is smaller\n",
    "- If pre-fit is good but post-gap is large → ratio is large\n",
    "- Controls for quality of synthetic\n",
    "\n",
    "**Example**:\n",
    "- State A: pre-RMSE=5, post-RMSE=20 → ratio=4\n",
    "- State B: pre-RMSE=50, post-RMSE=100 → ratio=2\n",
    "\n",
    "State A has better evidence of treatment effect despite smaller raw post-RMSE.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q3 (Amazon L6, Econ)**: *\"What's the intuition behind filtering states with poor pre-treatment fit?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**The problem**:\n",
    "\n",
    "Some states cannot be well-synthesized:\n",
    "- Too different from donor pool\n",
    "- Idiosyncratic trends\n",
    "- Insufficient donors\n",
    "\n",
    "**Why filtering helps**:\n",
    "\n",
    "1. **Garbage in, garbage out**: Poor pre-fit → unreliable post-treatment \"effect\"\n",
    "\n",
    "2. **Apples to apples**: Only compare California to states that *could* be matched\n",
    "\n",
    "3. **Conservative inference**: Removing bad placebos typically raises p-value (fewer \"extreme\" results)\n",
    "\n",
    "**The tradeoff**:\n",
    "\n",
    "- Filtering reduces sample size for permutation test\n",
    "- Too aggressive filtering → lose power\n",
    "- Threshold choice is somewhat arbitrary\n",
    "\n",
    "**Best practice**:\n",
    "- Report both filtered and unfiltered results\n",
    "- Use RMSPE ratio as primary (natural adjustment)\n",
    "- Filtering is a robustness check\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q4 (Google L5, DS)**: *\"With 39 states, what's the minimum possible p-value?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Minimum p-value = 1/N** where N = number of states.\n",
    "\n",
    "With 39 states: minimum p-value = 1/39 ≈ **0.026**\n",
    "\n",
    "**Why?**\n",
    "\n",
    "- P-value = proportion of states with more extreme effect\n",
    "- At minimum, only the treated state itself is \"as extreme\"\n",
    "- So p-value ≥ 1/39 always\n",
    "\n",
    "**Implications**:\n",
    "\n",
    "1. Can never achieve p < 0.026 with 39 states\n",
    "2. Need more states for smaller p-values\n",
    "3. With few units, precision of inference is limited\n",
    "\n",
    "**Comparison to regression**:\n",
    "- Regression p-values can be arbitrarily small\n",
    "- Permutation p-values bounded by 1/N\n",
    "- This reflects fundamental uncertainty with few units\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 15.\n",
    "\n",
    "[^2]: Abadie, A., Diamond, A., and Hainmueller, J. (2010). Synthetic Control Methods for Comparative Case Studies. *JASA*, 105(490), 493-505.\n",
    "\n",
    "[^3]: Abadie, A. (2021). Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects. *Journal of Economic Literature*, 59(2), 391-425.\n",
    "\n",
    "[^4]: Fisher, R.A. (1935). *The Design of Experiments*. Oliver & Boyd. (Origin of exact permutation tests)\n",
    "\n",
    "---\n",
    "\n",
    "**Precision Improvement:**\n",
    "- You said: \"Build inference notebook\"\n",
    "- Concise: \"Build 04_inference.ipynb\"\n",
    "- Precise: `/facure_augment 15.4 --fisher-exact --placebo-permutation`\n",
    "- Pattern: [build] [target] [content-flags]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}