{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.1 All You Need is Regression\n",
    "\n",
    "**Chapter**: 5 - The Unreasonable Effectiveness of Linear Regression  \n",
    "**Section**: 1 - All You Need is Regression  \n",
    "**Facure Source**: 05-The-Unreasonable-Effectiveness-of-Linear-Regression.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-09\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Facure's Intuition](#1-facures-intuition)\n",
    "   - 1.1 [Potential Outcomes Recap](#11-potential-outcomes-recap)\n",
    "   - 1.2 [From Means to Regression](#12-from-means-to-regression)\n",
    "2. [Formal Treatment](#2-formal-treatment)\n",
    "   - 2.1 [Regression as Conditional Expectation](#21-regression-as-conditional-expectation)\n",
    "   - 2.2 [Why Regression Works for RCTs](#22-why-regression-works-for-rcts)\n",
    "3. [Numeric Demonstration](#3-numeric-demonstration)\n",
    "   - 3.1 [Online Classroom Example](#31-online-classroom-example)\n",
    "   - 3.2 [Verifying Coefficient = Difference in Means](#32-verifying-coefficient--difference-in-means)\n",
    "4. [Implementation](#4-implementation)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports via common module\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from facure_augment.common import (\n",
    "    np, pd, plt, sm,\n",
    "    load_facure_data,\n",
    "    set_notebook_style,\n",
    "    ols_summary_table,\n",
    "    create_tufte_figure,\n",
    "    TUFTE_PALETTE,\n",
    ")\n",
    "\n",
    "set_notebook_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition\n",
    "\n",
    "> **Interview Relevance**: Understanding regression as a causal estimator is foundational. Interviewers test whether you understand *when* regression gives causal estimates vs. mere associations.\n",
    "\n",
    "### 1.1 Potential Outcomes Recap\n",
    "\n",
    "As Facure reminds us, each individual has two **potential outcomes**:\n",
    "\n",
    "- $Y_0$: outcome without treatment\n",
    "- $Y_1$: outcome with treatment\n",
    "\n",
    "The **observed outcome** depends on treatment assignment:\n",
    "\n",
    "$$Y_i = Y_{0i}(1-T_i) + Y_{1i} T_i = Y_{0i} + T_i(Y_{1i} - Y_{0i})$$\n",
    "\n",
    "The **individual treatment effect** $\\tau_i = Y_{1i} - Y_{0i}$ is unknowable—we only see one potential outcome.\n",
    "\n",
    "So we focus on the **Average Treatment Effect (ATE)**:\n",
    "\n",
    "$$\\text{ATE} = E[Y_1 - Y_0]$$\n",
    "\n",
    "### 1.2 From Means to Regression\n",
    "\n",
    "Facure's key insight: if we could simply compare means...\n",
    "\n",
    "$$E[Y|T=1] - E[Y|T=0] = \\underbrace{E[Y_1 - Y_0|T=1]}_{\\text{ATT}} + \\underbrace{E[Y_0|T=1] - E[Y_0|T=0]}_{\\text{BIAS}}$$\n",
    "\n",
    "The bias term reflects **selection**: treated units may differ from control units even without treatment.\n",
    "\n",
    "**Randomization eliminates bias**: In an RCT, treatment is independent of potential outcomes, so $E[Y_0|T=1] = E[Y_0|T=0]$.\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Regression with treatment dummy recovers the difference in means\n",
    "- With randomization, this equals the ATE\n",
    "- Bonus: regression gives standard errors and confidence intervals \"for free\"\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment\n",
    "\n",
    "### 2.1 Regression as Conditional Expectation\n",
    "\n",
    "Consider the simple regression model:\n",
    "\n",
    "$$Y_i = \\beta_0 + \\kappa T_i + u_i$$\n",
    "\n",
    "where $T_i \\in \\{0, 1\\}$ is a treatment indicator.\n",
    "\n",
    "**Proposition**: The OLS estimates satisfy:\n",
    "\n",
    "$$\\hat{\\beta}_0 = \\bar{Y}_0 = \\frac{1}{n_0} \\sum_{i: T_i=0} Y_i$$\n",
    "\n",
    "$$\\hat{\\kappa} = \\bar{Y}_1 - \\bar{Y}_0$$\n",
    "\n",
    "**Proof**: With a binary regressor, the OLS coefficient is:\n",
    "\n",
    "$$\\hat{\\kappa} = \\frac{\\text{Cov}(Y, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "For binary $T$ with $P(T=1) = p$:\n",
    "- $\\text{Var}(T) = p(1-p)$\n",
    "- $\\text{Cov}(Y, T) = E[YT] - E[Y]E[T] = p\\bar{Y}_1 - (p\\bar{Y}_1 + (1-p)\\bar{Y}_0)p$\n",
    "\n",
    "Simplifying:\n",
    "$$\\hat{\\kappa} = \\frac{p(1-p)(\\bar{Y}_1 - \\bar{Y}_0)}{p(1-p)} = \\bar{Y}_1 - \\bar{Y}_0 \\quad \\blacksquare$$\n",
    "\n",
    "### 2.2 Why Regression Works for RCTs\n",
    "\n",
    "**Assumption (Randomization)**: $(Y_0, Y_1) \\perp T$\n",
    "\n",
    "Under randomization:\n",
    "\n",
    "$$E[\\hat{\\kappa}] = E[\\bar{Y}_1 - \\bar{Y}_0] = E[Y_1] - E[Y_0] = \\text{ATE}$$\n",
    "\n",
    "The regression coefficient is an **unbiased estimator** of the ATE.\n",
    "\n",
    "**Variance**: The Neyman (1923) variance formula for the difference in means:\n",
    "\n",
    "$$\\text{Var}(\\hat{\\kappa}) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_0^2}{n_0}$$\n",
    "\n",
    "OLS with heteroskedasticity-robust standard errors recovers this exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration\n",
    "\n",
    "### 3.1 Online Classroom Example\n",
    "\n",
    "Facure's example: students randomly assigned to online vs. face-to-face instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load online classroom data\n",
    "data = load_facure_data('online_classroom.csv')\n",
    "\n",
    "# Filter to non-blended formats (pure online vs face-to-face)\n",
    "data = data.query('format_blended == 0').copy()\n",
    "\n",
    "print(f\"Sample size: n = {len(data)}\")\n",
    "print(f\"Treatment: format_ol (1 = online, 0 = face-to-face)\")\n",
    "print(f\"Outcome: falsexam (exam score)\")\n",
    "print(f\"\\nTreatment distribution:\")\n",
    "print(data['format_ol'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Simple difference in means\n",
    "mean_control = data.query('format_ol == 0')['falsexam'].mean()\n",
    "mean_treated = data.query('format_ol == 1')['falsexam'].mean()\n",
    "diff_means = mean_treated - mean_control\n",
    "\n",
    "print(\"Method 1: Difference in Means\")\n",
    "print(f\"  E[Y|T=0] (face-to-face): {mean_control:.4f}\")\n",
    "print(f\"  E[Y|T=1] (online):       {mean_treated:.4f}\")\n",
    "print(f\"  Difference:              {diff_means:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: OLS regression\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols('falsexam ~ format_ol', data=data).fit()\n",
    "\n",
    "print(\"\\nMethod 2: OLS Regression\")\n",
    "print(f\"  Intercept (β₀):    {model.params['Intercept']:.4f}\")\n",
    "print(f\"  Coefficient (κ):   {model.params['format_ol']:.4f}\")\n",
    "print(f\"  95% CI:            [{model.conf_int().loc['format_ol', 0]:.4f}, {model.conf_int().loc['format_ol', 1]:.4f}]\")\n",
    "print(f\"  p-value:           {model.pvalues['format_ol']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Verifying Coefficient = Difference in Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the two methods match exactly\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Intercept = E[Y|T=0]?\")\n",
    "print(f\"  {model.params['Intercept']:.10f} = {mean_control:.10f}\")\n",
    "print(f\"  Match: {np.isclose(model.params['Intercept'], mean_control)}\")\n",
    "print()\n",
    "print(f\"Coefficient = Difference in means?\")\n",
    "print(f\"  {model.params['format_ol']:.10f} = {diff_means:.10f}\")\n",
    "print(f\"  Match: {np.isclose(model.params['format_ol'], diff_means)}\")\n",
    "\n",
    "# Assertions for test validation\n",
    "assert np.isclose(model.params['Intercept'], mean_control, rtol=1e-10)\n",
    "assert np.isclose(model.params['format_ol'], diff_means, rtol=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Panel 1: Distribution by treatment group\n",
    "ax = axes[0]\n",
    "for t, label, color in [(0, 'Face-to-face', TUFTE_PALETTE['control']), \n",
    "                         (1, 'Online', TUFTE_PALETTE['treatment'])]:\n",
    "    subset = data.query(f'format_ol == {t}')['falsexam']\n",
    "    ax.hist(subset, bins=20, alpha=0.6, label=f'{label} (n={len(subset)})', \n",
    "            color=color, edgecolor='white')\n",
    "    ax.axvline(subset.mean(), color=color, linestyle='--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Exam Score')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('(a) Score Distribution by Format')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Panel 2: Treatment effect estimate\n",
    "ax = axes[1]\n",
    "ax.barh(['ATE'], [model.params['format_ol']], \n",
    "        xerr=[[model.params['format_ol'] - model.conf_int().loc['format_ol', 0]],\n",
    "              [model.conf_int().loc['format_ol', 1] - model.params['format_ol']]],\n",
    "        color=TUFTE_PALETTE['effect'], capsize=5, height=0.4)\n",
    "ax.axvline(0, color=TUFTE_PALETTE['spine'], linestyle='-', linewidth=1)\n",
    "ax.set_xlabel('Effect on Exam Score')\n",
    "ax.set_title('(b) Estimated Treatment Effect')\n",
    "ax.text(model.params['format_ol'], 0.2, f'{model.params[\"format_ol\"]:.2f}', \n",
    "        ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: Online classes reduce exam scores by about 4.9 points on average. The 95% confidence interval excludes zero, suggesting this effect is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation\n",
    "\n",
    "The simple ATE estimator via regression is a building block for more sophisticated methods in `causal_inference_mastery`:\n",
    "\n",
    "```python\n",
    "# From causal_inference.rct.simple_ate\n",
    "from causal_inference.rct.simple_ate import simple_ate, ATEResult\n",
    "\n",
    "result = simple_ate(outcome=data['falsexam'], treatment=data['format_ol'])\n",
    "print(f\"ATE: {result.ate:.4f}\")\n",
    "print(f\"SE:  {result.se:.4f}\")\n",
    "print(f\"CI:  [{result.ci_lower:.4f}, {result.ci_upper:.4f}]\")\n",
    "```\n",
    "\n",
    "The production code adds:\n",
    "- Heteroskedasticity-robust standard errors\n",
    "- Cluster-robust inference\n",
    "- Covariate adjustment for efficiency gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1 (Meta E5, DS)**: *\"Why does regression give us causal estimates in an RCT but not always in observational data?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "1. **Identification vs. estimation**: Regression is an *estimation* technique. Whether it identifies a *causal* effect depends on the data-generating process.\n",
    "\n",
    "2. **RCT case**: Randomization ensures $(Y_0, Y_1) \\perp T$:\n",
    "   - Treated and control groups have the same distribution of potential outcomes\n",
    "   - Selection bias = 0\n",
    "   - $E[Y|T=1] - E[Y|T=0] = E[Y_1] - E[Y_0] = \\text{ATE}$\n",
    "\n",
    "3. **Observational case**: Without randomization, $T$ may depend on $Y_0$:\n",
    "   - Example: People who choose more education may have higher baseline ability\n",
    "   - Selection bias $\\neq 0$\n",
    "   - Regression coefficient captures ATE + bias\n",
    "\n",
    "4. **Fix**: In observational data, add controls for confounders (see Section 03-04). But this requires the \"conditional ignorability\" assumption—that *all* confounders are observed and controlled.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q2 (Google L5, Quant)**: *\"Show mathematically that the regression coefficient on a binary treatment equals the difference in means.\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Derivation:**\n",
    "\n",
    "For regression $Y = \\beta_0 + \\kappa T + u$ with binary $T$:\n",
    "\n",
    "$$\\hat{\\kappa} = \\frac{\\text{Cov}(Y, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "Let $p = P(T=1)$ (treatment probability).\n",
    "\n",
    "**Variance of T**:\n",
    "$$\\text{Var}(T) = E[T^2] - E[T]^2 = p - p^2 = p(1-p)$$\n",
    "\n",
    "**Covariance**:\n",
    "$$\\text{Cov}(Y,T) = E[YT] - E[Y]E[T]$$\n",
    "\n",
    "- $E[YT] = E[Y|T=1]P(T=1) = \\bar{Y}_1 \\cdot p$\n",
    "- $E[Y] = \\bar{Y}_1 p + \\bar{Y}_0(1-p)$\n",
    "- $E[T] = p$\n",
    "\n",
    "So:\n",
    "$$\\text{Cov}(Y,T) = \\bar{Y}_1 p - [\\bar{Y}_1 p + \\bar{Y}_0(1-p)]p = p(1-p)(\\bar{Y}_1 - \\bar{Y}_0)$$\n",
    "\n",
    "Therefore:\n",
    "$$\\hat{\\kappa} = \\frac{p(1-p)(\\bar{Y}_1 - \\bar{Y}_0)}{p(1-p)} = \\bar{Y}_1 - \\bar{Y}_0$$\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q3 (Amazon L6, Econ)**: *\"What's the advantage of using regression over a simple t-test for A/B testing?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Advantages of regression:**\n",
    "\n",
    "1. **Covariate adjustment**: Can add pre-treatment covariates to reduce variance and increase precision (ANCOVA)\n",
    "\n",
    "2. **Multiple treatments**: Easy to compare >2 groups with dummy variables\n",
    "\n",
    "3. **Heterogeneous effects**: Can test interactions (e.g., does treatment work differently for men vs women?)\n",
    "\n",
    "4. **Continuous treatments**: Regression generalizes naturally; t-test is binary only\n",
    "\n",
    "5. **Standard error flexibility**: Can use robust, clustered, or bootstrap SEs\n",
    "\n",
    "6. **Model diagnostics**: R², F-tests, residual plots\n",
    "\n",
    "**Note**: For a simple two-group comparison without covariates, the regression coefficient and t-test give *identical* p-values (they're mathematically equivalent).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 5: \"All You Need is Regression.\"\n",
    "\n",
    "[^2]: Neyman, J. (1923). On the Application of Probability Theory to Agricultural Experiments. *Statistical Science*, 5(4), 465-472 (translated 1990).\n",
    "\n",
    "[^3]: Angrist, J. D. and Pischke, J.-S. (2009). *Mostly Harmless Econometrics*. Princeton University Press, Chapter 2.\n",
    "\n",
    "[^4]: Imbens, G. W. and Rubin, D. B. (2015). *Causal Inference for Statistics, Social, and Biomedical Sciences*. Cambridge University Press.\n",
    "\n",
    "---\n",
    "\n",
    "**Precision Improvement:**\n",
    "- You said: \"Build the first section notebook\"\n",
    "- Concise: \"Build 01_all_you_need_is_regression\"\n",
    "- Precise: `/facure_augment 05.1 --ate-basics --verify-means`\n",
    "- Pattern: [build] [target] [content-flags]"
   ]
  }
 ],
 "metadata": {
  "facure_augment": {
   "chapter_number": 5,
   "facure_source": "05-The-Unreasonable-Effectiveness-of-Linear-Regression.ipynb",
   "last_validated": "2026-01-09",
   "section_number": 1,
   "section_types": [
    "table_of_contents",
    "facure_intuition",
    "formal_treatment",
    "numeric_demonstration",
    "implementation",
    "interview_appendix",
    "references"
   ],
   "title": "All You Need is Regression",
   "version": "1.0.0"
  },
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
