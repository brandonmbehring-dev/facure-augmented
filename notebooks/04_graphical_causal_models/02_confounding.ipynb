{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04.2 Confounding Bias: The Backdoor Problem\n",
    "\n",
    "**Chapter**: 4 - Graphical Causal Models  \n",
    "**Section**: 2 - Confounding  \n",
    "**Facure Source**: 04-Graphical-Causal-Models.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-09\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Facure's Intuition](#1-facures-intuition)\n",
    "   - 1.1 [What is Confounding?](#11-what-is-confounding)\n",
    "   - 1.2 [The Backdoor Path](#12-the-backdoor-path)\n",
    "2. [Formal Treatment](#2-formal-treatment)\n",
    "   - 2.1 [Backdoor Criterion](#21-backdoor-criterion)\n",
    "   - 2.2 [Adjustment Formula](#22-adjustment-formula)\n",
    "3. [Numeric Demonstration](#3-numeric-demonstration)\n",
    "   - 3.1 [Confounding Simulation](#31-confounding-simulation)\n",
    "   - 3.2 [Surrogate Confounders](#32-surrogate-confounders)\n",
    "4. [Implementation](#4-implementation)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from facure_augment.common import (\n",
    "    np, pd, plt, sm,\n",
    "    set_notebook_style,\n",
    "    create_tufte_figure,\n",
    "    TUFTE_PALETTE,\n",
    ")\n",
    "\n",
    "set_notebook_style()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition\n",
    "\n",
    "> **Interview Relevance**: Confounding is THE central problem in observational causal inference. Every interview will test whether you can identify and address confounders.\n",
    "\n",
    "### 1.1 What is Confounding?\n",
    "\n",
    "Facure's example: **Education → Wage**\n",
    "\n",
    "We observe: People with more education earn more. Is education **causing** higher wages?\n",
    "\n",
    "**The problem**: Intelligence affects both:\n",
    "- Smarter people get more education\n",
    "- Smarter people earn more (even without education)\n",
    "\n",
    "**Intelligence** is a **confounder**—a common cause of both treatment and outcome.\n",
    "\n",
    "### 1.2 The Backdoor Path\n",
    "\n",
    "In DAG terms:\n",
    "\n",
    "```\n",
    "Intelligence → Education\n",
    "Intelligence → Wage\n",
    "Education → Wage  (the causal effect we want)\n",
    "```\n",
    "\n",
    "There's a **backdoor path**: Education ← Intelligence → Wage\n",
    "\n",
    "This path creates spurious association that mixes with the causal effect.\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Confounding = common cause creates backdoor path\n",
    "- Backdoor paths flow T ← ... → Y (arrow INTO treatment)\n",
    "- Solution: Block all backdoor paths\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment\n",
    "\n",
    "### 2.1 Backdoor Criterion\n",
    "\n",
    "**Definition** (Pearl, 2009): A set of variables $Z$ satisfies the **backdoor criterion** relative to $(T, Y)$ if:\n",
    "\n",
    "1. No node in $Z$ is a descendant of $T$\n",
    "2. $Z$ blocks every path between $T$ and $Y$ that contains an arrow **into** $T$\n",
    "\n",
    "**Implication**: If $Z$ satisfies the backdoor criterion, then:\n",
    "$$P(Y \\mid do(T=t)) = \\sum_z P(Y \\mid T=t, Z=z) P(Z=z)$$\n",
    "\n",
    "### 2.2 Adjustment Formula\n",
    "\n",
    "For continuous variables, the **adjustment formula** becomes:\n",
    "\n",
    "$$E[Y \\mid do(T=t)] = \\int E[Y \\mid T=t, Z=z] \\, dP(Z=z)$$\n",
    "\n",
    "In regression:\n",
    "$$Y = \\alpha + \\tau T + \\beta Z + \\epsilon$$\n",
    "\n",
    "The coefficient $\\tau$ is the causal effect **if** Z satisfies the backdoor criterion.\n",
    "\n",
    "**Conditional ignorability** (Rubin's framing):\n",
    "$$(Y_0, Y_1) \\perp\\!\\!\\!\\perp T \\mid Z$$\n",
    "\n",
    "This is equivalent to saying: given Z, treatment assignment is \"as good as random.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration\n",
    "\n",
    "### 3.1 Confounding Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate confounding: Intelligence → Education, Intelligence → Wage, Education → Wage\n",
    "np.random.seed(42)\n",
    "n = 2000\n",
    "\n",
    "# True causal effect of education on wage\n",
    "TRUE_EFFECT = 5.0  # Each year of education increases wage by $5k\n",
    "\n",
    "# Confounder: Intelligence (unobserved IQ)\n",
    "intelligence = np.random.normal(100, 15, n)\n",
    "\n",
    "# Treatment: Years of education (affected by intelligence)\n",
    "education = 10 + 0.1 * (intelligence - 100) + np.random.normal(0, 2, n)\n",
    "education = np.clip(education, 0, 20)  # 0-20 years\n",
    "\n",
    "# Outcome: Wage (affected by both intelligence AND education)\n",
    "wage = 30 + TRUE_EFFECT * education + 0.5 * (intelligence - 100) + np.random.normal(0, 10, n)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'intelligence': intelligence,\n",
    "    'education': education,\n",
    "    'wage': wage,\n",
    "})\n",
    "\n",
    "print(\"SIMULATED DATA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"True causal effect of education: {TRUE_EFFECT}\")\n",
    "print(f\"Sample size: {n}\")\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive estimate: Regress wage on education (ignoring intelligence)\n",
    "naive_model = sm.OLS(df['wage'], sm.add_constant(df['education'])).fit()\n",
    "\n",
    "# Adjusted estimate: Regress wage on education AND intelligence\n",
    "adjusted_model = sm.OLS(df['wage'], sm.add_constant(df[['education', 'intelligence']])).fit()\n",
    "\n",
    "print(\"CONFOUNDING DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"True causal effect:       {TRUE_EFFECT:.2f}\")\n",
    "print(f\"Naive estimate:           {naive_model.params['education']:.2f} (BIASED!)\")\n",
    "print(f\"Adjusted estimate:        {adjusted_model.params['education']:.2f} (close to true)\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Bias from confounding:    {naive_model.params['education'] - TRUE_EFFECT:.2f}\")\n",
    "print(f\"Residual bias:            {adjusted_model.params['education'] - TRUE_EFFECT:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confounding\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Left: Naive relationship (confounded)\n",
    "ax = axes[0]\n",
    "ax.scatter(df['education'], df['wage'], alpha=0.3, s=10, c=TUFTE_PALETTE['secondary'])\n",
    "# Add regression line\n",
    "x_line = np.linspace(df['education'].min(), df['education'].max(), 100)\n",
    "ax.plot(x_line, naive_model.params['const'] + naive_model.params['education'] * x_line,\n",
    "        color=TUFTE_PALETTE['control'], linewidth=2, label=f'Naive: β = {naive_model.params[\"education\"]:.1f}')\n",
    "ax.set_xlabel('Education (years)')\n",
    "ax.set_ylabel('Wage ($k)')\n",
    "ax.set_title('Naive Analysis (Confounded)\\nIntelligence not controlled')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Right: Color by intelligence to show confounding\n",
    "ax = axes[1]\n",
    "scatter = ax.scatter(df['education'], df['wage'], c=df['intelligence'], \n",
    "                     alpha=0.5, s=10, cmap='coolwarm')\n",
    "plt.colorbar(scatter, ax=ax, label='Intelligence (IQ)')\n",
    "ax.set_xlabel('Education (years)')\n",
    "ax.set_ylabel('Wage ($k)')\n",
    "ax.set_title('Revealing the Confounder\\nHigh IQ → More education AND higher wage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Surrogate Confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if intelligence is UNOBSERVED but we have a proxy (SAT scores)?\n",
    "np.random.seed(42)\n",
    "\n",
    "# SAT is caused by intelligence (surrogate/proxy)\n",
    "sat_score = 1000 + 5 * (df['intelligence'] - 100) + np.random.normal(0, 100, n)\n",
    "df['sat_score'] = sat_score\n",
    "\n",
    "# Estimate with SAT as proxy\n",
    "proxy_model = sm.OLS(df['wage'], sm.add_constant(df[['education', 'sat_score']])).fit()\n",
    "\n",
    "print(\"SURROGATE CONFOUNDER ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"If intelligence is unmeasured but SAT is available:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"True effect:              {TRUE_EFFECT:.2f}\")\n",
    "print(f\"Naive (no control):       {naive_model.params['education']:.2f}\")\n",
    "print(f\"With true confounder:     {adjusted_model.params['education']:.2f}\")\n",
    "print(f\"With SAT proxy:           {proxy_model.params['education']:.2f}\")\n",
    "print(\"-\"*60)\n",
    "print(\"\\nSAT partially controls for intelligence, reducing (but not eliminating) bias.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate that multiple surrogates help\n",
    "# Add another proxy: Father's education (correlated with child's intelligence)\n",
    "father_edu = 10 + 0.05 * (df['intelligence'] - 100) + np.random.normal(0, 3, n)\n",
    "df['father_edu'] = father_edu\n",
    "\n",
    "multi_proxy_model = sm.OLS(df['wage'], \n",
    "                           sm.add_constant(df[['education', 'sat_score', 'father_edu']])).fit()\n",
    "\n",
    "print(\"MULTIPLE SURROGATES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"True effect:              {TRUE_EFFECT:.2f}\")\n",
    "print(f\"With SAT only:            {proxy_model.params['education']:.2f}\")\n",
    "print(f\"With SAT + Father Edu:    {multi_proxy_model.params['education']:.2f}\")\n",
    "print(\"-\"*60)\n",
    "print(\"Multiple proxies absorb more variance from the unobserved confounder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation\n",
    "\n",
    "```python\n",
    "# Basic regression adjustment\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Control for confounders\n",
    "X = sm.add_constant(df[['treatment', 'confounder1', 'confounder2']])\n",
    "model = sm.OLS(df['outcome'], X).fit()\n",
    "ate = model.params['treatment']\n",
    "\n",
    "# Using DoWhy for causal effect estimation\n",
    "from dowhy import CausalModel\n",
    "\n",
    "model = CausalModel(\n",
    "    data=df,\n",
    "    treatment='education',\n",
    "    outcome='wage',\n",
    "    common_causes=['intelligence', 'family_income'],\n",
    ")\n",
    "identified = model.identify_effect()\n",
    "estimate = model.estimate_effect(identified, method_name=\"backdoor.linear_regression\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix\n",
    "\n",
    "**Q1 (Uber, Lyft)**: *\"What is confounding bias? How would you address it?\"*\n",
    "\n",
    "<details><summary>Solution</summary>\n",
    "\n",
    "**Confounding bias** occurs when a common cause of treatment and outcome creates a spurious association.\n",
    "\n",
    "**DAG**: X → T, X → Y, T → Y\n",
    "\n",
    "**Solutions**:\n",
    "1. **Randomization**: Break X → T link (gold standard)\n",
    "2. **Regression adjustment**: Control for X\n",
    "3. **Matching/Weighting**: Balance X across treatment groups\n",
    "4. **Instrumental variables**: Find variable that affects T but not Y except through T\n",
    "5. **Difference-in-differences**: Exploit within-unit variation over time\n",
    "\n",
    "**Key insight**: The method must close all backdoor paths without opening new ones.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q2 (Meta, Google)**: *\"What is the backdoor criterion?\"*\n",
    "\n",
    "<details><summary>Solution</summary>\n",
    "\n",
    "The **backdoor criterion** (Pearl, 2009) specifies when a set of variables Z is sufficient to identify causal effects:\n",
    "\n",
    "Z satisfies the backdoor criterion for (T, Y) if:\n",
    "1. **No descendants of T**: Z doesn't include any variable on the causal path T → ... → Y\n",
    "2. **Blocks backdoor paths**: Z blocks all paths T ← ... → Y (arrows into T)\n",
    "\n",
    "If satisfied, the causal effect is:\n",
    "$$E[Y|do(T)] = \\sum_z E[Y|T,Z=z]P(Z=z)$$\n",
    "\n",
    "**Why it matters**: It tells us exactly which variables to control for, avoiding both under-controlling (missing confounders) and over-controlling (conditioning on mediators or colliders).\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q3**: *\"If you can't measure a confounder directly, what can you do?\"*\n",
    "\n",
    "<details><summary>Solution</summary>\n",
    "\n",
    "**Options for unmeasured confounders**:\n",
    "\n",
    "1. **Proxy variables (surrogates)**: Variables caused by the confounder\n",
    "   - Example: SAT scores as proxy for intelligence\n",
    "   - Partial reduction in bias\n",
    "\n",
    "2. **Instrumental variables**: Find IV that affects T but not Y directly\n",
    "   - Example: Distance to college as IV for education\n",
    "\n",
    "3. **Panel data / Fixed effects**: Control for time-invariant unobservables\n",
    "   - Requires within-unit variation\n",
    "\n",
    "4. **Sensitivity analysis**: Bound how bad bias could be\n",
    "   - E.g., \"How strong would unmeasured confounder need to be to explain away the effect?\"\n",
    "\n",
    "5. **Diff-in-diff / RDD**: Exploit natural experiments\n",
    "\n",
    "**Key principle**: Acknowledge limitations, use multiple approaches, conduct sensitivity analysis.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 4.\n",
    "\n",
    "[^2]: Pearl, J. (2009). *Causality: Models, Reasoning, and Inference*. Cambridge University Press, Chapter 3.\n",
    "\n",
    "[^3]: Angrist, J. D., & Pischke, J.-S. (2009). *Mostly Harmless Econometrics*. Princeton University Press, Chapter 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
