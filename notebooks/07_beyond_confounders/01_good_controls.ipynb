{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Good Controls: Variance Reduction\n",
    "\n",
    "**Chapter 7, Section 1**\n",
    "\n",
    "This notebook covers how adding controls that predict the outcome (but not treatment) reduces standard errors without introducing bias.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition) - Controls that predict Y help\n",
    "2. [Formal Treatment](#formal) - FWL and variance decomposition\n",
    "3. [Numeric Demonstration](#numeric) - Email campaign example\n",
    "4. [Implementation](#implementation) - Partialling out in practice\n",
    "5. [Interview Appendix](#interview) - Practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from facure_augment.common import *\n",
    "\n",
    "# Set notebook style\n",
    "set_notebook_style()\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "### When Controls Help (Without Being Confounders)\n",
    "\n",
    "Consider an RCT: treatment $T$ is randomly assigned, so there's no confounding. Why would we add controls?\n",
    "\n",
    "**Answer**: Controls that predict the outcome $Y$ **reduce residual variance**, leading to:\n",
    "- Smaller standard errors\n",
    "- Narrower confidence intervals\n",
    "- More statistical power\n",
    "\n",
    "This is the **variance reduction** argument:\n",
    "\n",
    "$$\\text{Var}(Y | X) < \\text{Var}(Y)$$\n",
    "\n",
    "If $X$ explains part of $Y$'s variance, the residual variance $\\sigma^2_{Y|X}$ is smaller.\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Good controls predict **Y**, not (or not only) **T**\n",
    "- In an RCT, controls aren't needed for unbiasedness\n",
    "- But they increase precision (statistical power)\n",
    "- Key: Adding good controls ≠ changing the coefficient\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collections email data (5,000 customers)\n",
    "email = load_facure_data(\"collections_email.csv\")\n",
    "\n",
    "print(f\"Data: {len(email)} customers\")\n",
    "print(f\"Treatment (email): {email['email'].mean():.1%} received email\")\n",
    "print(f\"\\nColumns: {list(email.columns)}\")\n",
    "email.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# This is an RCT - email was randomly assigned\n# Verify randomization by checking balance\nprint(\"Balance check (means by treatment):\")\nbalance = email.groupby('email')[['credit_limit', 'risk_score']].mean()\nprint(balance)\nprint(f\"\\nDifference (email=1 minus email=0):\")\ndiff = balance.loc[1] - balance.loc[0]\nprint(f\"  credit_limit: {diff['credit_limit']:.2f}\")\nprint(f\"  risk_score:   {diff['risk_score']:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Treatment\n",
    "\n",
    "### Why Good Controls Reduce Standard Errors\n",
    "\n",
    "Consider the regression:\n",
    "\n",
    "$$Y = \\alpha + \\beta T + \\gamma X + \\epsilon$$\n",
    "\n",
    "The standard error of $\\hat{\\beta}$ is:\n",
    "\n",
    "$$SE(\\hat{\\beta}) = \\sqrt{\\frac{\\hat{\\sigma}^2_{\\epsilon}}{\\sum_i (T_i - \\bar{T})^2 \\cdot (1 - R^2_{T \\sim X})}}$$\n",
    "\n",
    "**Two effects of adding X**:\n",
    "\n",
    "| Component | Effect of Adding X | Net Result |\n",
    "|-----------|-------------------|------------|\n",
    "| $\\hat{\\sigma}^2_{\\epsilon}$ | **Decreases** if X predicts Y | ↓ SE |\n",
    "| $R^2_{T \\sim X}$ | **Increases** if X predicts T | ↑ SE |\n",
    "\n",
    "**Good control**: X predicts Y strongly, T weakly → Net SE reduction\n",
    "\n",
    "**Bad control**: X predicts T strongly, Y weakly → Net SE increase\n",
    "\n",
    "### FWL Perspective\n",
    "\n",
    "By Frisch-Waugh-Lovell, $\\hat{\\beta}$ comes from:\n",
    "\n",
    "$$\\tilde{Y} = \\beta \\tilde{T} + \\epsilon$$\n",
    "\n",
    "where $\\tilde{Y}$ and $\\tilde{T}$ are residuals after partialling out X.\n",
    "\n",
    "- If X explains Y variance → $\\text{Var}(\\tilde{Y})$ smaller → smaller SE\n",
    "- If X explains T variance → $\\text{Var}(\\tilde{T})$ smaller → **larger SE** (denominator shrinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: No controls (simple treatment effect)\n",
    "model_simple = smf.ols('payments ~ email', data=email).fit()\n",
    "\n",
    "# Model 2: With good controls (credit_limit, risk_score)\n",
    "model_controls = smf.ols('payments ~ email + credit_limit + risk_score', data=email).fit()\n",
    "\n",
    "print(\"COMPARISON: Simple vs With Controls\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"\\nTreatment Effect (email → payments):\")\n",
    "print(f\"  Without controls: {model_simple.params['email']:.2f} (SE: {model_simple.bse['email']:.2f})\")\n",
    "print(f\"  With controls:    {model_controls.params['email']:.2f} (SE: {model_controls.bse['email']:.2f})\")\n",
    "print(f\"\\nSE reduction: {(1 - model_controls.bse['email']/model_simple.bse['email'])*100:.1f}%\")\n",
    "print(f\"R² increase: {model_simple.rsquared:.4f} → {model_controls.rsquared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numeric Demonstration\n",
    "\n",
    "### Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose variance reduction\n",
    "var_Y_total = email['payments'].var()\n",
    "var_Y_residual_simple = model_simple.resid.var()\n",
    "var_Y_residual_controls = model_controls.resid.var()\n",
    "\n",
    "print(\"Variance Decomposition:\")\n",
    "print(f\"  Total Var(Y):           {var_Y_total:.2f}\")\n",
    "print(f\"  Residual (no controls): {var_Y_residual_simple:.2f}\")\n",
    "print(f\"  Residual (controls):    {var_Y_residual_controls:.2f}\")\n",
    "print(f\"\\nVariance explained by controls: {(1 - var_Y_residual_controls/var_Y_residual_simple)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the precision gain\n",
    "fig, axes = create_tufte_figure(ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Left: Confidence intervals comparison\n",
    "ax = axes[0]\n",
    "\n",
    "models = ['Without Controls', 'With Controls']\n",
    "effects = [model_simple.params['email'], model_controls.params['email']]\n",
    "ci_lower = [model_simple.conf_int().loc['email', 0], model_controls.conf_int().loc['email', 0]]\n",
    "ci_upper = [model_simple.conf_int().loc['email', 1], model_controls.conf_int().loc['email', 1]]\n",
    "\n",
    "y_pos = [1, 0]\n",
    "for i, (model, effect, lo, hi) in enumerate(zip(models, effects, ci_lower, ci_upper)):\n",
    "    color = COLORS['blue'] if i == 0 else COLORS['green']\n",
    "    ax.errorbar(effect, y_pos[i], xerr=[[effect-lo], [hi-effect]], \n",
    "                fmt='o', color=color, capsize=5, markersize=8, linewidth=2)\n",
    "    ax.text(hi + 5, y_pos[i], f'{effect:.1f} ± {(hi-lo)/2:.1f}', \n",
    "            va='center', fontsize=10, color=color)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(models)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth=0.5)\n",
    "set_tufte_title(ax, \"Treatment Effect: Precision Gain with Controls\")\n",
    "set_tufte_labels(ax, \"Email Effect on Payments ($)\", \"\")\n",
    "\n",
    "# Right: How controls predict outcome\n",
    "ax = axes[1]\n",
    "\n",
    "# Show correlation between controls and outcome\n",
    "ax.scatter(email['risk_score'], email['payments'], alpha=0.3, s=10, c=COLORS['blue'])\n",
    "\n",
    "# Add regression line\n",
    "x_range = np.linspace(email['risk_score'].min(), email['risk_score'].max(), 100)\n",
    "risk_model = smf.ols('payments ~ risk_score', data=email).fit()\n",
    "ax.plot(x_range, risk_model.params['Intercept'] + risk_model.params['risk_score'] * x_range,\n",
    "        color=COLORS['red'], linewidth=2, label=f'R² = {risk_model.rsquared:.3f}')\n",
    "\n",
    "set_tufte_title(ax, \"Good Control: Risk Score Predicts Payments\")\n",
    "set_tufte_labels(ax, \"Risk Score\", \"Payments ($)\")\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that controls don't predict treatment (RCT verification)\n",
    "model_predict_T = smf.ols('email ~ credit_limit + risk_score', data=email).fit()\n",
    "\n",
    "print(\"Do controls predict treatment? (Should be ~0 for RCT)\")\n",
    "print(f\"R² of email ~ credit_limit + risk_score: {model_predict_T.rsquared:.6f}\")\n",
    "print(f\"\\nThis confirms random assignment: controls don't predict who got email.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Control Variable Decision Tree\n",
    "\n",
    "| Variable Type | Control? | Effect on SE | Effect on $\\hat{\\beta}$ |\n",
    "|--------------|----------|--------------|------------------------|\n",
    "| **Confounder** (X → T, X → Y) | ✅ YES | Mixed | Removes bias |\n",
    "| **Outcome predictor** (X → Y only) | ✅ YES | ↓ Decreases | No change (RCT) |\n",
    "| **Treatment predictor** (X → T only) | ❌ NO | ↑ Increases | No change (RCT) |\n",
    "| **Collider** (T → X ← Y) | ❌ NO | Mixed | Introduces bias |\n",
    "| **Mediator** (T → X → Y) | ❌ NO | Mixed | Blocks causal path |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### FWL Demonstration: Partialling Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate FWL: partialling out gives same coefficient\n",
    "\n",
    "# Step 1: Regress Y on controls, get residuals\n",
    "model_Y_on_X = smf.ols('payments ~ credit_limit + risk_score', data=email).fit()\n",
    "Y_tilde = model_Y_on_X.resid\n",
    "\n",
    "# Step 2: Regress T on controls, get residuals\n",
    "model_T_on_X = smf.ols('email ~ credit_limit + risk_score', data=email).fit()\n",
    "T_tilde = model_T_on_X.resid\n",
    "\n",
    "# Step 3: Regress Y~ on T~\n",
    "residuals_df = pd.DataFrame({'Y_tilde': Y_tilde, 'T_tilde': T_tilde})\n",
    "model_fwl = smf.ols('Y_tilde ~ T_tilde - 1', data=residuals_df).fit()  # No intercept\n",
    "\n",
    "print(\"FWL Verification:\")\n",
    "print(f\"  Full regression β: {model_controls.params['email']:.10f}\")\n",
    "print(f\"  FWL (partialled):  {model_fwl.params['T_tilde']:.10f}\")\n",
    "print(f\"  Match: {np.isclose(model_controls.params['email'], model_fwl.params['T_tilde'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the partialling out process\n",
    "fig, axes = create_tufte_figure(ncols=3, figsize=(15, 4))\n",
    "\n",
    "# Left: Raw Y vs T\n",
    "ax = axes[0]\n",
    "for t_val, color, label in [(0, COLORS['blue'], 'No Email'), (1, COLORS['red'], 'Email')]:\n",
    "    subset = email[email['email'] == t_val]\n",
    "    ax.hist(subset['payments'], bins=30, alpha=0.5, color=color, label=label, density=True)\n",
    "set_tufte_title(ax, \"Raw: Payments by Treatment\")\n",
    "set_tufte_labels(ax, \"Payments ($)\", \"Density\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Middle: Residualized Y\n",
    "ax = axes[1]\n",
    "ax.hist(Y_tilde, bins=30, alpha=0.7, color=COLORS['green'], density=True)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth=1)\n",
    "set_tufte_title(ax, \"Ỹ: Payments After Partialling Out Controls\")\n",
    "set_tufte_labels(ax, \"Residualized Payments\", \"Density\")\n",
    "\n",
    "# Right: Residualized T (should be ~centered at 0.5 for RCT)\n",
    "ax = axes[2]\n",
    "ax.hist(T_tilde, bins=30, alpha=0.7, color=COLORS['orange'], density=True)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth=1)\n",
    "set_tufte_title(ax, \"T̃: Treatment After Partialling (RCT ≈ No Change)\")\n",
    "set_tufte_labels(ax, \"Residualized Treatment\", \"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVariance comparison:\")\n",
    "print(f\"  Var(Y):  {email['payments'].var():.2f}\")\n",
    "print(f\"  Var(Ỹ): {Y_tilde.var():.2f} (reduced by {(1-Y_tilde.var()/email['payments'].var())*100:.1f}%)\")\n",
    "print(f\"  Var(T):  {email['email'].var():.4f}\")\n",
    "print(f\"  Var(T̃): {T_tilde.var():.4f} (unchanged for RCT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1: When do additional controls help causal inference?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "Additional controls help in two distinct ways:\n",
    "\n",
    "**1. Removing confounding bias** (observational data):\n",
    "- Control for common causes of T and Y\n",
    "- Blocks backdoor paths in the DAG\n",
    "- Necessary for identification\n",
    "\n",
    "**2. Reducing variance** (RCT or observational):\n",
    "- Control for variables that predict Y (but not necessarily T)\n",
    "- Reduces residual variance → smaller SE\n",
    "- Increases statistical power\n",
    "- **Not** necessary for unbiasedness in RCT\n",
    "\n",
    "**Key insight**: In an RCT, controls aren't needed for unbiasedness (treatment is random), but they help with precision. A variable that strongly predicts Y will reduce SE even if it has zero correlation with T.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q2: Why might adding a control variable INCREASE standard errors?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "A control variable increases SE when it **predicts T more than it predicts Y** (after conditioning on T).\n",
    "\n",
    "**Mathematical reason**:\n",
    "$$SE(\\hat{\\beta}_T) \\propto \\frac{\\sigma_{\\epsilon}}{\\sqrt{\\text{Var}(\\tilde{T})}}$$\n",
    "\n",
    "If X predicts T:\n",
    "- $\\text{Var}(\\tilde{T}) = \\text{Var}(T) \\cdot (1 - R^2_{T \\sim X})$ decreases\n",
    "- Denominator shrinks → SE increases\n",
    "\n",
    "This is why we call these \"bad controls\" even if they're pre-treatment—they reduce the effective variation in treatment.\n",
    "\n",
    "**Example**: Controlling for \"intention to treat\" in a drug trial. It predicts T (compliance) but not Y|T.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q3: How does FWL explain the variance reduction from controls?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "FWL shows that $\\hat{\\beta}_T$ from the full regression equals the coefficient from:\n",
    "\n",
    "$$\\tilde{Y} = \\beta_T \\tilde{T} + \\epsilon$$\n",
    "\n",
    "where $\\tilde{Y}$ and $\\tilde{T}$ are residuals after partialling out X.\n",
    "\n",
    "**Variance reduction mechanism**:\n",
    "\n",
    "1. If X predicts Y: $\\text{Var}(\\tilde{Y}) < \\text{Var}(Y)$\n",
    "   - Less \"noise\" in outcome → cleaner signal\n",
    "   - Residual variance in final regression is smaller\n",
    "\n",
    "2. If X predicts T: $\\text{Var}(\\tilde{T}) < \\text{Var}(T)$\n",
    "   - Less variation in treatment → harder to identify effect\n",
    "   - Denominator shrinks → SE increases\n",
    "\n",
    "**Net effect** depends on relative predictive power for Y vs T.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[^1]: Facure, M. (2022). *Causal Inference for the Brave and True*, Chapter 7.\n",
    "\n",
    "[^2]: Angrist, J. D., & Pischke, J.-S. (2009). *Mostly Harmless Econometrics*, Section 3.2.3.\n",
    "\n",
    "[^3]: Cross-reference: FWL theorem in `05_linear_regression/02_regression_theory.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}