{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPTW Practical Issues: Positivity and Variance\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition)\n",
    "2. [Formal Treatment](#formal)\n",
    "3. [Numeric Demonstration](#numeric)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Interview Appendix](#interview)\n",
    "6. [References](#references)\n",
    "\n",
    "---\n",
    "\n",
    "**Appendix A3 | Notebook 2 of 2**\n",
    "\n",
    "This notebook covers practical challenges with IPTW: extreme propensity\n",
    "scores causing high variance, positivity violations, and remediation\n",
    "strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent to path for imports\n",
    "module_path = str(Path.cwd().parent.parent)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "\n",
    "from facure_augment.common import *\n",
    "set_notebook_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Intuition {#intuition}\n",
    "\n",
    "### The Extreme Weight Problem\n",
    "\n",
    "**Scenario**: Unit with propensity score = 0.03 but received treatment.\n",
    "\n",
    "**Weight**: 1/0.03 ≈ 33\n",
    "\n",
    "**Problem**: This one unit counts as much as 33 typical units!\n",
    "\n",
    "**Consequences**:\n",
    "- Dataset dominated by few high-weight units\n",
    "- High variance in ATE estimate\n",
    "- Sensitivity to individual observations\n",
    "\n",
    "### Positivity Violations\n",
    "\n",
    "**Positivity assumption**: $0 < e(X) < 1$ for all X.\n",
    "\n",
    "**Violation examples**:\n",
    "- Email-3 only sent to customers age > 40\n",
    "- Premium product never offered to low-income segment\n",
    "- Medical treatment contraindicated for certain patients\n",
    "\n",
    "**Implications**:\n",
    "- Cannot estimate effect for excluded subpopulation\n",
    "- Infinite weights for boundary cases\n",
    "- Must restrict to common support region\n",
    "\n",
    "```\n",
    "★ Insight ─────────────────────────────────────────────────────\n",
    "Positivity issues are DATA problems, not METHOD problems.\n",
    "\n",
    "IPTW doesn't cause the issue - it reveals it!\n",
    "Other methods hide positivity violations but suffer same bias.\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment {#formal}\n",
    "\n",
    "### 2.1 Variance of IPTW Estimator\n",
    "\n",
    "For the Horvitz-Thompson estimator:\n",
    "\n",
    "$$\\text{Var}(\\hat{\\mu}_1^{HT}) = \\frac{1}{n} E\\left[\\frac{\\text{Var}(Y|X,T=1)}{e(X)} + \\frac{(\\mu_1(X) - \\mu_1)^2}{e(X)}\\right]$$\n",
    "\n",
    "**Key insight**: Variance inversely proportional to $e(X)$.\n",
    "\n",
    "- Small $e(X)$ → large variance contribution\n",
    "- Extreme PS → extreme variance\n",
    "\n",
    "### 2.2 Effective Sample Size\n",
    "\n",
    "With normalized weights $\\tilde{w}_i = w_i / \\sum_j w_j$:\n",
    "\n",
    "$$n_{eff} = \\frac{(\\sum_i w_i)^2}{\\sum_i w_i^2} = \\frac{1}{\\sum_i \\tilde{w}_i^2}$$\n",
    "\n",
    "**Interpretation**: Equivalent number of equally-weighted observations.\n",
    "\n",
    "**Example**:\n",
    "- 1000 units with equal weights → $n_{eff} = 1000$\n",
    "- 1000 units but one has weight 100 → $n_{eff} \\approx 100$\n",
    "\n",
    "### 2.3 Positivity (Common Support)\n",
    "\n",
    "**Strict positivity**:\n",
    "$$\\exists \\epsilon > 0: \\epsilon < e(X) < 1-\\epsilon \\quad \\forall X$$\n",
    "\n",
    "**Practical positivity**:\n",
    "$$P(e(X) < \\epsilon \\text{ or } e(X) > 1-\\epsilon) \\text{ is small}$$\n",
    "\n",
    "### 2.4 Weight Trimming\n",
    "\n",
    "**Clip weights at maximum**:\n",
    "$$\\tilde{w}_i = \\min(w_i, c)$$\n",
    "\n",
    "where $c$ is a threshold (e.g., 10 or 20).\n",
    "\n",
    "**Trade-off**:\n",
    "- Reduces variance\n",
    "- Introduces bias\n",
    "- Changes target estimand\n",
    "\n",
    "### 2.5 Restricting to Common Support\n",
    "\n",
    "**Drop units outside overlap region**:\n",
    "$$\\text{Keep if } \\epsilon < e(X) < 1-\\epsilon$$\n",
    "\n",
    "**Estimand changes** from ATE to ATE on overlap population.\n",
    "\n",
    "```\n",
    "★ Key Result ──────────────────────────────────────────────────\n",
    "Weight trimming and restriction change the target estimand:\n",
    "\n",
    "- Original: ATE for entire population\n",
    "- After restriction: ATE for \"overlap population\"\n",
    "\n",
    "This is often acceptable - you're estimating effect for\n",
    "population where effect CAN be estimated.\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration {#numeric}\n",
    "\n",
    "### Extreme Weight Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with some extreme propensity scores\n",
    "np.random.seed(42)\n",
    "n = 5000\n",
    "\n",
    "# Customer characteristics\n",
    "age = np.random.uniform(25, 55, n)\n",
    "income = np.random.exponential(5000, n)\n",
    "insurance = np.random.exponential(20000, n)\n",
    "invested = np.random.exponential(10000, n)\n",
    "\n",
    "# Propensity scores with some extreme values\n",
    "em1_ps = 1 / (1 + np.exp(0.001*income + 0.0001*invested - 3))\n",
    "em1_ps = np.clip(em1_ps, 0.02, 0.98)  # Most in [0.02, 0.98]\n",
    "\n",
    "# But some VERY low PS for high-income units\n",
    "high_income_mask = income > 15000\n",
    "em1_ps[high_income_mask] = np.clip(em1_ps[high_income_mask], 0.01, 0.05)\n",
    "\n",
    "# Treatment assignment\n",
    "em1 = np.random.binomial(1, em1_ps)\n",
    "\n",
    "# Outcome (true effect = 0.05)\n",
    "convert_prob = 1 / (1 + np.exp(-0.1*age + 0.0001*income - 0.05*em1 - 2))\n",
    "converted = np.random.binomial(1, convert_prob)\n",
    "\n",
    "email = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'income': income,\n",
    "    'insurance': insurance,\n",
    "    'invested': invested,\n",
    "    'em1_ps': em1_ps,\n",
    "    'em1': em1,\n",
    "    'converted': converted\n",
    "})\n",
    "\n",
    "# Compute weights\n",
    "email['weight'] = np.where(\n",
    "    email['em1'] == 1,\n",
    "    1 / email['em1_ps'],\n",
    "    1 / (1 - email['em1_ps'])\n",
    ")\n",
    "\n",
    "print(\"Weight Distribution:\")\n",
    "print(email['weight'].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find extreme weight units\n",
    "extreme_units = email[email['weight'] > 20].sort_values('weight', ascending=False)\n",
    "\n",
    "print(f\"Units with weight > 20: {len(extreme_units)}\")\n",
    "print(f\"\\nTop 5 highest-weight units:\")\n",
    "print(extreme_units[['income', 'em1_ps', 'em1', 'weight', 'converted']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weight distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Weight histogram\n",
    "ax = axes[0]\n",
    "ax.hist(email['weight'], bins=50, color=COLORS['blue'], alpha=0.7, edgecolor='white')\n",
    "ax.axvline(x=20, color=COLORS['red'], linestyle='--', label='Threshold = 20')\n",
    "ax.set_xlabel('IPTW Weight')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of IPTW Weights\\n(Note the long right tail)')\n",
    "ax.legend()\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "# Weight vs PS\n",
    "ax = axes[1]\n",
    "treated = email[email['em1'] == 1]\n",
    "control = email[email['em1'] == 0]\n",
    "ax.scatter(treated['em1_ps'], treated['weight'], alpha=0.3, s=10, \n",
    "           color=COLORS['blue'], label='Treated')\n",
    "ax.scatter(control['em1_ps'], control['weight'], alpha=0.3, s=10, \n",
    "           color=COLORS['gray'], label='Control')\n",
    "ax.set_xlabel('Propensity Score')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_title('Weight vs Propensity Score\\n(Extreme weights at tails)')\n",
    "ax.legend()\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effective Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_sample_size(weights):\n",
    "    \"\"\"\n",
    "    Compute effective sample size from weights.\n",
    "    \n",
    "    n_eff = (sum w)^2 / sum(w^2)\n",
    "    \"\"\"\n",
    "    return (np.sum(weights)**2) / np.sum(weights**2)\n",
    "\n",
    "# Compute ESS\n",
    "n_actual = len(email)\n",
    "n_eff = effective_sample_size(email['weight'])\n",
    "\n",
    "print(\"Effective Sample Size Analysis:\")\n",
    "print(f\"  Actual sample size: {n_actual}\")\n",
    "print(f\"  Effective sample size: {n_eff:.0f}\")\n",
    "print(f\"  Efficiency: {100*n_eff/n_actual:.1f}%\")\n",
    "\n",
    "# ESS by treatment status\n",
    "n_eff_treated = effective_sample_size(treated['weight'])\n",
    "n_eff_control = effective_sample_size(control['weight'])\n",
    "\n",
    "print(f\"\\n  Treated: {len(treated)} → {n_eff_treated:.0f} effective\")\n",
    "print(f\"  Control: {len(control)} → {n_eff_control:.0f} effective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replication Count in Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample with IPTW weights\n",
    "np.random.seed(123)\n",
    "weights_normalized = email['weight'] / email['weight'].sum()\n",
    "indices = np.random.choice(len(email), size=10000, replace=True, p=weights_normalized)\n",
    "\n",
    "# Count replications\n",
    "unique, counts = np.unique(indices, return_counts=True)\n",
    "replication_counts = pd.DataFrame({'index': unique, 'count': counts})\n",
    "\n",
    "# Merge with original data\n",
    "email_with_counts = email.copy()\n",
    "email_with_counts['replication_count'] = 0\n",
    "for idx, count in zip(unique, counts):\n",
    "    email_with_counts.loc[idx, 'replication_count'] = count\n",
    "\n",
    "print(\"Replication count distribution:\")\n",
    "print(email_with_counts['replication_count'].describe().round(1))\n",
    "print(f\"\\nUnits appearing >10 times: {(email_with_counts['replication_count'] > 10).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize replication pattern\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    email_with_counts['em1_ps'], \n",
    "    email_with_counts['replication_count'],\n",
    "    c=email_with_counts['em1'],\n",
    "    cmap='coolwarm',\n",
    "    alpha=0.5,\n",
    "    s=20\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Propensity Score')\n",
    "ax.set_ylabel('Replication Count in Debiased Sample')\n",
    "ax.set_title('Replication Count vs Propensity Score\\n(Blue=Control, Red=Treated)')\n",
    "apply_tufte_style(ax)\n",
    "plt.colorbar(scatter, label='Treatment')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: Treated units with low PS and control units with high PS\")\n",
    "print(\"are replicated many times, dominating the pseudo-population.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positivity Violation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with positivity violation\n",
    "# Treatment (em3) only assigned to age > 40\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 5000\n",
    "\n",
    "age = np.random.uniform(25, 55, n)\n",
    "income = np.random.exponential(5000, n)\n",
    "\n",
    "# em3 propensity: 0 for age < 40, positive for age >= 40\n",
    "em3_ps = np.where(\n",
    "    age < 40,\n",
    "    0,  # ZERO probability for young customers\n",
    "    1 / (1 + np.exp(-0.1*age + 0.0001*income + 1))\n",
    ")\n",
    "em3_ps = np.clip(em3_ps, 0, 0.95)\n",
    "\n",
    "em3 = np.random.binomial(1, em3_ps)\n",
    "converted = np.random.binomial(1, 0.3 + 0.005*age + 0.05*em3)\n",
    "\n",
    "email_em3 = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'income': income,\n",
    "    'em3_ps': em3_ps,\n",
    "    'em3': em3,\n",
    "    'converted': converted\n",
    "})\n",
    "\n",
    "print(\"Positivity Violation Diagnosis:\")\n",
    "print(f\"  Customers age < 40: {(age < 40).sum()}\")\n",
    "print(f\"  Treated customers age < 40: {((age < 40) & (em3 == 1)).sum()}\")\n",
    "print(f\"  Customers with PS = 0: {(em3_ps == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize positivity violation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# PS distribution by treatment\n",
    "ax = axes[0]\n",
    "for em3_val, color, label in [(0, COLORS['gray'], 'Control'), (1, COLORS['blue'], 'Treated')]:\n",
    "    subset = email_em3[email_em3['em3'] == em3_val]['em3_ps']\n",
    "    subset_nonzero = subset[subset > 0]\n",
    "    if len(subset_nonzero) > 0:\n",
    "        ax.hist(subset_nonzero, bins=30, alpha=0.5, color=color, label=label, density=True)\n",
    "ax.axvline(x=0, color=COLORS['red'], linestyle='--', linewidth=2, \n",
    "           label=f'PS=0 (n={(em3_ps == 0).sum()})')\n",
    "ax.set_xlabel('Propensity Score')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Positivity Violation: Many Units with PS = 0')\n",
    "ax.legend()\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "# Age distribution by treatment\n",
    "ax = axes[1]\n",
    "for em3_val, color, label in [(0, COLORS['gray'], 'Control'), (1, COLORS['blue'], 'Treated')]:\n",
    "    subset = email_em3[email_em3['em3'] == em3_val]['age']\n",
    "    ax.hist(subset, bins=30, alpha=0.5, color=color, label=label, density=True)\n",
    "ax.axvline(x=40, color=COLORS['red'], linestyle='--', linewidth=2, label='Age cutoff')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('No Treated Units Below Age 40\\n(Cannot estimate effect for young)')\n",
    "ax.legend()\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation {#implementation}\n",
    "\n",
    "### Weight Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iptw_ate_trimmed(outcome, treatment, propensity_score, max_weight=None, \n",
    "                      ps_bounds=None, normalized=True):\n",
    "    \"\"\"\n",
    "    IPTW ATE with optional weight trimming and PS bounds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    outcome : array\n",
    "        Outcome variable\n",
    "    treatment : array\n",
    "        Binary treatment\n",
    "    propensity_score : array\n",
    "        Propensity scores\n",
    "    max_weight : float or None\n",
    "        Maximum allowed weight (clip above this)\n",
    "    ps_bounds : tuple or None\n",
    "        (lower, upper) bounds for PS (exclude units outside)\n",
    "    normalized : bool\n",
    "        Use Hajek estimator\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        ate, mu1, mu0, n_included, n_excluded\n",
    "    \"\"\"\n",
    "    T = np.asarray(treatment)\n",
    "    Y = np.asarray(outcome)\n",
    "    e = np.asarray(propensity_score)\n",
    "    \n",
    "    # Apply PS bounds (restriction to common support)\n",
    "    if ps_bounds is not None:\n",
    "        mask = (e >= ps_bounds[0]) & (e <= ps_bounds[1])\n",
    "    else:\n",
    "        mask = np.ones(len(Y), dtype=bool)\n",
    "    \n",
    "    T = T[mask]\n",
    "    Y = Y[mask]\n",
    "    e = e[mask]\n",
    "    \n",
    "    # Compute weights\n",
    "    weights = np.where(T == 1, 1 / e, 1 / (1 - e))\n",
    "    \n",
    "    # Apply weight trimming\n",
    "    if max_weight is not None:\n",
    "        weights = np.clip(weights, 0, max_weight)\n",
    "    \n",
    "    # Estimate\n",
    "    if normalized:\n",
    "        mu1 = np.sum(Y * T * weights) / np.sum(T * weights) if np.sum(T * weights) > 0 else np.nan\n",
    "        mu0 = np.sum(Y * (1 - T) * weights) / np.sum((1 - T) * weights) if np.sum((1 - T) * weights) > 0 else np.nan\n",
    "    else:\n",
    "        n = len(Y)\n",
    "        mu1 = np.sum(Y * T * weights) / n\n",
    "        mu0 = np.sum(Y * (1 - T) * weights) / n\n",
    "    \n",
    "    return {\n",
    "        'ate': mu1 - mu0,\n",
    "        'mu1': mu1,\n",
    "        'mu0': mu0,\n",
    "        'n_included': mask.sum(),\n",
    "        'n_excluded': (~mask).sum() if ps_bounds else 0\n",
    "    }\n",
    "\n",
    "# Compare approaches\n",
    "print(\"ATE Estimates with Different Approaches:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# No trimming\n",
    "result_raw = iptw_ate_trimmed(email['converted'], email['em1'], email['em1_ps'])\n",
    "print(f\"No trimming:           ATE = {result_raw['ate']:.4f}\")\n",
    "\n",
    "# Weight trimmed at 10\n",
    "result_trim10 = iptw_ate_trimmed(email['converted'], email['em1'], email['em1_ps'], max_weight=10)\n",
    "print(f\"Weight trimmed at 10:  ATE = {result_trim10['ate']:.4f}\")\n",
    "\n",
    "# Weight trimmed at 20\n",
    "result_trim20 = iptw_ate_trimmed(email['converted'], email['em1'], email['em1_ps'], max_weight=20)\n",
    "print(f\"Weight trimmed at 20:  ATE = {result_trim20['ate']:.4f}\")\n",
    "\n",
    "# PS bounds [0.05, 0.95]\n",
    "result_bounds = iptw_ate_trimmed(email['converted'], email['em1'], email['em1_ps'], ps_bounds=(0.05, 0.95))\n",
    "print(f\"PS bounds [.05, .95]:  ATE = {result_bounds['ate']:.4f} (n={result_bounds['n_included']}, excl={result_bounds['n_excluded']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Comparison via Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_iptw_ate(outcome, treatment, propensity_score, max_weight=None, \n",
    "                        n_bootstrap=500, seed=42):\n",
    "    \"\"\"\n",
    "    Bootstrap confidence interval for IPTW ATE.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n = len(outcome)\n",
    "    \n",
    "    estimates = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        result = iptw_ate_trimmed(\n",
    "            outcome[idx], treatment[idx], propensity_score[idx],\n",
    "            max_weight=max_weight, normalized=True\n",
    "        )\n",
    "        if not np.isnan(result['ate']):\n",
    "            estimates.append(result['ate'])\n",
    "    \n",
    "    estimates = np.array(estimates)\n",
    "    return {\n",
    "        'mean': np.mean(estimates),\n",
    "        'std': np.std(estimates),\n",
    "        'ci_lower': np.percentile(estimates, 2.5),\n",
    "        'ci_upper': np.percentile(estimates, 97.5)\n",
    "    }\n",
    "\n",
    "# Compare variance\n",
    "print(\"Bootstrap SE Comparison (500 bootstrap samples):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "Y = email['converted'].values\n",
    "T = email['em1'].values\n",
    "PS = email['em1_ps'].values\n",
    "\n",
    "for label, max_w in [('No trim', None), ('Trim at 10', 10), ('Trim at 20', 20)]:\n",
    "    boot = bootstrap_iptw_ate(Y, T, PS, max_weight=max_w, n_bootstrap=500)\n",
    "    print(f\"{label:15s}: ATE = {boot['mean']:.4f} (SE = {boot['std']:.4f}), \"\n",
    "          f\"95% CI = [{boot['ci_lower']:.4f}, {boot['ci_upper']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Positivity Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to common support region for em3 example\n",
    "print(\"Handling Positivity Violation for em3:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Full sample (problematic)\n",
    "try:\n",
    "    # Avoid division by zero\n",
    "    ps_safe = np.clip(email_em3['em3_ps'], 0.001, 0.999)\n",
    "    result_full = iptw_ate_trimmed(\n",
    "        email_em3['converted'], email_em3['em3'], ps_safe\n",
    "    )\n",
    "    print(f\"Full sample (problematic): ATE = {result_full['ate']:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Full sample error: {e}\")\n",
    "\n",
    "# Restrict to age >= 40 (where common support exists)\n",
    "email_restricted = email_em3[email_em3['age'] >= 40]\n",
    "result_restricted = iptw_ate_trimmed(\n",
    "    email_restricted['converted'], \n",
    "    email_restricted['em3'], \n",
    "    email_restricted['em3_ps']\n",
    ")\n",
    "print(f\"Restricted (age >= 40):    ATE = {result_restricted['ate']:.4f} (n={len(email_restricted)})\")\n",
    "\n",
    "# Check balance in restricted sample\n",
    "print(f\"\\nBalance check (restricted sample):\")\n",
    "print(f\"  Correlation (age, em3): {email_restricted['age'].corr(email_restricted['em3']):.3f}\")\n",
    "print(f\"  Correlation (income, em3): {email_restricted['income'].corr(email_restricted['em3']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize balance before/after restriction\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before restriction\n",
    "ax = axes[0]\n",
    "for em3_val, color, label in [(0, COLORS['gray'], 'Control'), (1, COLORS['blue'], 'Treated')]:\n",
    "    subset = email_em3[email_em3['em3'] == em3_val]['age']\n",
    "    ax.hist(subset, bins=30, alpha=0.5, color=color, label=label, density=True)\n",
    "ax.axvline(x=40, color=COLORS['red'], linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Full Sample: No Overlap Below Age 40')\n",
    "ax.legend()\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "# After restriction\n",
    "ax = axes[1]\n",
    "for em3_val, color, label in [(0, COLORS['gray'], 'Control'), (1, COLORS['blue'], 'Treated')]:\n",
    "    subset = email_restricted[email_restricted['em3'] == em3_val]['age']\n",
    "    ax.hist(subset, bins=20, alpha=0.5, color=color, label=label, density=True)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Restricted Sample (age >= 40): Good Overlap')\n",
    "ax.legend()\n",
    "apply_tufte_style(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "★ Key Takeaway ────────────────────────────────────────────────\n",
    "Practical IPTW Recommendations:\n",
    "\n",
    "1. **Check PS distribution** - Plot by treatment status\n",
    "2. **Calculate effective sample size** - Warn if < 0.5 × actual n\n",
    "3. **Consider trimming** - Trade-off bias vs variance\n",
    "4. **Restrict if needed** - Change estimand explicitly\n",
    "5. **Report sensitivity** - Show results with/without trimming\n",
    "\n",
    "**Golden rule**: Design experiments to avoid extreme PS!\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix {#interview}\n",
    "\n",
    "### Q1: What happens when propensity scores are very close to 0 or 1?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Mathematical problem**:\n",
    "- Weight = 1/PS for treated\n",
    "- PS → 0 means weight → ∞\n",
    "\n",
    "**Practical consequences**:\n",
    "\n",
    "1. **Extreme weights**\n",
    "   - Single unit dominates entire analysis\n",
    "   - Removing that unit changes results drastically\n",
    "\n",
    "2. **High variance**\n",
    "   - Effective sample size collapses\n",
    "   - Confidence intervals explode\n",
    "\n",
    "3. **Positivity violation**\n",
    "   - PS = 0 means some units NEVER get treatment\n",
    "   - Cannot estimate counterfactual for that subpopulation\n",
    "\n",
    "**Remedies**:\n",
    "\n",
    "| Approach | Pro | Con |\n",
    "|----------|-----|-----|\n",
    "| Weight trimming | Reduces variance | Introduces bias |\n",
    "| PS bounds | Clear estimand | Loses observations |\n",
    "| Doubly robust | More stable | Still needs overlap |\n",
    "| Better design | Root cause fix | Only for new experiments |\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q2: Should you trim weights or restrict the sample?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Weight trimming**:\n",
    "- Set max weight (e.g., 10 or 20)\n",
    "- Keeps all observations\n",
    "- Introduces bias toward over-trimmed group\n",
    "- Estimand unclear (\"approximate ATE\")\n",
    "\n",
    "**Sample restriction**:\n",
    "- Exclude units with extreme PS\n",
    "- Clear estimand: ATE on overlap population\n",
    "- Loses observations explicitly\n",
    "- More transparent about what you're estimating\n",
    "\n",
    "**Recommendation**:\n",
    "\n",
    "1. **Prefer restriction** when:\n",
    "   - Positivity is clearly violated (PS = 0)\n",
    "   - You're okay estimating effect for overlap population\n",
    "   - Academic setting requiring clear estimand\n",
    "\n",
    "2. **Consider trimming** when:\n",
    "   - No true positivity violation, just extreme weights\n",
    "   - Applied setting with variance concerns\n",
    "   - Report sensitivity to trimming threshold\n",
    "\n",
    "**Always**: Report both analyses as sensitivity check!\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q3: How do you check for positivity violations?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Visual checks**:\n",
    "\n",
    "1. **PS distribution by treatment**\n",
    "   ```python\n",
    "   sns.histplot(data=df, x='ps', hue='treatment', stat='density')\n",
    "   ```\n",
    "   - Good: Overlapping distributions\n",
    "   - Bad: Separated distributions, peaks at 0 or 1\n",
    "\n",
    "2. **Covariate distributions**\n",
    "   ```python\n",
    "   sns.pairplot(df[covariates + ['treatment']], hue='treatment')\n",
    "   ```\n",
    "   - Look for regions with only treated or only control\n",
    "\n",
    "**Quantitative checks**:\n",
    "\n",
    "1. **Min/max PS**\n",
    "   - Check min(PS) > ε and max(PS) < 1-ε\n",
    "   - Typical ε = 0.01 to 0.10\n",
    "\n",
    "2. **Effective sample size**\n",
    "   - n_eff = (Σw)² / Σw²\n",
    "   - If n_eff << n, positivity issues likely\n",
    "\n",
    "3. **Weight distribution**\n",
    "   - Check for extreme weights (> 20-50)\n",
    "   - Flag if >5% of sample has weight > 10\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q4: In practice, when is positivity violation acceptable?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Academic research**: Usually problematic\n",
    "- Need generalizable conclusions\n",
    "- Must be transparent about limited external validity\n",
    "\n",
    "**Industry applications**: Often acceptable!\n",
    "\n",
    "**Examples where it's fine**:\n",
    "\n",
    "1. **Targeted marketing**\n",
    "   - Email-3 designed for age > 40\n",
    "   - You don't WANT to estimate effect on young customers\n",
    "   - Business relevance > statistical purity\n",
    "\n",
    "2. **Lending decisions**\n",
    "   - Don't give large loans to high-risk customers\n",
    "   - Interest in effect for creditworthy borrowers\n",
    "   - Positivity violation is by design\n",
    "\n",
    "3. **Medical treatment**\n",
    "   - Drug contraindicated for certain patients\n",
    "   - Focus on eligible population\n",
    "   - Ethical to exclude contraindicated groups\n",
    "\n",
    "**Key principle**: Positivity violation is fine IF:\n",
    "- You're clear about the target population\n",
    "- You don't generalize beyond common support\n",
    "- The restricted population is policy-relevant\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q5: Why is IPTW good at revealing positivity problems?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**IPTW makes positivity problems explicit**:\n",
    "\n",
    "1. **Weights are observable**\n",
    "   - Can literally see w = 1/0.01 = 100\n",
    "   - Other methods hide this in matrix algebra\n",
    "\n",
    "2. **PS distribution is diagnostic**\n",
    "   - Simple plot reveals overlap\n",
    "   - Harder to visualize with regression adjustment\n",
    "\n",
    "3. **Effective sample size is calculable**\n",
    "   - Direct measure of information loss\n",
    "   - n_eff << n signals problem\n",
    "\n",
    "**Contrast with regression**:\n",
    "\n",
    "| IPTW | Regression |\n",
    "|------|------------|\n",
    "| Extreme weights visible | Hidden extrapolation |\n",
    "| PS plot diagnostic | Need to examine X space |\n",
    "| Fails obviously | Fails silently |\n",
    "\n",
    "**Quote (Imbens)**: \"Propensity score methods have the advantage of \n",
    "making the assumptions transparent and easy to assess.\"\n",
    "\n",
    "**Implication**: Even if you use regression, check propensity scores!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References {#references}\n",
    "\n",
    "[^1]: Crump, R. K., Hotz, V. J., Imbens, G. W., & Mitnik, O. A. (2009). Dealing with \n",
    "      Limited Overlap in Estimation of Average Treatment Effects. *Biometrika*.\n",
    "\n",
    "[^2]: Cole, S. R., & Hernan, M. A. (2008). Constructing Inverse Probability Weights \n",
    "      for Marginal Structural Models. *American Journal of Epidemiology*.\n",
    "\n",
    "[^3]: Petersen, M. L., Porter, K. E., Gruber, S., Wang, Y., & Van Der Laan, M. J. (2012). \n",
    "      Diagnosing and Responding to Violations in the Positivity Assumption. \n",
    "      *Statistical Methods in Medical Research*.\n",
    "\n",
    "[^4]: Facure, M. (2022). *Causal Inference for the Brave and True*, Appendix: \n",
    "      Debiasing with Propensity Score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
