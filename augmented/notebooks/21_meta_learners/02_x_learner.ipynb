{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 21.2 X-Learner\n",
    "\n",
    "**Chapter**: 21 - Meta-Learners  \n",
    "**Section**: 2 - X-Learner (Two-Stage with Propensity Weighting)  \n",
    "**Facure Source**: 21-Meta-Learners.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-16\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [The T-Learner Problem Revisited](#1-the-t-learner-problem-revisited)\n",
    "2. [X-Learner Architecture](#2-x-learner-architecture)\n",
    "   - 2.1 [Stage 1: T-Learner Models](#21-stage-1-t-learner-models)\n",
    "   - 2.2 [Stage 2: Imputed Effect Models](#22-stage-2-imputed-effect-models)\n",
    "   - 2.3 [Propensity Score Weighting](#23-propensity-score-weighting)\n",
    "3. [Implementation](#3-implementation)\n",
    "4. [Why It Works](#4-why-it-works)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import (\n",
    "    np, pd, plt, sm, stats,\n",
    "    load_facure_data,\n",
    "    set_notebook_style,\n",
    "    create_tufte_figure,\n",
    "    apply_tufte_style,\n",
    "    TUFTE_PALETTE,\n",
    "    COLORS,\n",
    ")\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "set_notebook_style()\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = load_facure_data('invest_email_biased.csv')\n",
    "test = load_facure_data('invest_email_rnd.csv')\n",
    "\n",
    "y = 'converted'\n",
    "T = 'em1'\n",
    "X = ['age', 'income', 'insurance', 'invested']\n",
    "\n",
    "print(f\"Training: {len(train):,} samples\")\n",
    "print(f\"Testing: {len(test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition: The T-Learner Problem\n",
    "\n",
    "> **Recall**: T-learner fails with imbalanced groups because different regularization levels create spurious heterogeneity.\n",
    "\n",
    "The X-Learner solves this by:\n",
    "1. **Imputing** treatment effects using counterfactual predictions\n",
    "2. **Weighting** models by propensity score to favor reliable estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3_split",
   "metadata": {},
   "source": [
    "## 2. Formal Treatment: X-Learner Architecture\n",
    "\n",
    "```\n",
    "X-Learner (Kunzel et al. 2019) ─────────────────────────────\n",
    "\n",
    "STAGE 1: T-Learner (same as before)\n",
    "──────────────────────────────────\n",
    "Control data → μ̂₀(x) = E[Y | X, T=0]\n",
    "Treated data → μ̂₁(x) = E[Y | X, T=1]\n",
    "\n",
    "STAGE 2: Imputed Effects\n",
    "────────────────────────\n",
    "For control units: τ̃(X, T=0) = μ̂₁(X) - Y  (what they would have gained)\n",
    "For treated units: τ̃(X, T=1) = Y - μ̂₀(X)  (what they actually gained)\n",
    "\n",
    "Fit models on these imputed effects:\n",
    "  M_τ0 ≈ E[τ̃ | X, T=0]   (effect model from control imputation)\n",
    "  M_τ1 ≈ E[τ̃ | X, T=1]   (effect model from treated imputation)\n",
    "\n",
    "STAGE 3: Propensity-Weighted Combination\n",
    "────────────────────────────────────────\n",
    "e(x) = P(T=1 | X)  (propensity score)\n",
    "\n",
    "τ̂(x) = e(x) · M_τ0(x) + (1-e(x)) · M_τ1(x)\n",
    "\n",
    "↳ When treatment is rare: e(x) small → favors M_τ1 (from treated data)\n",
    "↳ When treatment is common: 1-e(x) small → favors M_τ0 (from control data)\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### 2.1 Stage 1: T-Learner Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Same as T-learner\n",
    "np.random.seed(123)\n",
    "\n",
    "m0 = LGBMRegressor(max_depth=2, min_child_samples=30, n_estimators=100, verbose=-1)\n",
    "m1 = LGBMRegressor(max_depth=2, min_child_samples=30, n_estimators=100, verbose=-1)\n",
    "\n",
    "# Fit on subsets\n",
    "m0.fit(train.query(f\"{T}==0\")[X], train.query(f\"{T}==0\")[y])\n",
    "m1.fit(train.query(f\"{T}==1\")[X], train.query(f\"{T}==1\")[y])\n",
    "\n",
    "# Also fit propensity score model\n",
    "g = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "g.fit(train[X], train[T])\n",
    "\n",
    "print(\"Stage 1 complete:\")\n",
    "print(f\"  mu0 trained on {(train[T]==0).sum():,} control samples\")\n",
    "print(f\"  mu1 trained on {(train[T]==1).sum():,} treated samples\")\n",
    "print(f\"  Propensity model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### 2.2 Stage 2: Imputed Effect Models\n",
    "\n",
    "**Key insight**: We impute treatment effects using counterfactual predictions:\n",
    "\n",
    "- For **control** units: $\\tilde{\\tau}(X, T=0) = \\hat{\\mu}_1(X) - Y$\n",
    "  - \"How much would this control unit have gained if treated?\"\n",
    "  - Uses the treated model to predict counterfactual\n",
    "\n",
    "- For **treated** units: $\\tilde{\\tau}(X, T=1) = Y - \\hat{\\mu}_0(X)$\n",
    "  - \"How much did this treated unit actually gain vs. if untreated?\"\n",
    "  - Uses the control model to predict counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Impute treatment effects\n",
    "\n",
    "# For control: imputed effect = what they would have gotten - what they got\n",
    "# For treated: imputed effect = what they got - what they would have gotten\n",
    "d_train = np.where(\n",
    "    train[T] == 0,\n",
    "    m1.predict(train[X]) - train[y],  # Control: mu1(x) - Y\n",
    "    train[y] - m0.predict(train[X])   # Treated: Y - mu0(x)\n",
    ")\n",
    "\n",
    "print(\"Imputed treatment effects:\")\n",
    "print(f\"  For control units: mean={d_train[train[T]==0].mean():.4f}\")\n",
    "print(f\"  For treated units: mean={d_train[train[T]==1].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit second-stage models on imputed effects\n",
    "mx0 = LGBMRegressor(max_depth=2, min_child_samples=30, n_estimators=100, verbose=-1)\n",
    "mx1 = LGBMRegressor(max_depth=2, min_child_samples=30, n_estimators=100, verbose=-1)\n",
    "\n",
    "# M_tau0: effect model trained on control imputation\n",
    "mx0.fit(train.query(f\"{T}==0\")[X], d_train[train[T]==0])\n",
    "\n",
    "# M_tau1: effect model trained on treated imputation\n",
    "mx1.fit(train.query(f\"{T}==1\")[X], d_train[train[T]==1])\n",
    "\n",
    "print(\"Stage 2 complete: second-stage effect models fitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 2.3 Propensity Score Weighting\n",
    "\n",
    "The final CATE combines both models, weighted by propensity:\n",
    "\n",
    "$$\\hat{\\tau}(x) = \\hat{e}(x) \\cdot M_{\\tau 0}(x) + (1 - \\hat{e}(x)) \\cdot M_{\\tau 1}(x)$$\n",
    "\n",
    "**Why this weighting?**\n",
    "\n",
    "- $M_{\\tau 0}$ uses treated model predictions → reliable when treated group is large\n",
    "- $M_{\\tau 1}$ uses control model predictions → reliable when control group is large\n",
    "- Propensity $e(x)$ tells us which group is larger for units like $x$\n",
    "- Weight toward the model that uses the larger group's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_learner_cate(mx0, mx1, g, df, X):\n",
    "    \"\"\"\n",
    "    Compute CATE using X-learner.\n",
    "    \n",
    "    tau(x) = e(x) * M_tau0(x) + (1-e(x)) * M_tau1(x)\n",
    "    \"\"\"\n",
    "    ps = g.predict_proba(df[X])[:, 1]  # e(x) = P(T=1|X)\n",
    "    \n",
    "    # Weight by propensity score\n",
    "    # e(x) weights M_tau0 (uses mu1 predictions)\n",
    "    # (1-e(x)) weights M_tau1 (uses mu0 predictions)\n",
    "    cate = ps * mx0.predict(df[X]) + (1 - ps) * mx1.predict(df[X])\n",
    "    \n",
    "    return cate\n",
    "\n",
    "# Compute CATE\n",
    "cate_x_train = x_learner_cate(mx0, mx1, g, train, X)\n",
    "cate_x_test = x_learner_cate(mx0, mx1, g, test, X)\n",
    "\n",
    "print(f\"X-Learner CATE statistics (test set):\")\n",
    "print(f\"  Mean:   {cate_x_test.mean():.4f}\")\n",
    "print(f\"  Std:    {cate_x_test.std():.4f}\")\n",
    "print(f\"  Min:    {cate_x_test.min():.4f}\")\n",
    "print(f\"  Max:    {cate_x_test.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration: Implementation\n",
    "\n",
    "Let's put it all together in a clean class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLearner:\n",
    "    \"\"\"\n",
    "    X-Learner for CATE estimation.\n",
    "    \n",
    "    Two-stage meta-learner that addresses T-learner's\n",
    "    sample imbalance problem using propensity weighting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_model : sklearn estimator\n",
    "        Base model for outcome prediction (default: LGBMRegressor)\n",
    "    propensity_model : sklearn classifier\n",
    "        Model for propensity score (default: LogisticRegression)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_model=None, propensity_model=None):\n",
    "        from sklearn.base import clone\n",
    "        \n",
    "        if base_model is None:\n",
    "            base_model = LGBMRegressor(max_depth=3, n_estimators=100, verbose=-1)\n",
    "        if propensity_model is None:\n",
    "            propensity_model = LogisticRegression(max_iter=1000)\n",
    "        \n",
    "        # Stage 1 models\n",
    "        self.m0 = clone(base_model)\n",
    "        self.m1 = clone(base_model)\n",
    "        \n",
    "        # Stage 2 models\n",
    "        self.mx0 = clone(base_model)\n",
    "        self.mx1 = clone(base_model)\n",
    "        \n",
    "        # Propensity model\n",
    "        self.g = clone(propensity_model)\n",
    "    \n",
    "    def fit(self, X, T, Y):\n",
    "        \"\"\"\n",
    "        Fit X-learner.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "        T : array-like of shape (n_samples,) - binary treatment\n",
    "        Y : array-like of shape (n_samples,) - outcome\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        T = np.asarray(T)\n",
    "        Y = np.asarray(Y)\n",
    "        \n",
    "        # Stage 1: T-learner\n",
    "        self.m0.fit(X[T == 0], Y[T == 0])\n",
    "        self.m1.fit(X[T == 1], Y[T == 1])\n",
    "        \n",
    "        # Propensity score\n",
    "        self.g.fit(X, T)\n",
    "        \n",
    "        # Stage 2: Imputed effects\n",
    "        d = np.where(\n",
    "            T == 0,\n",
    "            self.m1.predict(X) - Y,  # Control\n",
    "            Y - self.m0.predict(X)   # Treated\n",
    "        )\n",
    "        \n",
    "        self.mx0.fit(X[T == 0], d[T == 0])\n",
    "        self.mx1.fit(X[T == 1], d[T == 1])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict CATE.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        cate : array of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        ps = self.g.predict_proba(X)[:, 1]\n",
    "        return ps * self.mx0.predict(X) + (1 - ps) * self.mx1.predict(X)\n",
    "\n",
    "print(\"XLearner class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the class\n",
    "xl = XLearner()\n",
    "xl.fit(train[X].values, train[T].values, train[y].values)\n",
    "cate_xl = xl.predict(test[X].values)\n",
    "\n",
    "print(f\"XLearner CATE: mean={cate_xl.mean():.4f}, std={cate_xl.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation: Why It Works\n",
    "\n",
    "Let's demonstrate on the imbalanced simulation from notebook 01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate imbalanced data\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 2000\n",
    "X_imb = np.random.uniform(0, 1, (n, 1))\n",
    "T_imb = np.random.binomial(1, 0.1, n)  # Only 10% treated\n",
    "true_cate_const = 1.0  # Constant CATE\n",
    "Y_imb = np.sin(2 * np.pi * X_imb[:, 0]) + T_imb * true_cate_const + np.random.normal(0, 0.3, n)\n",
    "\n",
    "print(f\"Imbalanced data: {T_imb.sum()} treated ({T_imb.mean():.1%}), {n-T_imb.sum()} control\")\n",
    "print(f\"True CATE = {true_cate_const} (constant!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare T-learner vs X-learner on imbalanced data\n",
    "\n",
    "# T-learner\n",
    "m0_t = LGBMRegressor(max_depth=5, n_estimators=100, verbose=-1, random_state=42)\n",
    "m1_t = LGBMRegressor(max_depth=5, n_estimators=100, verbose=-1, random_state=42)\n",
    "m0_t.fit(X_imb[T_imb==0], Y_imb[T_imb==0])\n",
    "m1_t.fit(X_imb[T_imb==1], Y_imb[T_imb==1])\n",
    "cate_t = m1_t.predict(X_imb) - m0_t.predict(X_imb)\n",
    "\n",
    "# X-learner\n",
    "xl_imb = XLearner(\n",
    "    base_model=LGBMRegressor(max_depth=5, n_estimators=100, verbose=-1, random_state=42)\n",
    ")\n",
    "xl_imb.fit(X_imb, T_imb, Y_imb)\n",
    "cate_x = xl_imb.predict(X_imb)\n",
    "\n",
    "print(f\"T-Learner: mean={cate_t.mean():.3f}, std={cate_t.std():.3f}\")\n",
    "print(f\"X-Learner: mean={cate_x.mean():.3f}, std={cate_x.std():.3f}\")\n",
    "print(f\"Truth:     mean={true_cate_const:.3f}, std=0.000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the improvement\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 5))\n",
    "\n",
    "X_grid = np.linspace(0, 1, 200).reshape(-1, 1)\n",
    "\n",
    "# T-learner\n",
    "ax = axes[0]\n",
    "cate_t_grid = m1_t.predict(X_grid) - m0_t.predict(X_grid)\n",
    "ax.plot(X_grid, cate_t_grid, c=COLORS['red'], lw=2.5, label='T-Learner CATE')\n",
    "ax.axhline(true_cate_const, c='black', ls='--', lw=2, label=f'True CATE = {true_cate_const}')\n",
    "ax.fill_between(X_grid.flatten(), true_cate_const, cate_t_grid.flatten(), \n",
    "                alpha=0.3, color=COLORS['red'], label='Error')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('CATE')\n",
    "ax.set_title('(a) T-Learner: Spurious Heterogeneity', fontweight='bold')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "ax.set_ylim(-0.5, 2.5)\n",
    "\n",
    "# X-learner\n",
    "ax = axes[1]\n",
    "cate_x_grid = xl_imb.predict(X_grid)\n",
    "ax.plot(X_grid, cate_x_grid, c=COLORS['green'], lw=2.5, label='X-Learner CATE')\n",
    "ax.axhline(true_cate_const, c='black', ls='--', lw=2, label=f'True CATE = {true_cate_const}')\n",
    "ax.fill_between(X_grid.flatten(), true_cate_const, cate_x_grid.flatten(), \n",
    "                alpha=0.3, color=COLORS['green'], label='Error')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('CATE')\n",
    "ax.set_title('(b) X-Learner: Much Flatter!', fontweight='bold')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "ax.set_ylim(-0.5, 2.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_t = np.sqrt(np.mean((cate_t - true_cate_const)**2))\n",
    "rmse_x = np.sqrt(np.mean((cate_x - true_cate_const)**2))\n",
    "print(f\"\\nRMSE:\")\n",
    "print(f\"  T-Learner: {rmse_t:.3f}\")\n",
    "print(f\"  X-Learner: {rmse_x:.3f}\")\n",
    "print(f\"  Improvement: {(1 - rmse_x/rmse_t)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "```\n",
    "Why X-Learner Works ──────────────────────────────────────────\n",
    "\n",
    "In our imbalanced example (10% treated, 90% control):\n",
    "\n",
    "1. μ̂₀ (control model) learns the nonlinear sin(2πx) pattern well\n",
    "   (trained on 1800 samples)\n",
    "\n",
    "2. μ̂₁ (treated model) is linear due to regularization\n",
    "   (trained on only 200 samples)\n",
    "\n",
    "3. Imputed effects for TREATED units:\n",
    "   τ̃(T=1) = Y - μ̂₀(X) = [sin(x) + 1 + ε] - sin(x) ≈ 1 ✓\n",
    "   → Uses the GOOD model (μ̂₀)!\n",
    "\n",
    "4. Imputed effects for CONTROL units:\n",
    "   τ̃(T=0) = μ̂₁(X) - Y = linear - sin(x) ✗\n",
    "   → Uses the BAD model (μ̂₁)\n",
    "\n",
    "5. Propensity weighting:\n",
    "   e(x) ≈ 0.1 (treatment is rare)\n",
    "   τ̂(x) = 0.1 * M_τ0(x) + 0.9 * M_τ1(x)\n",
    "   → Heavily weights M_τ1 (from treated imputation, which is GOOD)\n",
    "\n",
    "Result: X-learner \"knows\" to trust the estimate that uses\n",
    "        the large control model for counterfactual prediction.\n",
    "──────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1 (Meta E6, DS)**: *\"Walk me through the X-learner algorithm and explain why it handles sample imbalance better than T-learner.\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**X-Learner Algorithm (3 stages)**:\n",
    "\n",
    "**Stage 1 (T-learner)**:\n",
    "- Fit $\\hat{\\mu}_0(x) = E[Y|X, T=0]$ on control\n",
    "- Fit $\\hat{\\mu}_1(x) = E[Y|X, T=1]$ on treated\n",
    "\n",
    "**Stage 2 (Imputed effects)**:\n",
    "- For control: $\\tilde{\\tau}_0 = \\hat{\\mu}_1(X) - Y$ (counterfactual gain)\n",
    "- For treated: $\\tilde{\\tau}_1 = Y - \\hat{\\mu}_0(X)$ (actual gain)\n",
    "- Fit $M_{\\tau 0}$ on control imputed effects\n",
    "- Fit $M_{\\tau 1}$ on treated imputed effects\n",
    "\n",
    "**Stage 3 (Propensity weighting)**:\n",
    "- $\\hat{\\tau}(x) = e(x) \\cdot M_{\\tau 0}(x) + (1-e(x)) \\cdot M_{\\tau 1}(x)$\n",
    "\n",
    "**Why it handles imbalance**:\n",
    "\n",
    "Consider 10% treated, 90% control:\n",
    "- $\\hat{\\mu}_0$ is accurate (many samples)\n",
    "- $\\hat{\\mu}_1$ is regularized (few samples)\n",
    "- $\\tilde{\\tau}_1 = Y - \\hat{\\mu}_0$ uses the GOOD model\n",
    "- $\\tilde{\\tau}_0 = \\hat{\\mu}_1 - Y$ uses the BAD model\n",
    "- Propensity $e(x) \\approx 0.1$ → weights $M_{\\tau 1}$ heavily\n",
    "- Final estimate dominated by the reliable model!\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q2 (Amazon L6)**: *\"What's the intuition behind the propensity score weighting in X-learner?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Intuition**: Weight toward the model trained using predictions from the larger group.\n",
    "\n",
    "**Details**:\n",
    "- $M_{\\tau 0}$ is fit on imputed effects for control, which uses $\\hat{\\mu}_1$ predictions\n",
    "- $M_{\\tau 1}$ is fit on imputed effects for treated, which uses $\\hat{\\mu}_0$ predictions\n",
    "\n",
    "The quality of imputed effects depends on the counterfactual model:\n",
    "- If treated group is small → $\\hat{\\mu}_1$ is poor → $M_{\\tau 0}$ unreliable\n",
    "- If control group is small → $\\hat{\\mu}_0$ is poor → $M_{\\tau 1}$ unreliable\n",
    "\n",
    "Propensity score tells us relative group sizes:\n",
    "- $e(x) = P(T=1|X)$ small → treatment rare → small treated group → trust $M_{\\tau 1}$\n",
    "- $e(x)$ large → treatment common → small control group → trust $M_{\\tau 0}$\n",
    "\n",
    "The weighting formula achieves exactly this:\n",
    "$$\\hat{\\tau}(x) = \\underbrace{e(x)}_{\\text{small}} \\cdot M_{\\tau 0} + \\underbrace{(1-e(x))}_{\\text{large}} \\cdot M_{\\tau 1}$$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Kunzel, S. R., Sekhon, J. S., Bickel, P. J., and Yu, B. (2019). Metalearners for estimating heterogeneous treatment effects using machine learning. *PNAS*, 116(10), 4156-4165.\n",
    "\n",
    "[^2]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 21: \"Meta-Learners.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: [03. Meta-Learner Comparison](./03_meta_learner_comparison.ipynb) — Evaluating and choosing between learners"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
