{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.4 Omitted Variable Bias\n",
    "\n",
    "**Chapter**: 5 - The Unreasonable Effectiveness of Linear Regression  \n",
    "**Section**: 4 - Omitted Variable or Confounding Bias  \n",
    "**Facure Source**: 05-The-Unreasonable-Effectiveness-of-Linear-Regression.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-09\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Facure's Intuition](#1-facures-intuition)\n",
    "   - 1.1 [The Angrist Mantra](#11-the-angrist-mantra)\n",
    "   - 1.2 [Confounders and DAGs](#12-confounders-and-dags)\n",
    "2. [Formal Treatment](#2-formal-treatment)\n",
    "   - 2.1 [The OVB Formula](#21-the-ovb-formula)\n",
    "   - 2.2 [Proof of OVB Formula](#22-proof-of-ovb-formula)\n",
    "   - 2.3 [Sign of Bias](#23-sign-of-bias)\n",
    "3. [Numeric Demonstration](#3-numeric-demonstration)\n",
    "   - 3.1 [Simulating OVB](#31-simulating-ovb)\n",
    "   - 3.2 [Verifying the Formula](#32-verifying-the-formula)\n",
    "4. [Implementation](#4-implementation)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports via common module\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import (\n",
    "    np, pd, plt, sm,\n",
    "    load_facure_data,\n",
    "    set_notebook_style,\n",
    "    create_tufte_figure,\n",
    "    TUFTE_PALETTE,\n",
    ")\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "set_notebook_style()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition\n",
    "\n",
    "> **Interview Relevance**: The OVB formula is one of the most-asked concepts in econometrics interviews. You should be able to derive it, interpret the sign, and give examples.\n",
    "\n",
    "### 1.1 The Angrist Mantra\n",
    "\n",
    "Facure highlights Joshua Angrist's famous mantra for remembering OVB:\n",
    "\n",
    "> **\"Short equals long plus the effect of omitted times the regression of omitted on included.\"**\n",
    "\n",
    "In symbols, if the true model is:\n",
    "\n",
    "$$Y = \\beta_0 + \\kappa T + \\gamma A + \\epsilon$$\n",
    "\n",
    "But we estimate the \"short\" regression (omitting $A$):\n",
    "\n",
    "$$Y = \\beta_0 + \\hat{\\kappa}_{short} T + e$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\hat{\\kappa}_{short} = \\kappa + \\gamma \\cdot \\delta$$\n",
    "\n",
    "where $\\delta$ is the coefficient from regressing $A$ on $T$.\n",
    "\n",
    "### 1.2 Confounders and DAGs\n",
    "\n",
    "**Confounder**: A variable that causes both the treatment and the outcome.\n",
    "\n",
    "Facure's examples:\n",
    "\n",
    "**Example 1: Education → Wages (positive bias)**\n",
    "- IQ → Education (positive)\n",
    "- IQ → Wages (positive)\n",
    "- Bias = (+)(+) = positive → overestimate education effect\n",
    "\n",
    "**Example 2: Police → Violence (negative bias)**\n",
    "- Crime → Police (positive)\n",
    "- Crime → Violence (positive)\n",
    "- But Police → Violence might be negative\n",
    "- Omitting Crime causes bias that makes police look harmful\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Bias = 0 if omitted doesn't affect outcome (γ = 0)\n",
    "- Bias = 0 if omitted uncorrelated with treatment (δ = 0, as in RCT!)\n",
    "- Sign of bias = sign(γ) × sign(δ)\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment\n",
    "\n",
    "### 2.1 The OVB Formula\n",
    "\n",
    "**Theorem (Omitted Variable Bias)**:\n",
    "\n",
    "Let the true data-generating process be:\n",
    "\n",
    "$$Y_i = \\beta_0 + \\kappa T_i + \\gamma A_i + \\epsilon_i$$\n",
    "\n",
    "where $E[\\epsilon | T, A] = 0$.\n",
    "\n",
    "If we estimate the \"short\" regression omitting $A$:\n",
    "\n",
    "$$Y_i = \\tilde{\\beta}_0 + \\tilde{\\kappa} T_i + u_i$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\boxed{\\text{plim } \\tilde{\\kappa} = \\kappa + \\gamma \\cdot \\delta}$$\n",
    "\n",
    "where $\\delta = \\frac{\\text{Cov}(A, T)}{\\text{Var}(T)}$ is the population coefficient from regressing $A$ on $T$.\n",
    "\n",
    "### 2.2 Proof of OVB Formula\n",
    "\n",
    "**Proof**:\n",
    "\n",
    "The short regression coefficient (in population) is:\n",
    "\n",
    "$$\\tilde{\\kappa} = \\frac{\\text{Cov}(Y, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "Substitute $Y = \\beta_0 + \\kappa T + \\gamma A + \\epsilon$:\n",
    "\n",
    "$$\\tilde{\\kappa} = \\frac{\\text{Cov}(\\kappa T + \\gamma A + \\epsilon, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "Since $\\text{Cov}(\\epsilon, T) = 0$ by assumption:\n",
    "\n",
    "$$= \\frac{\\kappa \\text{Var}(T) + \\gamma \\text{Cov}(A, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "$$= \\kappa + \\gamma \\cdot \\frac{\\text{Cov}(A, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "$$= \\kappa + \\gamma \\cdot \\delta \\quad \\blacksquare$$\n",
    "\n",
    "### 2.3 Sign of Bias\n",
    "\n",
    "The bias term $\\gamma \\cdot \\delta$ has sign equal to:\n",
    "\n",
    "$$\\text{sign}(\\text{Bias}) = \\text{sign}(\\gamma) \\times \\text{sign}(\\delta)$$\n",
    "\n",
    "| $\\gamma$ (omitted → Y) | $\\delta$ (omitted ↔ T) | Bias direction |\n",
    "|:----------------------:|:----------------------:|:--------------:|\n",
    "| + | + | Positive (overestimate) |\n",
    "| + | − | Negative (underestimate) |\n",
    "| − | + | Negative (underestimate) |\n",
    "| − | − | Positive (overestimate) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration\n",
    "\n",
    "### 3.1 Simulating OVB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data with known DGP\n",
    "n = 5000\n",
    "\n",
    "# True parameters\n",
    "kappa_true = 2.0    # True effect of T on Y\n",
    "gamma_true = 3.0    # Effect of confounder A on Y\n",
    "delta_true = 0.5    # Correlation of A with T\n",
    "\n",
    "# Generate data\n",
    "# Confounder A (unobserved in short regression)\n",
    "A = np.random.normal(0, 1, n)\n",
    "\n",
    "# Treatment T (correlated with A)\n",
    "T = delta_true * A + np.random.normal(0, np.sqrt(1 - delta_true**2), n)\n",
    "\n",
    "# Outcome Y\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "Y = kappa_true * T + gamma_true * A + epsilon\n",
    "\n",
    "sim_data = pd.DataFrame({'Y': Y, 'T': T, 'A': A})\n",
    "\n",
    "print(\"Simulated DGP\")\n",
    "print(\"=\"*50)\n",
    "print(f\"True κ (T → Y):        {kappa_true}\")\n",
    "print(f\"True γ (A → Y):        {gamma_true}\")\n",
    "print(f\"True δ (A ~ T):        {delta_true}\")\n",
    "print(f\"Expected bias:         {gamma_true * delta_true}\")\n",
    "print(f\"Expected short coef:   {kappa_true + gamma_true * delta_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long regression (includes confounder)\n",
    "model_long = smf.ols('Y ~ T + A', data=sim_data).fit()\n",
    "\n",
    "print(\"Long Regression (includes A)\")\n",
    "print(f\"  κ̂ (T):  {model_long.params['T']:.4f}  (true: {kappa_true})\")\n",
    "print(f\"  γ̂ (A):  {model_long.params['A']:.4f}  (true: {gamma_true})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short regression (omits confounder)\n",
    "model_short = smf.ols('Y ~ T', data=sim_data).fit()\n",
    "\n",
    "print(\"Short Regression (omits A)\")\n",
    "print(f\"  κ̃ (T):  {model_short.params['T']:.4f}  (expected: {kappa_true + gamma_true * delta_true})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary regression (A on T)\n",
    "model_aux = smf.ols('A ~ T', data=sim_data).fit()\n",
    "\n",
    "print(\"Auxiliary Regression (A ~ T)\")\n",
    "print(f\"  δ̂:     {model_aux.params['T']:.4f}  (true: {delta_true})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Verifying the Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify OVB formula\n",
    "kappa_long = model_long.params['T']\n",
    "gamma_hat = model_long.params['A']\n",
    "delta_hat = model_aux.params['T']\n",
    "kappa_short = model_short.params['T']\n",
    "\n",
    "# Formula: short = long + gamma * delta\n",
    "kappa_predicted = kappa_long + gamma_hat * delta_hat\n",
    "\n",
    "print(\"OVB Formula Verification\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Short coefficient:                {kappa_short:.6f}\")\n",
    "print(f\"Long + γ·δ (formula prediction):  {kappa_predicted:.6f}\")\n",
    "print(f\"\")\n",
    "print(f\"Difference: {abs(kappa_short - kappa_predicted):.2e}\")\n",
    "print(f\"Match: {np.isclose(kappa_short, kappa_predicted, rtol=1e-6)}\")\n",
    "\n",
    "# Verify to reasonable precision (finite sample)\n",
    "assert np.isclose(kappa_short, kappa_predicted, rtol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bias\n",
    "fig, axes = create_tufte_figure(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Panel 1: DAG representation\n",
    "ax = axes[0]\n",
    "ax.set_xlim(-0.5, 2.5)\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "\n",
    "# Draw nodes\n",
    "node_style = dict(ha='center', va='center', fontsize=14, fontweight='bold',\n",
    "                  bbox=dict(boxstyle='circle,pad=0.3', facecolor='white', edgecolor='black'))\n",
    "ax.text(0, 1, 'A', **node_style)\n",
    "ax.text(1, 0, 'T', **node_style)\n",
    "ax.text(2, 1, 'Y', **node_style)\n",
    "\n",
    "# Draw edges\n",
    "arrow_style = dict(arrowstyle='->', color=TUFTE_PALETTE['primary'], lw=2)\n",
    "ax.annotate('', xy=(0.85, 0.15), xytext=(0.15, 0.85), arrowprops=arrow_style)\n",
    "ax.annotate('', xy=(1.85, 0.85), xytext=(0.15, 0.85), arrowprops=arrow_style)\n",
    "ax.annotate('', xy=(1.85, 0.85), xytext=(1.15, 0.15), arrowprops=arrow_style)\n",
    "\n",
    "# Labels\n",
    "ax.text(0.35, 0.65, f'δ={delta_true}', fontsize=10, color=TUFTE_PALETTE['secondary'])\n",
    "ax.text(1.0, 1.1, f'γ={gamma_true}', fontsize=10, color=TUFTE_PALETTE['secondary'])\n",
    "ax.text(1.65, 0.35, f'κ={kappa_true}', fontsize=10, color=TUFTE_PALETTE['effect'])\n",
    "\n",
    "ax.axis('off')\n",
    "ax.set_title('(a) Causal DAG')\n",
    "\n",
    "# Panel 2: Coefficient comparison\n",
    "ax = axes[1]\n",
    "labels = ['True κ', 'Long\\n(includes A)', 'Short\\n(omits A)']\n",
    "values = [kappa_true, kappa_long, kappa_short]\n",
    "colors = [TUFTE_PALETTE['effect'], TUFTE_PALETTE['effect'], TUFTE_PALETTE['bias']]\n",
    "\n",
    "bars = ax.bar(labels, values, color=colors, width=0.5, edgecolor='white')\n",
    "ax.axhline(kappa_true, ls='--', color=TUFTE_PALETTE['secondary'], lw=1, label='True effect')\n",
    "\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.1, f'{val:.2f}', \n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_ylabel('Coefficient on T')\n",
    "ax.set_title('(b) OVB Demonstration')\n",
    "\n",
    "# Panel 3: Bias decomposition\n",
    "ax = axes[2]\n",
    "bias_value = gamma_hat * delta_hat\n",
    "\n",
    "# Stacked bar showing decomposition\n",
    "ax.barh(['Short coef'], [kappa_long], color=TUFTE_PALETTE['effect'], \n",
    "        label=f'True effect: {kappa_long:.2f}', height=0.4)\n",
    "ax.barh(['Short coef'], [bias_value], left=[kappa_long], color=TUFTE_PALETTE['bias'],\n",
    "        label=f'Bias (γ·δ): {bias_value:.2f}', height=0.4)\n",
    "\n",
    "ax.axvline(kappa_true, ls='--', color=TUFTE_PALETTE['secondary'], lw=1)\n",
    "ax.set_xlabel('Coefficient value')\n",
    "ax.set_title('(c) Bias Decomposition')\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo: show OVB formula holds across many samples\n",
    "n_sims = 1000\n",
    "n_obs = 500\n",
    "\n",
    "results = []\n",
    "for _ in range(n_sims):\n",
    "    # Generate data\n",
    "    A_sim = np.random.normal(0, 1, n_obs)\n",
    "    T_sim = delta_true * A_sim + np.random.normal(0, np.sqrt(1 - delta_true**2), n_obs)\n",
    "    Y_sim = kappa_true * T_sim + gamma_true * A_sim + np.random.normal(0, 1, n_obs)\n",
    "    \n",
    "    # Short regression\n",
    "    X_short = sm.add_constant(T_sim)\n",
    "    kappa_s = np.linalg.lstsq(X_short, Y_sim, rcond=None)[0][1]\n",
    "    \n",
    "    # Long regression\n",
    "    X_long = sm.add_constant(np.column_stack([T_sim, A_sim]))\n",
    "    coefs_l = np.linalg.lstsq(X_long, Y_sim, rcond=None)[0]\n",
    "    kappa_l, gamma_l = coefs_l[1], coefs_l[2]\n",
    "    \n",
    "    # Aux regression\n",
    "    X_aux = sm.add_constant(T_sim)\n",
    "    delta_l = np.linalg.lstsq(X_aux, A_sim, rcond=None)[0][1]\n",
    "    \n",
    "    results.append({\n",
    "        'kappa_short': kappa_s,\n",
    "        'kappa_long': kappa_l,\n",
    "        'gamma': gamma_l,\n",
    "        'delta': delta_l,\n",
    "        'predicted': kappa_l + gamma_l * delta_l,\n",
    "    })\n",
    "\n",
    "mc_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Monte Carlo Results (1000 simulations)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"E[κ_short]:         {mc_df['kappa_short'].mean():.4f} (expected: {kappa_true + gamma_true * delta_true})\")\n",
    "print(f\"E[κ_long]:          {mc_df['kappa_long'].mean():.4f} (true: {kappa_true})\")\n",
    "print(f\"E[κ_long + γ·δ]:    {mc_df['predicted'].mean():.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"Bias of short:      {mc_df['kappa_short'].mean() - kappa_true:.4f}\")\n",
    "print(f\"Bias of long:       {mc_df['kappa_long'].mean() - kappa_true:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation\n",
    "\n",
    "For sensitivity analysis regarding unobserved confounders, see:\n",
    "\n",
    "```python\n",
    "from causal_inference.sensitivity import (\n",
    "    e_value,              # E-value for unmeasured confounding\n",
    "    rosenbaum_bounds,     # Rosenbaum sensitivity analysis\n",
    "    oster_bounds,         # Oster (2019) proportional selection\n",
    ")\n",
    "\n",
    "# How strong would confounding need to be to explain away the effect?\n",
    "e = e_value(estimate=model_full.params['educ'], \n",
    "            se=model_full.bse['educ'])\n",
    "print(f\"E-value: {e:.2f}\")\n",
    "# An unmeasured confounder would need RR > e with both treatment and outcome\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1 (Meta E5, Economist)**: *\"Derive the omitted variable bias formula.\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Setup**: True DGP is $Y = \\beta_0 + \\kappa T + \\gamma A + \\epsilon$ with $E[\\epsilon|T,A] = 0$.\n",
    "\n",
    "We estimate short regression $Y = \\tilde{\\beta}_0 + \\tilde{\\kappa} T + u$.\n",
    "\n",
    "**Derivation**:\n",
    "\n",
    "The OLS coefficient is:\n",
    "$$\\tilde{\\kappa} = \\frac{\\text{Cov}(Y, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "Substitute $Y = \\kappa T + \\gamma A + \\epsilon$ (dropping constant for simplicity):\n",
    "\n",
    "$$\\tilde{\\kappa} = \\frac{\\text{Cov}(\\kappa T + \\gamma A + \\epsilon, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "Using linearity of covariance and $\\text{Cov}(\\epsilon, T) = 0$:\n",
    "\n",
    "$$= \\frac{\\kappa \\text{Var}(T) + \\gamma \\text{Cov}(A, T)}{\\text{Var}(T)}$$\n",
    "\n",
    "$$= \\kappa + \\gamma \\cdot \\underbrace{\\frac{\\text{Cov}(A, T)}{\\text{Var}(T)}}_{\\delta}$$\n",
    "\n",
    "$$\\boxed{\\tilde{\\kappa} = \\kappa + \\gamma \\delta}$$\n",
    "\n",
    "where $\\delta$ is the coefficient from regressing $A$ on $T$.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q2 (Google L5, DS)**: *\"Give an example where OVB causes positive bias and one where it causes negative bias.\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Positive bias example (Education → Wages)**:\n",
    "\n",
    "- Treatment: Education\n",
    "- Outcome: Wages\n",
    "- Omitted: Ability (IQ)\n",
    "\n",
    "Bias = γ × δ:\n",
    "- γ (Ability → Wages) > 0: Higher ability → higher wages\n",
    "- δ (Ability ↔ Education) > 0: Higher ability → more education\n",
    "- Bias = (+)(+) = **positive**\n",
    "\n",
    "Result: Simple regression overstates return to education.\n",
    "\n",
    "---\n",
    "\n",
    "**Negative bias example (Ad spend → Sales)**:\n",
    "\n",
    "- Treatment: Ad spending\n",
    "- Outcome: Sales\n",
    "- Omitted: Product quality issues (recalls, bad reviews)\n",
    "\n",
    "Bias = γ × δ:\n",
    "- γ (Quality issues → Sales) < 0: Bad quality → lower sales\n",
    "- δ (Quality issues ↔ Ad spend) > 0: Companies increase ads to counter bad news\n",
    "- Bias = (−)(+) = **negative**\n",
    "\n",
    "Result: Simple regression understates (or reverses) ad effectiveness.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q3 (Two Sigma, Quant)**: *\"When is OVB zero? What does this tell us about randomization?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**OVB = γ × δ = 0 when:**\n",
    "\n",
    "1. **γ = 0**: Omitted variable doesn't affect outcome\n",
    "   - Then it's not a confounder, just irrelevant\n",
    "   - No need to control for it\n",
    "\n",
    "2. **δ = 0**: Omitted variable uncorrelated with treatment\n",
    "   - Cov(A, T) = 0\n",
    "   - Treatment variation is independent of the omitted variable\n",
    "\n",
    "**Connection to randomization:**\n",
    "\n",
    "In an RCT, treatment is randomly assigned. By definition:\n",
    "- $T \\perp A$ for *any* variable $A$ (observed or unobserved)\n",
    "- Therefore $\\delta = \\text{Cov}(A, T) / \\text{Var}(T) = 0$\n",
    "- OVB = 0 regardless of what confounders exist\n",
    "\n",
    "This is why RCTs are the gold standard: randomization eliminates ALL confounding, even from variables we don't observe or measure.\n",
    "\n",
    "**Implication for observational data:**\n",
    "\n",
    "We can only eliminate bias from *observed* confounders. There's always risk of unobserved confounding—hence the importance of:\n",
    "- Sensitivity analysis\n",
    "- Natural experiments\n",
    "- Instrumental variables\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 5: \"Omitted Variable or Confounding Bias.\"\n",
    "\n",
    "[^2]: Angrist, J. D. and Pischke, J.-S. (2009). *Mostly Harmless Econometrics*. Princeton University Press, Chapter 3.2.\n",
    "\n",
    "[^3]: Cinelli, C. and Hazlett, C. (2020). Making Sense of Sensitivity: Extending Omitted Variable Bias. *Journal of the Royal Statistical Society: Series B*, 82(1), 39-67.\n",
    "\n",
    "[^4]: Oster, E. (2019). Unobservable Selection and Coefficient Stability: Theory and Evidence. *Journal of Business & Economic Statistics*, 37(2), 187-204.\n",
    "\n",
    "---\n",
    "\n",
    "**Precision Improvement:**\n",
    "- You said: \"Build the OVB section\"\n",
    "- Concise: \"Build 04_omitted_variable_bias\"\n",
    "- Precise: `/augmented 05.4 --ovb-proof --simulation`\n",
    "- Pattern: [build] [target] [content-flags]"
   ]
  }
 ],
 "metadata": {
  "augmented": {
   "chapter_number": 5,
   "section_number": 4,
   "title": "Omitted Variable Bias",
   "facure_source": "05-The-Unreasonable-Effectiveness-of-Linear-Regression.ipynb",
   "section_types": [
    "table_of_contents",
    "facure_intuition",
    "formal_treatment",
    "numeric_demonstration",
    "implementation",
    "interview_appendix",
    "references"
   ],
   "version": "1.0.0",
   "last_validated": "2026-01-09"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
