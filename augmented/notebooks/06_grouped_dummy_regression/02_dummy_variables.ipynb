{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Variables and Treatment Effects\n",
    "\n",
    "**Chapter 6, Section 2**\n",
    "\n",
    "This notebook covers how dummy (indicator) variables in regression estimate treatment effects, and the interpretation of coefficients as conditional means.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition) - Dummy = difference in means\n",
    "2. [Formal Treatment](#formal) - Coefficient interpretation\n",
    "3. [Numeric Demonstration](#numeric) - Wage and education examples\n",
    "4. [Implementation](#implementation) - Visualizing parallel lines\n",
    "5. [Interview Appendix](#interview) - Practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import *\n",
    "\n",
    "# Set notebook style\n",
    "set_notebook_style()\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "### The Simplest Regression: Treatment vs Control\n",
    "\n",
    "Consider a binary treatment $T \\in \\{0, 1\\}$. The simplest regression is:\n",
    "\n",
    "$$Y_i = \\alpha + \\beta T_i + \\epsilon_i$$\n",
    "\n",
    "What does $\\beta$ estimate?\n",
    "\n",
    "- When $T = 0$: $E[Y | T=0] = \\alpha$\n",
    "- When $T = 1$: $E[Y | T=1] = \\alpha + \\beta$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\\beta = E[Y | T=1] - E[Y | T=0]$$\n",
    "\n",
    "**The dummy coefficient is simply the difference in means!**\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Regression with a single dummy = difference in means\n",
    "- The dummy coefficient estimates the Average Treatment Effect (ATE)\n",
    "- This is the starting point for all regression-based causal inference\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wage data\n",
    "wage = load_facure_data(\"wage.csv\")\n",
    "\n",
    "# Create a treatment dummy: high education (>12 years)\n",
    "wage['high_educ'] = (wage['educ'] > 12).astype(int)\n",
    "\n",
    "print(f\"Treatment distribution:\")\n",
    "print(wage['high_educ'].value_counts())\n",
    "print(f\"\\nProportion with high education: {wage['high_educ'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Simple difference in means\n",
    "mean_high = wage.loc[wage['high_educ'] == 1, 'wage'].mean()\n",
    "mean_low = wage.loc[wage['high_educ'] == 0, 'wage'].mean()\n",
    "diff_means = mean_high - mean_low\n",
    "\n",
    "print(\"Method 1: Difference in Means\")\n",
    "print(f\"  Mean wage (high educ): ${mean_high:.2f}\")\n",
    "print(f\"  Mean wage (low educ):  ${mean_low:.2f}\")\n",
    "print(f\"  Difference: ${diff_means:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Regression with dummy\n",
    "model_dummy = smf.ols('wage ~ high_educ', data=wage).fit()\n",
    "\n",
    "print(\"\\nMethod 2: Regression with Dummy\")\n",
    "print(f\"  Intercept (mean low educ): ${model_dummy.params['Intercept']:.2f}\")\n",
    "print(f\"  Coefficient (difference):  ${model_dummy.params['high_educ']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify they're identical\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"VERIFICATION: Methods produce identical results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Diff in means: ${diff_means:.6f}\")\n",
    "print(f\"Regression β:  ${model_dummy.params['high_educ']:.6f}\")\n",
    "print(f\"Match: {np.isclose(diff_means, model_dummy.params['high_educ'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Treatment\n",
    "\n",
    "### Adding Continuous Covariates\n",
    "\n",
    "When we add a continuous covariate $X$:\n",
    "\n",
    "$$Y_i = \\alpha + \\beta T_i + \\gamma X_i + \\epsilon_i$$\n",
    "\n",
    "Now $\\beta$ is the **conditional** treatment effect:\n",
    "\n",
    "$$\\beta = E[Y | T=1, X] - E[Y | T=0, X]$$\n",
    "\n",
    "This represents the treatment effect **holding X constant**.\n",
    "\n",
    "### The Parallel Lines Assumption\n",
    "\n",
    "This model assumes:\n",
    "- Treatment shifts the regression line **vertically** by $\\beta$\n",
    "- The **slope** with respect to X is the same ($\\gamma$) for both groups\n",
    "- The lines are **parallel**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[Y | T=0, X] &= \\alpha + \\gamma X \\\\\n",
    "E[Y | T=1, X] &= (\\alpha + \\beta) + \\gamma X\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with dummy + continuous covariate\n",
    "model_with_iq = smf.ols('wage ~ high_educ + IQ', data=wage).fit()\n",
    "\n",
    "print(\"Regression: wage ~ high_educ + IQ\")\n",
    "print(ols_summary_table(model_with_iq)[['Coefficient', 'Std. Error', 'p-value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parallel lines\n",
    "fig, ax = create_tufte_figure(figsize=(10, 6))\n",
    "\n",
    "# Plot data points\n",
    "colors = {0: COLORS['blue'], 1: COLORS['red']}\n",
    "for t_val in [0, 1]:\n",
    "    subset = wage[wage['high_educ'] == t_val]\n",
    "    label = 'High Education' if t_val == 1 else 'Low Education'\n",
    "    ax.scatter(subset['IQ'], subset['wage'], alpha=0.3, c=colors[t_val], \n",
    "               s=20, label=label)\n",
    "\n",
    "# Plot fitted lines (parallel)\n",
    "iq_range = np.linspace(wage['IQ'].min(), wage['IQ'].max(), 100)\n",
    "alpha = model_with_iq.params['Intercept']\n",
    "beta = model_with_iq.params['high_educ']\n",
    "gamma = model_with_iq.params['IQ']\n",
    "\n",
    "y_low = alpha + gamma * iq_range\n",
    "y_high = (alpha + beta) + gamma * iq_range\n",
    "\n",
    "ax.plot(iq_range, y_low, color=COLORS['blue'], linewidth=2, label=f'T=0: {alpha:.1f} + {gamma:.2f}×IQ')\n",
    "ax.plot(iq_range, y_high, color=COLORS['red'], linewidth=2, label=f'T=1: {alpha+beta:.1f} + {gamma:.2f}×IQ')\n",
    "\n",
    "# Annotate the gap\n",
    "mid_iq = (wage['IQ'].min() + wage['IQ'].max()) / 2\n",
    "ax.annotate('', xy=(mid_iq, alpha + beta + gamma * mid_iq), \n",
    "            xytext=(mid_iq, alpha + gamma * mid_iq),\n",
    "            arrowprops=dict(arrowstyle='<->', color=COLORS['gray']))\n",
    "ax.text(mid_iq + 3, alpha + beta/2 + gamma * mid_iq, f'β = ${beta:.0f}', fontsize=10)\n",
    "\n",
    "set_tufte_title(ax, \"Parallel Lines: Treatment Shifts Intercept, Same Slope\")\n",
    "set_tufte_labels(ax, \"IQ\", \"Hourly Wage ($)\")\n",
    "ax.legend(loc='upper left', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numeric Demonstration\n",
    "\n",
    "### Comparing Raw vs Adjusted Effects\n",
    "\n",
    "How does controlling for IQ change our estimate of the education effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare raw and adjusted effects\n",
    "model_raw = smf.ols('wage ~ high_educ', data=wage).fit()\n",
    "model_adj = smf.ols('wage ~ high_educ + IQ', data=wage).fit()\n",
    "\n",
    "print(\"COMPARISON: Raw vs IQ-Adjusted Education Effect\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Raw (no controls)', 'Adjusted (+ IQ)'],\n",
    "    'Effect': [\n",
    "        model_raw.params['high_educ'],\n",
    "        model_adj.params['high_educ']\n",
    "    ],\n",
    "    'Std Error': [\n",
    "        model_raw.bse['high_educ'],\n",
    "        model_adj.bse['high_educ']\n",
    "    ],\n",
    "    'R-squared': [\n",
    "        model_raw.rsquared,\n",
    "        model_adj.rsquared\n",
    "    ]\n",
    "})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "1. **Effect decreases** when we control for IQ → IQ is positively correlated with both education AND wages (confounder)\n",
    "2. **Standard error decreases** → controlling for a predictive variable (IQ) reduces residual variance\n",
    "3. **R-squared increases** → model explains more variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation structure\n",
    "print(\"Correlation between high_educ and IQ:\")\n",
    "corr = wage[['high_educ', 'IQ', 'wage']].corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Log Wages\n",
    "\n",
    "In labor economics, we typically use **log wages** because:\n",
    "1. Wage distributions are right-skewed\n",
    "2. Coefficients have percentage interpretation (approximately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare raw wage vs log wage\n",
    "model_level = smf.ols('wage ~ high_educ + IQ', data=wage).fit()\n",
    "model_log = smf.ols('lhwage ~ high_educ + IQ', data=wage).fit()\n",
    "\n",
    "print(\"Level wages: wage ~ high_educ + IQ\")\n",
    "print(f\"  Education effect: ${model_level.params['high_educ']:.2f}/hour\")\n",
    "\n",
    "print(\"\\nLog wages: log(wage) ~ high_educ + IQ\")\n",
    "print(f\"  Education effect: {model_log.params['high_educ']:.4f}\")\n",
    "print(f\"  ≈ {model_log.params['high_educ']*100:.1f}% wage premium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Creating Dummy Variables in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Boolean conversion\n",
    "wage['dummy_method1'] = (wage['educ'] > 12).astype(int)\n",
    "\n",
    "# Method 2: np.where\n",
    "wage['dummy_method2'] = np.where(wage['educ'] > 12, 1, 0)\n",
    "\n",
    "# Method 3: pd.cut for multiple categories\n",
    "wage['educ_cat'] = pd.cut(wage['educ'], bins=[0, 9, 12, 16, 100], \n",
    "                          labels=['<HS', 'HS', 'Some College', 'College+'])\n",
    "\n",
    "wage[['educ', 'dummy_method1', 'dummy_method2', 'educ_cat']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using categorical variables in regression (C() notation)\n",
    "# This automatically creates dummies with one category as reference\n",
    "model_cat = smf.ols('wage ~ C(educ_cat)', data=wage).fit()\n",
    "\n",
    "print(\"Regression with categorical education levels:\")\n",
    "print(ols_summary_table(model_cat)[['Coefficient', 'Std. Error', 'p-value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify: reference category is '<HS'\n",
    "print(\"\\nGroup means:\")\n",
    "group_means = wage.groupby('educ_cat', observed=True)['wage'].mean()\n",
    "print(group_means)\n",
    "\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"Intercept = mean(<HS): {model_cat.params['Intercept']:.2f} vs {group_means['<HS']:.2f}\")\n",
    "print(f\"HS coefficient = mean(HS) - mean(<HS): {model_cat.params['C(educ_cat)[T.HS]']:.2f} vs {group_means['HS'] - group_means['<HS']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1: What does a dummy coefficient estimate in a simple regression?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "In the regression $Y = \\alpha + \\beta T + \\epsilon$ where T is binary:\n",
    "\n",
    "- $\\alpha$ = E[Y | T=0], the mean outcome in the control group\n",
    "- $\\beta$ = E[Y | T=1] - E[Y | T=0], the difference in means\n",
    "\n",
    "The dummy coefficient is literally the difference in group means. This is the **naive ATE estimator**—it equals the true ATE only if treatment is randomly assigned (or conditional on covariates in a regression with controls).\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q2: What does the parallel lines assumption mean, and when might it be violated?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "The parallel lines assumption means:\n",
    "- The treatment effect is **constant** across all values of the covariate\n",
    "- Treatment shifts the regression line vertically (changes intercept)\n",
    "- Treatment does NOT change the slope\n",
    "\n",
    "Violations occur when:\n",
    "- Treatment effect varies by covariate value (effect heterogeneity)\n",
    "- Example: A training program might help low-IQ workers more than high-IQ workers\n",
    "\n",
    "To allow for heterogeneous effects, add an **interaction term**: $Y = \\alpha + \\beta_1 T + \\beta_2 X + \\beta_3 (T \\times X) + \\epsilon$\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q3: Why does controlling for IQ reduce the education coefficient?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "IQ is a **confounder** in the education-wage relationship:\n",
    "- High IQ → more likely to pursue education\n",
    "- High IQ → higher wages (independent of education)\n",
    "\n",
    "Without controlling for IQ, the education coefficient captures:\n",
    "1. The true effect of education on wages\n",
    "2. PLUS the spurious association from IQ\n",
    "\n",
    "This is the **omitted variable bias formula**:\n",
    "$$\\beta_{short} = \\beta_{long} + \\gamma \\times \\delta$$\n",
    "\n",
    "Where:\n",
    "- $\\gamma$ = effect of IQ on wages (positive)\n",
    "- $\\delta$ = correlation of IQ with education (positive)\n",
    "- Bias = positive → raw estimate is biased upward\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[^1]: Facure, M. (2022). *Causal Inference for the Brave and True*, Chapter 6.\n",
    "\n",
    "[^2]: Angrist, J. D., & Pischke, J.-S. (2009). *Mostly Harmless Econometrics*, Chapter 3.\n",
    "\n",
    "[^3]: Cross-reference: `augmented/notebooks/05_linear_regression/04_omitted_variable_bias.ipynb` for OVB formula."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
