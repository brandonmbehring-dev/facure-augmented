{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# The Propensity Score as a Balancing Score\n",
    "\n",
    "**Chapter 11, Section 1**\n",
    "\n",
    "This notebook covers the propensity score theorem: how a single scalar summarizes all confounders.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition) - Dimension reduction for matching\n",
    "2. [Formal Treatment](#formal) - Balancing score theorem\n",
    "3. [Numeric Demonstration](#numeric) - Growth mindset study\n",
    "4. [Implementation](#implementation) - Estimating propensity scores\n",
    "5. [Interview Appendix](#interview) - Practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set notebook style\n",
    "set_notebook_style()\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "### The Curse of Dimensionality Problem\n",
    "\n",
    "Matching on multiple covariates becomes difficult:\n",
    "- 2 continuous variables: Find 2D neighbors\n",
    "- 10 continuous variables: Find 10D neighbors (very hard)\n",
    "- 50 variables: Essentially impossible\n",
    "\n",
    "### The Propensity Score Solution\n",
    "\n",
    "**Key insight** (Rosenbaum & Rubin, 1983):\n",
    "\n",
    "> Matching on the **propensity score** is sufficient to remove confounding, regardless of how many covariates there are.\n",
    "\n",
    "$$e(X) = P(T=1 | X)$$\n",
    "\n",
    "The propensity score is the probability of receiving treatment given covariates.\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "**Balancing property**: Within strata of $e(X)$, treated and control groups have the same covariate distribution:\n",
    "\n",
    "$$X \\perp T \\mid e(X)$$\n",
    "\n",
    "If two units (one treated, one control) have the same propensity score, their covariates are \"balanced\" on average.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load learning mindset data\n",
    "mindset = load_facure_data(\"learning_mindset.csv\")\n",
    "\n",
    "print(f\"Data: {len(mindset)} students\")\n",
    "print(f\"Treatment (intervention): {mindset['intervention'].mean():.1%} received intervention\")\n",
    "print(f\"\\nOutcome: achievement_score\")\n",
    "print(f\"\\nCovariates:\")\n",
    "print(f\"  Individual: success_expect, ethnicity, gender, frst_in_family\")\n",
    "print(f\"  School: school_mindset, school_achievement, school_ethnic_minority, school_poverty, school_size\")\n",
    "mindset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covariates for propensity score\n",
    "covariates = [\n",
    "    'success_expect', 'ethnicity', 'gender', 'frst_in_family',\n",
    "    'school_mindset', 'school_achievement', 'school_ethnic_minority',\n",
    "    'school_poverty', 'school_size'\n",
    "]\n",
    "\n",
    "# Check balance before any adjustment\n",
    "print(\"COVARIATE BALANCE (before adjustment):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Covariate':<25} {'Control Mean':<15} {'Treated Mean':<15} {'Diff'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for cov in covariates:\n",
    "    control_mean = mindset[mindset['intervention'] == 0][cov].mean()\n",
    "    treated_mean = mindset[mindset['intervention'] == 1][cov].mean()\n",
    "    diff = treated_mean - control_mean\n",
    "    print(f\"{cov:<25} {control_mean:<15.3f} {treated_mean:<15.3f} {diff:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Treatment\n",
    "\n",
    "### Definition\n",
    "\n",
    "**Definition** (Propensity Score):\n",
    "\n",
    "$$e(X) = P(T=1 | X)$$\n",
    "\n",
    "The propensity score is the conditional probability of treatment given observed covariates.\n",
    "\n",
    "### Balancing Score Theorem\n",
    "\n",
    "**Theorem** (Rosenbaum & Rubin, 1983):\n",
    "\n",
    "If $(Y(0), Y(1)) \\perp T | X$, then $(Y(0), Y(1)) \\perp T | e(X)$.\n",
    "\n",
    "**Proof**:\n",
    "\n",
    "We need to show that $P(T=1 | Y(0), Y(1), e(X)) = P(T=1 | e(X))$.\n",
    "\n",
    "**Step 1**: By law of iterated expectations:\n",
    "$$P(T=1 | Y(0), Y(1), e(X)) = E[T | Y(0), Y(1), e(X)]$$\n",
    "\n",
    "**Step 2**: Condition on $X$:\n",
    "$$= E[E[T | Y(0), Y(1), X] | Y(0), Y(1), e(X)]$$\n",
    "\n",
    "**Step 3**: By conditional ignorability $(Y(0), Y(1)) \\perp T | X$:\n",
    "$$= E[E[T | X] | Y(0), Y(1), e(X)]$$\n",
    "$$= E[e(X) | Y(0), Y(1), e(X)]$$\n",
    "\n",
    "**Step 4**: Since $e(X)$ is a function of $X$:\n",
    "$$= e(X) = P(T=1 | e(X))$$\n",
    "\n",
    "Therefore, conditioning on $e(X)$ is sufficient for ignorability. $\\square$\n",
    "\n",
    "### Corollary: Balancing Property\n",
    "\n",
    "**Corollary**: $X \\perp T | e(X)$\n",
    "\n",
    "Within strata of the propensity score, covariates are balanced between treated and control groups.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate propensity scores using logistic regression\n",
    "X = mindset[covariates].values\n",
    "T = mindset['intervention'].values\n",
    "\n",
    "# Fit logistic regression (high C = no regularization)\n",
    "ps_model = LogisticRegression(C=1e6, max_iter=1000, solver='lbfgs')\n",
    "ps_model.fit(X, T)\n",
    "\n",
    "# Get propensity scores\n",
    "propensity_scores = ps_model.predict_proba(X)[:, 1]\n",
    "mindset['ps'] = propensity_scores\n",
    "\n",
    "print(\"PROPENSITY SCORE ESTIMATION:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: Logistic Regression\")\n",
    "print(f\"Covariates: {len(covariates)}\")\n",
    "print(f\"\\nPropensity Score Summary:\")\n",
    "print(f\"  Min:  {propensity_scores.min():.4f}\")\n",
    "print(f\"  Max:  {propensity_scores.max():.4f}\")\n",
    "print(f\"  Mean: {propensity_scores.mean():.4f}\")\n",
    "print(f\"  Std:  {propensity_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize propensity score distributions\n",
    "fig, axes = create_tufte_figure(ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Left: Overlapping histograms\n",
    "ax = axes[0]\n",
    "for t, color, label in [(0, COLORS['blue'], 'Control'), (1, COLORS['red'], 'Treated')]:\n",
    "    subset = mindset[mindset['intervention'] == t]\n",
    "    ax.hist(subset['ps'], bins=30, alpha=0.5, color=color, label=label, density=True)\n",
    "\n",
    "set_tufte_title(ax, \"Propensity Score Distribution by Treatment\")\n",
    "set_tufte_labels(ax, \"Propensity Score e(X)\", \"Density\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Right: Check overlap (common support)\n",
    "ax = axes[1]\n",
    "ps_treated = mindset[mindset['intervention'] == 1]['ps']\n",
    "ps_control = mindset[mindset['intervention'] == 0]['ps']\n",
    "\n",
    "ax.boxplot([ps_control, ps_treated], labels=['Control', 'Treated'])\n",
    "set_tufte_title(ax, \"Propensity Score Box Plot\")\n",
    "set_tufte_labels(ax, \"\", \"Propensity Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check overlap\n",
    "overlap_min = max(ps_treated.min(), ps_control.min())\n",
    "overlap_max = min(ps_treated.max(), ps_control.max())\n",
    "print(f\"\\nOverlap region: [{overlap_min:.4f}, {overlap_max:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numeric Demonstration\n",
    "\n",
    "### Verifying the Balancing Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by propensity score quintiles and check balance\n",
    "mindset['ps_quintile'] = pd.qcut(mindset['ps'], q=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"BALANCE WITHIN PROPENSITY SCORE STRATA:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# For each quintile, compute mean difference in one covariate\n",
    "example_cov = 'school_achievement'\n",
    "print(f\"\\nCovariate: {example_cov}\")\n",
    "print(f\"{'Quintile':<10} {'Control Mean':<15} {'Treated Mean':<15} {'Difference'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for q in [1, 2, 3, 4, 5]:\n",
    "    stratum = mindset[mindset['ps_quintile'] == q]\n",
    "    control_mean = stratum[stratum['intervention'] == 0][example_cov].mean()\n",
    "    treated_mean = stratum[stratum['intervention'] == 1][example_cov].mean()\n",
    "    diff = treated_mean - control_mean\n",
    "    print(f\"{q:<10} {control_mean:<15.3f} {treated_mean:<15.3f} {diff:+.3f}\")\n",
    "\n",
    "# Overall difference\n",
    "overall_diff = mindset[mindset['intervention']==1][example_cov].mean() - mindset[mindset['intervention']==0][example_cov].mean()\n",
    "print(f\"{'Overall':<10} {'':<15} {'':<15} {overall_diff:+.3f}\")\n",
    "print(f\"\\nWithin strata, balance is much better than overall!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standardized mean differences (SMD) before and within PS strata\n",
    "def compute_smd(df, covariate, treatment_col):\n",
    "    \"\"\"Compute standardized mean difference.\"\"\"\n",
    "    treated = df[df[treatment_col] == 1][covariate]\n",
    "    control = df[df[treatment_col] == 0][covariate]\n",
    "    \n",
    "    pooled_std = np.sqrt((treated.var() + control.var()) / 2)\n",
    "    if pooled_std == 0:\n",
    "        return 0\n",
    "    return (treated.mean() - control.mean()) / pooled_std\n",
    "\n",
    "print(\"\\nSTANDARDIZED MEAN DIFFERENCES:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Covariate':<25} {'Overall SMD':<15} {'Within-Strata SMD'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for cov in covariates:\n",
    "    # Overall SMD\n",
    "    overall_smd = compute_smd(mindset, cov, 'intervention')\n",
    "    \n",
    "    # Within-strata SMD (average across strata)\n",
    "    within_smds = []\n",
    "    for q in [1, 2, 3, 4, 5]:\n",
    "        stratum = mindset[mindset['ps_quintile'] == q]\n",
    "        if len(stratum[stratum['intervention']==0]) > 0 and len(stratum[stratum['intervention']==1]) > 0:\n",
    "            within_smds.append(compute_smd(stratum, cov, 'intervention'))\n",
    "    avg_within_smd = np.mean(np.abs(within_smds)) if within_smds else 0\n",
    "    \n",
    "    print(f\"{cov:<25} {overall_smd:+.3f} ({abs(overall_smd):<.3f}) {avg_within_smd:.3f}\")\n",
    "\n",
    "print(f\"\\nSMD < 0.1 is considered good balance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Simple Stratification Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratification estimator using propensity score quintiles\n",
    "def stratification_ate(df, outcome_col, treatment_col, strata_col):\n",
    "    \"\"\"\n",
    "    Estimate ATE using stratification on propensity score.\n",
    "    \"\"\"\n",
    "    strata_effects = []\n",
    "    \n",
    "    for stratum in df[strata_col].unique():\n",
    "        stratum_data = df[df[strata_col] == stratum]\n",
    "        treated = stratum_data[stratum_data[treatment_col] == 1]\n",
    "        control = stratum_data[stratum_data[treatment_col] == 0]\n",
    "        \n",
    "        if len(treated) > 0 and len(control) > 0:\n",
    "            effect = treated[outcome_col].mean() - control[outcome_col].mean()\n",
    "            weight = len(stratum_data) / len(df)\n",
    "            strata_effects.append({\n",
    "                'stratum': stratum,\n",
    "                'n': len(stratum_data),\n",
    "                'n_treated': len(treated),\n",
    "                'n_control': len(control),\n",
    "                'effect': effect,\n",
    "                'weight': weight\n",
    "            })\n",
    "    \n",
    "    strata_df = pd.DataFrame(strata_effects)\n",
    "    ate = (strata_df['effect'] * strata_df['weight']).sum()\n",
    "    \n",
    "    return ate, strata_df\n",
    "\n",
    "ate_strat, strata_details = stratification_ate(mindset, 'achievement_score', 'intervention', 'ps_quintile')\n",
    "\n",
    "print(\"STRATIFICATION ESTIMATOR:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nStrata details:\")\n",
    "print(strata_details.to_string(index=False))\n",
    "print(f\"\\nATE (stratification): {ate_strat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to naive and regression estimates\n",
    "print(\"\\nCOMPARISON OF ESTIMATES:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Naive\n",
    "naive = mindset[mindset['intervention']==1]['achievement_score'].mean() - mindset[mindset['intervention']==0]['achievement_score'].mean()\n",
    "print(f\"Naive (no adjustment): {naive:.4f}\")\n",
    "\n",
    "# Regression\n",
    "formula = 'achievement_score ~ intervention + ' + ' + '.join(covariates)\n",
    "reg_model = smf.ols(formula, data=mindset).fit()\n",
    "print(f\"Regression adjusted:   {reg_model.params['intervention']:.4f}\")\n",
    "\n",
    "# Stratification\n",
    "print(f\"PS Stratification:     {ate_strat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the propensity score stratification\n",
    "fig, ax = create_tufte_figure(figsize=(10, 6))\n",
    "\n",
    "quintile_means = strata_details.set_index('stratum')\n",
    "x = np.arange(len(quintile_means))\n",
    "width = 0.35\n",
    "\n",
    "# Get outcome means by quintile and treatment\n",
    "treated_means = []\n",
    "control_means = []\n",
    "for q in [1, 2, 3, 4, 5]:\n",
    "    stratum = mindset[mindset['ps_quintile'] == q]\n",
    "    treated_means.append(stratum[stratum['intervention']==1]['achievement_score'].mean())\n",
    "    control_means.append(stratum[stratum['intervention']==0]['achievement_score'].mean())\n",
    "\n",
    "ax.bar(x - width/2, control_means, width, label='Control', color=COLORS['blue'], alpha=0.7)\n",
    "ax.bar(x + width/2, treated_means, width, label='Treated', color=COLORS['red'], alpha=0.7)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Q1 (low PS)', 'Q2', 'Q3', 'Q4', 'Q5 (high PS)'])\n",
    "set_tufte_title(ax, \"Outcome by PS Quintile and Treatment\")\n",
    "set_tufte_labels(ax, \"Propensity Score Quintile\", \"Achievement Score\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Within each quintile, we compare treated vs control.\")\n",
    "print(\"This removes confounding because PS balances covariates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1: Why is the propensity score a balancing score?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "A **balancing score** $b(X)$ satisfies: $X \\perp T | b(X)$.\n",
    "\n",
    "**Why propensity score is balancing**:\n",
    "\n",
    "For any covariate $X_k$, within strata of $e(X)$:\n",
    "\n",
    "$$E[X_k | T=1, e(X)] = E[X_k | T=0, e(X)]$$\n",
    "\n",
    "**Intuition**: Among units with the same propensity score, treated and control groups are balanced on all covariates (on average).\n",
    "\n",
    "**Proof sketch**:\n",
    "1. $e(X) = P(T=1|X)$ is the conditional probability\n",
    "2. Within any stratum of $e(X)$, the probability of treatment is constant\n",
    "3. If treatment probability is constant conditional on $e(X)$, then treatment is essentially random within strata\n",
    "4. Random treatment implies balanced covariates\n",
    "\n",
    "**Key insight**: The propensity score is the **coarsest** balancing score - it summarizes all the information in $X$ that's relevant for treatment assignment.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q2: What assumptions are needed for propensity score methods?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Assumption 1: Conditional Ignorability (Unconfoundedness)**\n",
    "\n",
    "$$\\{Y(0), Y(1)\\} \\perp T | X$$\n",
    "\n",
    "Treatment is random conditional on observed covariates. **Cannot be tested** - requires subject matter knowledge.\n",
    "\n",
    "**Assumption 2: Positivity (Overlap/Common Support)**\n",
    "\n",
    "$$0 < e(X) < 1 \\quad \\text{for all } X$$\n",
    "\n",
    "Every unit has a chance of being treated or control. **Can be checked** by examining propensity score distributions.\n",
    "\n",
    "**Assumption 3: SUTVA**\n",
    "- No interference between units\n",
    "- No hidden versions of treatment\n",
    "\n",
    "**Assumption 4: Correct PS Model**\n",
    "\n",
    "The propensity score model should be correctly specified. Unlike outcome regression, we only need the PS model to balance covariates, not predict perfectly.\n",
    "\n",
    "**When PS methods fail**:\n",
    "1. Unmeasured confounding (violates A1)\n",
    "2. No overlap (violates A2)\n",
    "3. Severe PS model misspecification\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q3: How does propensity score solve the curse of dimensionality in matching?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**The Problem**:\n",
    "- Matching on $p$ covariates becomes infeasible as $p$ increases\n",
    "- In high dimensions, all points are approximately equidistant\n",
    "- Finding \"close\" matches becomes impossible\n",
    "\n",
    "**The PS Solution**:\n",
    "- Instead of matching on $p$ covariates, match on 1 scalar: $e(X)$\n",
    "- Propensity score summarizes all covariate information relevant for treatment\n",
    "- Matching on $e(X)$ balances all covariates (balancing score theorem)\n",
    "\n",
    "**Why this works**:\n",
    "\n",
    "The theorem proves that:\n",
    "$$(Y(0), Y(1)) \\perp T | X \\implies (Y(0), Y(1)) \\perp T | e(X)$$\n",
    "\n",
    "So we lose nothing (in terms of identification) by conditioning on the scalar $e(X)$ instead of the full vector $X$.\n",
    "\n",
    "**Trade-off**:\n",
    "- PS estimation introduces model dependence\n",
    "- If PS model is wrong, balance may be poor\n",
    "- Solution: Check balance after PS estimation\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[^1]: Facure, M. (2022). *Causal Inference for the Brave and True*, Chapter 11.\n",
    "\n",
    "[^2]: Rosenbaum, P. R., & Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. *Biometrika*, 70(1), 41-55.\n",
    "\n",
    "[^3]: Angrist, J. D., & Pischke, J.-S. (2009). *Mostly Harmless Econometrics*, Section 3.3.\n",
    "\n",
    "[^4]: Cross-reference: IPTW in `11_propensity_score/02_iptw.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
