{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Propensity Score Diagnostics\n",
    "\n",
    "**Chapter 11, Section 4**\n",
    "\n",
    "This notebook covers practical diagnostics for propensity score methods.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition) - Why diagnostics matter\n",
    "2. [Formal Treatment](#formal) - Overlap and balance metrics\n",
    "3. [Numeric Demonstration](#numeric) - Mindset data diagnostics\n",
    "4. [Implementation](#implementation) - Complete diagnostic workflow\n",
    "5. [Interview Appendix](#interview) - Practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set notebook style\n",
    "set_notebook_style()\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "### Why Diagnostics Matter\n",
    "\n",
    "Propensity score methods can fail silently in three ways:\n",
    "\n",
    "1. **Positivity violations**: Some covariate values only appear in one treatment group\n",
    "2. **Poor balance**: Weighting/matching doesn't actually balance covariates\n",
    "3. **Extreme weights**: A few observations dominate the estimate\n",
    "\n",
    "### The Three Key Diagnostics\n",
    "\n",
    "| Diagnostic | What It Checks | Solution If Violated |\n",
    "|------------|----------------|----------------------|\n",
    "| PS overlap | Can everyone receive both treatments? | Trim/restrict sample |\n",
    "| Covariate balance | Are covariates balanced after adjustment? | Respecify PS model |\n",
    "| Weight extremity | Do a few units dominate? | Stabilize/trim weights |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mindset data and estimate propensity scores\n",
    "mindset = load_facure_data(\"learning_mindset.csv\")\n",
    "\n",
    "covariates = [\n",
    "    'success_expect', 'ethnicity', 'gender', 'frst_in_family',\n",
    "    'school_mindset', 'school_achievement', 'school_ethnic_minority',\n",
    "    'school_poverty', 'school_size'\n",
    "]\n",
    "\n",
    "X = mindset[covariates].values\n",
    "T = mindset['intervention'].values\n",
    "Y = mindset['achievement_score'].values\n",
    "\n",
    "# Estimate propensity scores\n",
    "ps_model = LogisticRegression(C=1e6, max_iter=1000, solver='lbfgs')\n",
    "ps_model.fit(X, T)\n",
    "ps = ps_model.predict_proba(X)[:, 1]\n",
    "\n",
    "mindset['ps'] = ps\n",
    "\n",
    "print(f\"Data: {len(mindset)} students\")\n",
    "print(f\"Treated: {T.sum()} ({T.mean():.1%})\")\n",
    "print(f\"Control: {(1-T).sum()} ({(1-T).mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Treatment\n",
    "\n",
    "### 1. Positivity/Overlap Assumption\n",
    "\n",
    "**Requirement**: For all $x$ in the support,\n",
    "\n",
    "$$0 < P(T=1|X=x) < 1$$\n",
    "\n",
    "**In practice**: Check that PS distributions overlap.\n",
    "\n",
    "### 2. Covariate Balance Metrics\n",
    "\n",
    "**Standardized Mean Difference (SMD)**:\n",
    "\n",
    "$$SMD = \\frac{\\bar{X}_1 - \\bar{X}_0}{\\sqrt{(S_1^2 + S_0^2)/2}}$$\n",
    "\n",
    "**Rule of thumb**:\n",
    "- $|SMD| < 0.1$: Good balance\n",
    "- $|SMD| < 0.25$: Acceptable\n",
    "- $|SMD| \\geq 0.25$: Poor balance, respecify model\n",
    "\n",
    "### 3. Weight Diagnostics\n",
    "\n",
    "For IPTW, weights are: $w_i = T_i/e(X_i) + (1-T_i)/(1-e(X_i))$\n",
    "\n",
    "**Effective Sample Size**:\n",
    "\n",
    "$$ESS = \\frac{(\\sum w_i)^2}{\\sum w_i^2}$$\n",
    "\n",
    "Low ESS indicates a few units dominate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_smd(X, T, weights=None):\n",
    "    \"\"\"\n",
    "    Compute Standardized Mean Difference for each covariate.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : covariate matrix\n",
    "    T : treatment indicator\n",
    "    weights : optional weights for weighted means\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(T))\n",
    "    \n",
    "    # Normalize weights within groups\n",
    "    w1 = weights * T / np.sum(weights * T)\n",
    "    w0 = weights * (1-T) / np.sum(weights * (1-T))\n",
    "    \n",
    "    smds = []\n",
    "    for j in range(X.shape[1]):\n",
    "        x = X[:, j]\n",
    "        \n",
    "        # Weighted means\n",
    "        mean1 = np.sum(w1 * x)\n",
    "        mean0 = np.sum(w0 * x)\n",
    "        \n",
    "        # Unweighted variances (for denominator)\n",
    "        var1 = np.var(x[T==1])\n",
    "        var0 = np.var(x[T==0])\n",
    "        \n",
    "        # Pooled SD\n",
    "        pooled_sd = np.sqrt((var1 + var0) / 2)\n",
    "        \n",
    "        if pooled_sd > 0:\n",
    "            smd = (mean1 - mean0) / pooled_sd\n",
    "        else:\n",
    "            smd = 0.0\n",
    "        \n",
    "        smds.append(smd)\n",
    "    \n",
    "    return np.array(smds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numeric Demonstration\n",
    "\n",
    "### Diagnostic 1: PS Distribution Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PS overlap\n",
    "fig, axes = create_tufte_figure(ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Left: Histograms\n",
    "ax = axes[0]\n",
    "ax.hist(ps[T==0], bins=30, alpha=0.5, color=COLORS['blue'], label='Control', density=True)\n",
    "ax.hist(ps[T==1], bins=30, alpha=0.5, color=COLORS['red'], label='Treated', density=True)\n",
    "set_tufte_title(ax, \"PS Distribution by Treatment\")\n",
    "set_tufte_labels(ax, \"Propensity Score\", \"Density\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Right: Box plots\n",
    "ax = axes[1]\n",
    "bp = ax.boxplot([ps[T==0], ps[T==1]], labels=['Control', 'Treated'], patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor(COLORS['blue'])\n",
    "bp['boxes'][1].set_facecolor(COLORS['red'])\n",
    "for box in bp['boxes']:\n",
    "    box.set_alpha(0.5)\n",
    "set_tufte_title(ax, \"PS Summary by Group\")\n",
    "set_tufte_labels(ax, \"\", \"Propensity Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overlap statistics\n",
    "print(\"OVERLAP STATISTICS:\")\n",
    "print(f\"Control PS range: [{ps[T==0].min():.4f}, {ps[T==0].max():.4f}]\")\n",
    "print(f\"Treated PS range: [{ps[T==1].min():.4f}, {ps[T==1].max():.4f}]\")\n",
    "print(f\"Common support: [{max(ps[T==0].min(), ps[T==1].min()):.4f}, {min(ps[T==0].max(), ps[T==1].max()):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Diagnostic 2: Covariate Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute balance before and after IPTW\n",
    "weights_iptw = T / ps + (1 - T) / (1 - ps)\n",
    "\n",
    "smd_before = compute_smd(X, T, weights=None)\n",
    "smd_after = compute_smd(X, T, weights=weights_iptw)\n",
    "\n",
    "# Create balance plot\n",
    "fig, ax = create_tufte_figure(figsize=(10, 6))\n",
    "\n",
    "y_pos = np.arange(len(covariates))\n",
    "\n",
    "ax.scatter(smd_before, y_pos, color=COLORS['red'], s=80, label='Before Weighting', zorder=3)\n",
    "ax.scatter(smd_after, y_pos, color=COLORS['blue'], s=80, label='After IPTW', zorder=3)\n",
    "\n",
    "# Reference lines\n",
    "ax.axvline(0, color='gray', linewidth=1, alpha=0.5)\n",
    "ax.axvline(0.1, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.axvline(-0.1, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(covariates)\n",
    "ax.set_xlim(-0.5, 0.5)\n",
    "\n",
    "set_tufte_title(ax, \"Covariate Balance: Before vs After IPTW\")\n",
    "set_tufte_labels(ax, \"Standardized Mean Difference\", \"\")\n",
    "ax.legend(frameon=False, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print balance table\n",
    "print(\"\\nBALANCE TABLE:\")\n",
    "print(f\"{'Covariate':<25} {'Before':>10} {'After':>10} {'Improved':>10}\")\n",
    "print(\"-\" * 55)\n",
    "for i, cov in enumerate(covariates):\n",
    "    improved = abs(smd_after[i]) < abs(smd_before[i])\n",
    "    print(f\"{cov:<25} {smd_before[i]:>10.4f} {smd_after[i]:>10.4f} {'Yes' if improved else 'No':>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### Diagnostic 3: Weight Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_sample_size(weights, treatment):\n",
    "    \"\"\"Compute effective sample size for each group.\"\"\"\n",
    "    ess_treated = np.sum(weights[treatment==1])**2 / np.sum(weights[treatment==1]**2)\n",
    "    ess_control = np.sum(weights[treatment==0])**2 / np.sum(weights[treatment==0]**2)\n",
    "    return ess_treated, ess_control\n",
    "\n",
    "# Weight diagnostics\n",
    "fig, axes = create_tufte_figure(ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Left: Weight distribution\n",
    "ax = axes[0]\n",
    "ax.hist(weights_iptw, bins=50, color=COLORS['gray'], edgecolor='white', alpha=0.7)\n",
    "ax.axvline(np.median(weights_iptw), color=COLORS['red'], linestyle='--', label=f'Median: {np.median(weights_iptw):.2f}')\n",
    "set_tufte_title(ax, \"IPTW Weight Distribution\")\n",
    "set_tufte_labels(ax, \"Weight\", \"Count\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Right: Extreme weights\n",
    "ax = axes[1]\n",
    "sorted_weights = np.sort(weights_iptw)[::-1]\n",
    "cumsum = np.cumsum(sorted_weights) / np.sum(sorted_weights)\n",
    "ax.plot(np.arange(1, len(cumsum)+1), cumsum, color=COLORS['blue'], linewidth=2)\n",
    "ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axvline(np.searchsorted(cumsum, 0.5), color='gray', linestyle='--', alpha=0.5)\n",
    "set_tufte_title(ax, \"Cumulative Weight Contribution\")\n",
    "set_tufte_labels(ax, \"Number of Units (sorted by weight)\", \"Cumulative Share\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute ESS\n",
    "ess_t, ess_c = effective_sample_size(weights_iptw, T)\n",
    "\n",
    "print(\"\\nWEIGHT STATISTICS:\")\n",
    "print(f\"Weight range: [{weights_iptw.min():.2f}, {weights_iptw.max():.2f}]\")\n",
    "print(f\"Weight mean: {weights_iptw.mean():.2f}\")\n",
    "print(f\"Weight std: {weights_iptw.std():.2f}\")\n",
    "print(f\"Max/Median ratio: {weights_iptw.max()/np.median(weights_iptw):.1f}x\")\n",
    "print(f\"\\nEffective Sample Size:\")\n",
    "print(f\"  Treated: {ess_t:.0f} / {T.sum()} ({ess_t/T.sum():.1%})\")\n",
    "print(f\"  Control: {ess_c:.0f} / {(1-T).sum()} ({ess_c/(1-T).sum():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Weight Trimming (Use with Caution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_weights(weights, percentile=99):\n",
    "    \"\"\"\n",
    "    Trim extreme weights to a percentile threshold.\n",
    "    \n",
    "    WARNING: Trimming introduces bias. Use only when\n",
    "    extreme weights dominate the estimate.\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(weights, percentile)\n",
    "    trimmed = np.minimum(weights, threshold)\n",
    "    return trimmed\n",
    "\n",
    "def iptw_ate_comparison(Y, T, ps, trim_pct=None):\n",
    "    \"\"\"Compare IPTW with and without trimming.\"\"\"\n",
    "    # Standard weights\n",
    "    weights = T / ps + (1 - T) / (1 - ps)\n",
    "    \n",
    "    if trim_pct is not None:\n",
    "        weights = trim_weights(weights, trim_pct)\n",
    "    \n",
    "    # Hajek estimator\n",
    "    mu1 = np.sum(T * Y * weights) / np.sum(T * weights)\n",
    "    mu0 = np.sum((1 - T) * Y * weights) / np.sum((1 - T) * weights)\n",
    "    \n",
    "    return mu1 - mu0\n",
    "\n",
    "# Compare estimates\n",
    "print(\"IPTW SENSITIVITY TO TRIMMING:\")\n",
    "print(\"=\" * 50)\n",
    "for pct in [None, 99, 95, 90]:\n",
    "    ate = iptw_ate_comparison(Y, T, ps, trim_pct=pct)\n",
    "    label = f\"Trim {pct}%\" if pct else \"No trimming\"\n",
    "    print(f\"{label:<15}: ATE = {ate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete diagnostic workflow\n",
    "def ps_diagnostic_summary(X, T, Y, covariates, ps):\n",
    "    \"\"\"Generate complete PS diagnostic summary.\"\"\"\n",
    "    weights = T / ps + (1 - T) / (1 - ps)\n",
    "    \n",
    "    # 1. Overlap\n",
    "    overlap_min = max(ps[T==0].min(), ps[T==1].min())\n",
    "    overlap_max = min(ps[T==0].max(), ps[T==1].max())\n",
    "    overlap_good = overlap_min < 0.1 and overlap_max > 0.9\n",
    "    \n",
    "    # 2. Balance\n",
    "    smd_before = compute_smd(X, T, weights=None)\n",
    "    smd_after = compute_smd(X, T, weights=weights)\n",
    "    max_smd_before = np.max(np.abs(smd_before))\n",
    "    max_smd_after = np.max(np.abs(smd_after))\n",
    "    balance_improved = max_smd_after < max_smd_before\n",
    "    balance_good = max_smd_after < 0.1\n",
    "    \n",
    "    # 3. Weights\n",
    "    ess_t, ess_c = effective_sample_size(weights, T)\n",
    "    ess_ratio_t = ess_t / T.sum()\n",
    "    ess_ratio_c = ess_c / (1-T).sum()\n",
    "    weights_good = min(ess_ratio_t, ess_ratio_c) > 0.5\n",
    "    \n",
    "    print(\"PS DIAGNOSTIC SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\n1. OVERLAP:\")\n",
    "    print(f\"   Common support: [{overlap_min:.4f}, {overlap_max:.4f}]\")\n",
    "    print(f\"   Status: {'GOOD' if overlap_good else 'CHECK'}\")\n",
    "    print(f\"\\n2. BALANCE:\")\n",
    "    print(f\"   Max SMD before: {max_smd_before:.4f}\")\n",
    "    print(f\"   Max SMD after:  {max_smd_after:.4f}\")\n",
    "    print(f\"   Improved: {'Yes' if balance_improved else 'No'}\")\n",
    "    print(f\"   Status: {'GOOD' if balance_good else 'CHECK'}\")\n",
    "    print(f\"\\n3. WEIGHTS:\")\n",
    "    print(f\"   ESS treated: {ess_t:.0f}/{T.sum()} ({ess_ratio_t:.1%})\")\n",
    "    print(f\"   ESS control: {ess_c:.0f}/{int((1-T).sum())} ({ess_ratio_c:.1%})\")\n",
    "    print(f\"   Status: {'GOOD' if weights_good else 'CHECK'}\")\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    overall = 'GOOD' if (overlap_good and balance_good and weights_good) else 'REVIEW NEEDED'\n",
    "    print(f\"OVERALL: {overall}\")\n",
    "\n",
    "ps_diagnostic_summary(X, T, Y, covariates, ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1: How do you check if propensity score estimation worked?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Three key diagnostics**:\n",
    "\n",
    "1. **Overlap/Positivity**:\n",
    "   - Plot PS distributions for treated and control\n",
    "   - Check for common support (both groups have similar PS ranges)\n",
    "   - Red flag: No overlap in certain regions\n",
    "\n",
    "2. **Covariate Balance**:\n",
    "   - Compute SMD before and after weighting/matching\n",
    "   - Target: |SMD| < 0.1 for all covariates\n",
    "   - If balance doesn't improve, respecify PS model\n",
    "\n",
    "3. **Weight Extremity**:\n",
    "   - Check weight distribution and ESS\n",
    "   - Red flag: ESS < 50% of nominal sample\n",
    "   - Consider stabilized weights or trimming (with caution)\n",
    "\n",
    "**Key insight**: The PS model doesn't need to be \"correct\" - it needs to achieve balance.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q2: What is the positivity assumption and why does it matter?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Definition**: $0 < P(T=1|X=x) < 1$ for all $x$ in the support.\n",
    "\n",
    "**Interpretation**: Every unit has some chance of receiving either treatment.\n",
    "\n",
    "**Why it matters**:\n",
    "- IPTW uses weights $1/e(X)$ and $1/(1-e(X))$\n",
    "- If $e(X) \\approx 0$ or $e(X) \\approx 1$, weights explode\n",
    "- This leads to high variance and unstable estimates\n",
    "\n",
    "**Practical violations**:\n",
    "- Deterministic treatment rules (age > 65 always gets Medicare)\n",
    "- Rare covariate combinations only in one group\n",
    "\n",
    "**Solutions**:\n",
    "- Restrict analysis to common support\n",
    "- Trim extreme propensity scores (e.g., keep 0.05 < PS < 0.95)\n",
    "- Use doubly robust methods (more stable with near-violations)\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q3: What is the effective sample size and when should you worry?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Definition**: $ESS = (\\sum w_i)^2 / \\sum w_i^2$\n",
    "\n",
    "**Interpretation**: The number of equally-weighted observations that would give the same variance.\n",
    "\n",
    "**Example**:\n",
    "- 1000 observations, but 10 have huge weights\n",
    "- ESS might be only 50-100\n",
    "- Your estimate is effectively based on 50-100 units\n",
    "\n",
    "**When to worry**:\n",
    "- ESS < 50% of nominal sample → Significant information loss\n",
    "- ESS < 30% → Results dominated by few observations\n",
    "- Very low ESS → May need different method entirely\n",
    "\n",
    "**Solutions**:\n",
    "1. Stabilized weights: $w_i = P(T_i) / e(X_i)$ instead of $1/e(X_i)$\n",
    "2. Weight trimming (introduces bias)\n",
    "3. Consider matching instead of weighting\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[^1]: Facure, M. (2022). *Causal Inference for the Brave and True*, Chapter 11.\n",
    "\n",
    "[^2]: Austin, P. C. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity-score matched samples. *Statistics in Medicine*, 28(25), 3083-3107.\n",
    "\n",
    "[^3]: Crump, R. K., et al. (2009). Dealing with limited overlap in estimation of average treatment effects. *Biometrika*, 96(1), 187-199.\n",
    "\n",
    "[^4]: Cross-reference: `src/causal_inference/psm/diagnostics.py` for production balance metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
