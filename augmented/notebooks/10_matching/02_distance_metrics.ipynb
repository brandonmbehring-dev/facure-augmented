{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Distance Metrics for Matching\n",
    "\n",
    "**Chapter 10, Section 2**\n",
    "\n",
    "This notebook covers how to measure \"similarity\" between units when exact matching isn't possible.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Intuition](#intuition) - Why distance matters\n",
    "2. [Formal Treatment](#formal) - Distance metric definitions\n",
    "3. [Numeric Demonstration](#numeric) - Comparing metrics on medicine data\n",
    "4. [Implementation](#implementation) - Feature scaling and matching\n",
    "5. [Interview Appendix](#interview) - Practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import *\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set notebook style\n",
    "set_notebook_style()\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intuition\n",
    "\n",
    "### The Problem with Continuous Covariates\n",
    "\n",
    "Exact matching works when covariates are discrete with limited values. But with continuous covariates:\n",
    "\n",
    "- Age = 35.04913... has no exact match\n",
    "- Income = $52,347.23 is unique\n",
    "- Probability = 0.73421... appears once\n",
    "\n",
    "We need to find \"close enough\" matches instead of exact ones.\n",
    "\n",
    "### Distance as Similarity\n",
    "\n",
    "**Core insight**: Use a distance function to measure how similar two units are.\n",
    "\n",
    "$$d(x_i, x_j) = \\text{\"how different are units } i \\text{ and } j \\text{ on covariates?\"}$$\n",
    "\n",
    "Small distance = similar units = good match.\n",
    "\n",
    "### The Feature Scale Problem\n",
    "\n",
    "Consider matching on age (20-60 years) and income ($20,000-$200,000):\n",
    "\n",
    "| Unit | Age | Income |\n",
    "|------|-----|--------|\n",
    "| A | 30 | $50,000 |\n",
    "| B | 31 | $50,000 |\n",
    "| C | 30 | $100,000 |\n",
    "\n",
    "Naive Euclidean distance:\n",
    "- $d(A, B) = \\sqrt{(30-31)^2 + (50000-50000)^2} = 1$\n",
    "- $d(A, C) = \\sqrt{(30-30)^2 + (50000-100000)^2} = 50000$\n",
    "\n",
    "Income dominates! A 1-year age difference is treated as negligible compared to income differences.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load medicine data\n",
    "med = load_facure_data(\"medicine_impact_recovery.csv\")\n",
    "\n",
    "print(f\"Data: {len(med)} patients\")\n",
    "print(f\"Treatment (medication): {med['medication'].mean():.1%} received medication\")\n",
    "print(f\"\\nColumns: {list(med.columns)}\")\n",
    "print(f\"\\nFeature ranges:\")\n",
    "for col in ['age', 'severity']:\n",
    "    print(f\"  {col}: [{med[col].min():.2f}, {med[col].max():.2f}]\")\n",
    "med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the scale problem\n",
    "features = ['age', 'severity']\n",
    "print(\"SCALE PROBLEM:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nAge range: {med['age'].max() - med['age'].min():.1f} years\")\n",
    "print(f\"Severity range: {med['severity'].max() - med['severity'].min():.3f} units\")\n",
    "print(f\"\\nRatio: Age range / Severity range = {(med['age'].max() - med['age'].min()) / (med['severity'].max() - med['severity'].min()):.0f}x\")\n",
    "print(f\"\\nAge differences will dominate naive Euclidean distance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Treatment\n",
    "\n",
    "### Distance Metrics\n",
    "\n",
    "**Definition 1** (Euclidean Distance):\n",
    "\n",
    "$$d_{Euc}(x_i, x_j) = \\sqrt{\\sum_{k=1}^{p} (x_{ik} - x_{jk})^2}$$\n",
    "\n",
    "Standard \"as the crow flies\" distance. Sensitive to feature scales.\n",
    "\n",
    "**Definition 2** (Standardized Euclidean Distance):\n",
    "\n",
    "First standardize features: $\\tilde{x}_{ik} = \\frac{x_{ik} - \\bar{x}_k}{s_k}$\n",
    "\n",
    "Then compute Euclidean distance on standardized values:\n",
    "\n",
    "$$d_{SEuc}(x_i, x_j) = \\sqrt{\\sum_{k=1}^{p} \\left(\\frac{x_{ik} - x_{jk}}{s_k}\\right)^2}$$\n",
    "\n",
    "**Definition 3** (Mahalanobis Distance):\n",
    "\n",
    "$$d_{Mah}(x_i, x_j) = \\sqrt{(x_i - x_j)' \\Sigma^{-1} (x_i - x_j)}$$\n",
    "\n",
    "where $\\Sigma$ is the covariance matrix of $X$.\n",
    "\n",
    "Accounts for both scale and correlation between features.\n",
    "\n",
    "### Why Mahalanobis?\n",
    "\n",
    "| Metric | Handles Scale? | Handles Correlation? |\n",
    "|--------|---------------|---------------------|\n",
    "| Euclidean | No | No |\n",
    "| Standardized Euclidean | Yes | No |\n",
    "| Mahalanobis | Yes | Yes |\n",
    "\n",
    "If features are correlated, Mahalanobis \"stretches\" the space to account for this.\n",
    "\n",
    "**Key insight**: Standardized Euclidean is a special case of Mahalanobis with diagonal covariance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement distance metrics\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"Standard Euclidean distance.\"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "def standardized_euclidean(x1, x2, means, stds):\n",
    "    \"\"\"Euclidean distance on standardized features.\"\"\"\n",
    "    z1 = (x1 - means) / stds\n",
    "    z2 = (x2 - means) / stds\n",
    "    return np.sqrt(np.sum((z1 - z2)**2))\n",
    "\n",
    "def mahalanobis_distance(x1, x2, cov_inv):\n",
    "    \"\"\"Mahalanobis distance using inverse covariance.\"\"\"\n",
    "    diff = x1 - x2\n",
    "    return np.sqrt(diff @ cov_inv @ diff)\n",
    "\n",
    "# Prepare data\n",
    "features = ['age', 'severity']\n",
    "X = med[features].values\n",
    "means = X.mean(axis=0)\n",
    "stds = X.std(axis=0)\n",
    "cov_matrix = np.cov(X.T)\n",
    "cov_inv = np.linalg.inv(cov_matrix)\n",
    "\n",
    "print(\"Feature statistics:\")\n",
    "print(f\"Means: age={means[0]:.2f}, severity={means[1]:.3f}\")\n",
    "print(f\"Stds:  age={stds[0]:.2f}, severity={stds[1]:.3f}\")\n",
    "print(f\"\\nCovariance matrix:\")\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distances for specific pairs\n",
    "# Pick a reference patient and compare to two candidates\n",
    "np.random.seed(42)\n",
    "ref_idx = np.random.choice(len(med))\n",
    "ref = X[ref_idx]\n",
    "\n",
    "# Find patients with different characteristics\n",
    "# Candidate 1: Similar age, different severity\n",
    "similar_age_mask = np.abs(X[:, 0] - ref[0]) < 1  # Within 1 year\n",
    "different_severity_mask = np.abs(X[:, 1] - ref[1]) > 0.3  # Different severity\n",
    "cand1_mask = similar_age_mask & different_severity_mask\n",
    "if cand1_mask.sum() > 0:\n",
    "    cand1_idx = np.where(cand1_mask)[0][0]\n",
    "else:\n",
    "    cand1_idx = np.random.choice(len(med))\n",
    "cand1 = X[cand1_idx]\n",
    "\n",
    "# Candidate 2: Different age, similar severity\n",
    "different_age_mask = np.abs(X[:, 0] - ref[0]) > 10  # More than 10 years\n",
    "similar_severity_mask = np.abs(X[:, 1] - ref[1]) < 0.1  # Similar severity\n",
    "cand2_mask = different_age_mask & similar_severity_mask\n",
    "if cand2_mask.sum() > 0:\n",
    "    cand2_idx = np.where(cand2_mask)[0][0]\n",
    "else:\n",
    "    cand2_idx = np.random.choice(len(med))\n",
    "cand2 = X[cand2_idx]\n",
    "\n",
    "print(\"COMPARING DISTANCE METRICS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nReference patient: age={ref[0]:.1f}, severity={ref[1]:.3f}\")\n",
    "print(f\"Candidate 1: age={cand1[0]:.1f}, severity={cand1[1]:.3f} (similar age)\")\n",
    "print(f\"Candidate 2: age={cand2[0]:.1f}, severity={cand2[1]:.3f} (similar severity)\")\n",
    "\n",
    "print(f\"\\nDistances to Reference:\")\n",
    "print(f\"{'Metric':<25} {'Candidate 1':<15} {'Candidate 2':<15} {'Better Match'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "d_euc1 = euclidean_distance(ref, cand1)\n",
    "d_euc2 = euclidean_distance(ref, cand2)\n",
    "print(f\"{'Euclidean':<25} {d_euc1:<15.3f} {d_euc2:<15.3f} {'Cand 1' if d_euc1 < d_euc2 else 'Cand 2'}\")\n",
    "\n",
    "d_seuc1 = standardized_euclidean(ref, cand1, means, stds)\n",
    "d_seuc2 = standardized_euclidean(ref, cand2, means, stds)\n",
    "print(f\"{'Standardized Euclidean':<25} {d_seuc1:<15.3f} {d_seuc2:<15.3f} {'Cand 1' if d_seuc1 < d_seuc2 else 'Cand 2'}\")\n",
    "\n",
    "d_mah1 = mahalanobis_distance(ref, cand1, cov_inv)\n",
    "d_mah2 = mahalanobis_distance(ref, cand2, cov_inv)\n",
    "print(f\"{'Mahalanobis':<25} {d_mah1:<15.3f} {d_mah2:<15.3f} {'Cand 1' if d_mah1 < d_mah2 else 'Cand 2'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numeric Demonstration\n",
    "\n",
    "### Feature Scaling Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the effect of standardization\n",
    "fig, axes = create_tufte_figure(ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Subset for visualization\n",
    "np.random.seed(42)\n",
    "sample_idx = np.random.choice(len(med), 500, replace=False)\n",
    "X_sample = X[sample_idx]\n",
    "\n",
    "# Left: Raw features\n",
    "ax = axes[0]\n",
    "ax.scatter(X_sample[:, 0], X_sample[:, 1], alpha=0.5, s=30, c=COLORS['blue'])\n",
    "set_tufte_title(ax, \"Raw Features (Different Scales)\")\n",
    "set_tufte_labels(ax, \"Age\", \"Severity\")\n",
    "\n",
    "# Draw a unit circle (stretched by scales)\n",
    "center = np.array([40, 0.5])\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "# Circle with radius proportional to std\n",
    "circle_x = center[0] + stds[0] * np.cos(theta)\n",
    "circle_y = center[1] + stds[1] * np.sin(theta)\n",
    "ax.plot(circle_x, circle_y, color=COLORS['red'], linewidth=2, linestyle='--', label='1-std circle')\n",
    "ax.scatter([center[0]], [center[1]], color=COLORS['red'], s=100, marker='x', zorder=5)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Right: Standardized features\n",
    "ax = axes[1]\n",
    "X_std = (X_sample - means) / stds\n",
    "ax.scatter(X_std[:, 0], X_std[:, 1], alpha=0.5, s=30, c=COLORS['blue'])\n",
    "set_tufte_title(ax, \"Standardized Features (Same Scale)\")\n",
    "set_tufte_labels(ax, \"Age (z-score)\", \"Severity (z-score)\")\n",
    "\n",
    "# Draw unit circle (now truly circular)\n",
    "center_std = np.array([0, 0])\n",
    "circle_x = center_std[0] + np.cos(theta)\n",
    "circle_y = center_std[1] + np.sin(theta)\n",
    "ax.plot(circle_x, circle_y, color=COLORS['red'], linewidth=2, linestyle='--', label='1-std circle')\n",
    "ax.scatter([0], [0], color=COLORS['red'], s=100, marker='x', zorder=5)\n",
    "ax.legend(frameon=False)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"After standardization, both features contribute equally to distance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare matching quality with different distance metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Split into treated and control\n",
    "treated_mask = med['medication'] == 1\n",
    "X_treated = X[treated_mask]\n",
    "X_control = X[~treated_mask]\n",
    "Y_treated = med.loc[treated_mask, 'recovery'].values\n",
    "Y_control = med.loc[~treated_mask, 'recovery'].values\n",
    "\n",
    "# Standardize control group (for standardized matching)\n",
    "scaler = StandardScaler()\n",
    "X_control_std = scaler.fit_transform(X_control)\n",
    "X_treated_std = scaler.transform(X_treated)\n",
    "\n",
    "print(f\"Treated: {len(X_treated)} patients\")\n",
    "print(f\"Control: {len(X_control)} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_ate(X_treated, X_control, Y_treated, Y_control, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    Estimate ATT using 1-nearest neighbor matching.\n",
    "    \"\"\"\n",
    "    # Fit nearest neighbor on control group\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric=metric)\n",
    "    nn.fit(X_control)\n",
    "    \n",
    "    # Find nearest control for each treated\n",
    "    distances, indices = nn.kneighbors(X_treated)\n",
    "    \n",
    "    # Get matched control outcomes\n",
    "    matched_control_outcomes = Y_control[indices.flatten()]\n",
    "    \n",
    "    # ATT = mean of (treated outcome - matched control outcome)\n",
    "    individual_effects = Y_treated - matched_control_outcomes\n",
    "    att = individual_effects.mean()\n",
    "    se = individual_effects.std() / np.sqrt(len(individual_effects))\n",
    "    \n",
    "    return {\n",
    "        'ATT': att,\n",
    "        'SE': se,\n",
    "        'mean_distance': distances.mean(),\n",
    "        'max_distance': distances.max()\n",
    "    }\n",
    "\n",
    "# Compare metrics\n",
    "print(\"MATCHING ESTIMATES BY DISTANCE METRIC:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Naive (no matching)\n",
    "naive_att = Y_treated.mean() - Y_control.mean()\n",
    "print(f\"\\nNaive (no matching): ATT = {naive_att:.2f}\")\n",
    "\n",
    "# Euclidean on raw features\n",
    "result_euc = matching_ate(X_treated, X_control, Y_treated, Y_control, 'euclidean')\n",
    "print(f\"\\nEuclidean (raw features):\")\n",
    "print(f\"  ATT = {result_euc['ATT']:.2f} (SE = {result_euc['SE']:.2f})\")\n",
    "print(f\"  Mean match distance: {result_euc['mean_distance']:.3f}\")\n",
    "\n",
    "# Euclidean on standardized features\n",
    "result_std = matching_ate(X_treated_std, X_control_std, Y_treated, Y_control, 'euclidean')\n",
    "print(f\"\\nEuclidean (standardized):\")\n",
    "print(f\"  ATT = {result_std['ATT']:.2f} (SE = {result_std['SE']:.2f})\")\n",
    "print(f\"  Mean match distance: {result_std['mean_distance']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis matching\n",
    "# Use scipy for Mahalanobis with precomputed covariance\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Compute Mahalanobis distances from all treated to all control\n",
    "cov_matrix_full = np.cov(X.T)\n",
    "cov_inv_full = np.linalg.inv(cov_matrix_full)\n",
    "\n",
    "# For each treated, find nearest control by Mahalanobis\n",
    "distances_mah = cdist(X_treated, X_control, metric='mahalanobis', VI=cov_inv_full)\n",
    "nearest_indices = distances_mah.argmin(axis=1)\n",
    "nearest_distances = distances_mah.min(axis=1)\n",
    "\n",
    "# Get matched outcomes\n",
    "matched_outcomes_mah = Y_control[nearest_indices]\n",
    "effects_mah = Y_treated - matched_outcomes_mah\n",
    "att_mah = effects_mah.mean()\n",
    "se_mah = effects_mah.std() / np.sqrt(len(effects_mah))\n",
    "\n",
    "print(f\"\\nMahalanobis:\")\n",
    "print(f\"  ATT = {att_mah:.2f} (SE = {se_mah:.2f})\")\n",
    "print(f\"  Mean match distance: {nearest_distances.mean():.3f}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY:\")\n",
    "print(f\"{'Method':<25} {'ATT':<10} {'SE':<10} {'95% CI'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Naive':<25} {naive_att:<10.2f} {'-':<10} -\")\n",
    "print(f\"{'Euclidean (raw)':<25} {result_euc['ATT']:<10.2f} {result_euc['SE']:<10.2f} [{result_euc['ATT']-1.96*result_euc['SE']:.2f}, {result_euc['ATT']+1.96*result_euc['SE']:.2f}]\")\n",
    "print(f\"{'Euclidean (standardized)':<25} {result_std['ATT']:<10.2f} {result_std['SE']:<10.2f} [{result_std['ATT']-1.96*result_std['SE']:.2f}, {result_std['ATT']+1.96*result_std['SE']:.2f}]\")\n",
    "print(f\"{'Mahalanobis':<25} {att_mah:<10.2f} {se_mah:<10.2f} [{att_mah-1.96*se_mah:.2f}, {att_mah+1.96*se_mah:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Match Quality Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize match quality for different metrics\n",
    "fig, axes = create_tufte_figure(ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Get matches for visualization (subset)\n",
    "np.random.seed(42)\n",
    "viz_idx = np.random.choice(len(X_treated), 50, replace=False)\n",
    "\n",
    "# Euclidean matches (raw)\n",
    "nn_euc = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "nn_euc.fit(X_control)\n",
    "_, euc_matches = nn_euc.kneighbors(X_treated[viz_idx])\n",
    "\n",
    "ax = axes[0]\n",
    "for i, (t_idx, c_idx) in enumerate(zip(viz_idx, euc_matches.flatten())):\n",
    "    ax.plot([X_treated[t_idx, 0], X_control[c_idx, 0]], \n",
    "            [X_treated[t_idx, 1], X_control[c_idx, 1]], \n",
    "            color='gray', alpha=0.3, linewidth=0.5)\n",
    "ax.scatter(X_treated[viz_idx, 0], X_treated[viz_idx, 1], \n",
    "           c=COLORS['red'], s=30, label='Treated', alpha=0.7)\n",
    "ax.scatter(X_control[euc_matches.flatten(), 0], X_control[euc_matches.flatten(), 1], \n",
    "           c=COLORS['blue'], s=30, label='Matched Control', alpha=0.7)\n",
    "set_tufte_title(ax, \"Euclidean Matching (Raw Features)\")\n",
    "set_tufte_labels(ax, \"Age\", \"Severity\")\n",
    "ax.legend(frameon=False, loc='upper right')\n",
    "\n",
    "# Standardized Euclidean matches\n",
    "nn_std = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "nn_std.fit(X_control_std)\n",
    "_, std_matches = nn_std.kneighbors(X_treated_std[viz_idx])\n",
    "\n",
    "ax = axes[1]\n",
    "for i, (t_idx, c_idx) in enumerate(zip(viz_idx, std_matches.flatten())):\n",
    "    ax.plot([X_treated[t_idx, 0], X_control[c_idx, 0]], \n",
    "            [X_treated[t_idx, 1], X_control[c_idx, 1]], \n",
    "            color='gray', alpha=0.3, linewidth=0.5)\n",
    "ax.scatter(X_treated[viz_idx, 0], X_treated[viz_idx, 1], \n",
    "           c=COLORS['red'], s=30, label='Treated', alpha=0.7)\n",
    "ax.scatter(X_control[std_matches.flatten(), 0], X_control[std_matches.flatten(), 1], \n",
    "           c=COLORS['blue'], s=30, label='Matched Control', alpha=0.7)\n",
    "set_tufte_title(ax, \"Euclidean Matching (Standardized)\")\n",
    "set_tufte_labels(ax, \"Age\", \"Severity\")\n",
    "ax.legend(frameon=False, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Standardized matching produces more balanced matches across both features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze match quality: covariate balance\n",
    "def analyze_balance(X_treated, X_control_matched, feature_names):\n",
    "    \"\"\"Compute standardized mean differences (SMD) for balance check.\"\"\"\n",
    "    results = []\n",
    "    for i, name in enumerate(feature_names):\n",
    "        treat_mean = X_treated[:, i].mean()\n",
    "        control_mean = X_control_matched[:, i].mean()\n",
    "        pooled_std = np.sqrt((X_treated[:, i].var() + X_control_matched[:, i].var()) / 2)\n",
    "        smd = (treat_mean - control_mean) / pooled_std\n",
    "        results.append({\n",
    "            'feature': name,\n",
    "            'treated_mean': treat_mean,\n",
    "            'control_mean': control_mean,\n",
    "            'SMD': smd\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Balance before matching\n",
    "print(\"COVARIATE BALANCE ANALYSIS:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nBefore matching:\")\n",
    "balance_before = analyze_balance(X_treated, X_control, features)\n",
    "print(balance_before.to_string(index=False))\n",
    "\n",
    "# Balance after Euclidean (raw)\n",
    "print(\"\\nAfter Euclidean (raw):\")\n",
    "nn_euc_full = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "nn_euc_full.fit(X_control)\n",
    "_, euc_all_matches = nn_euc_full.kneighbors(X_treated)\n",
    "balance_euc = analyze_balance(X_treated, X_control[euc_all_matches.flatten()], features)\n",
    "print(balance_euc.to_string(index=False))\n",
    "\n",
    "# Balance after standardized\n",
    "print(\"\\nAfter standardized Euclidean:\")\n",
    "nn_std_full = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "nn_std_full.fit(X_control_std)\n",
    "_, std_all_matches = nn_std_full.kneighbors(X_treated_std)\n",
    "balance_std = analyze_balance(X_treated, X_control[std_all_matches.flatten()], features)\n",
    "print(balance_std.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SMD < 0.1 is generally considered good balance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1: Why is feature scaling important for matching?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "Feature scaling is critical because:\n",
    "\n",
    "**The Problem**: Different features have different scales (age in years, income in dollars, probability in 0-1). Without scaling, features with larger numeric ranges dominate distance calculations.\n",
    "\n",
    "**Example**: Age difference of 5 years vs income difference of $50,000\n",
    "- Raw Euclidean: Income dominates (50,000 >> 5)\n",
    "- Standardized: Both contribute proportionally to their variability\n",
    "\n",
    "**Solutions**:\n",
    "1. **Standardization** (z-score): $\\tilde{x} = (x - \\bar{x}) / s$\n",
    "   - Centers at 0, scales to unit variance\n",
    "   - Most common approach\n",
    "\n",
    "2. **Min-max scaling**: $\\tilde{x} = (x - x_{min}) / (x_{max} - x_{min})$\n",
    "   - Scales to [0, 1] range\n",
    "   - Sensitive to outliers\n",
    "\n",
    "3. **Mahalanobis distance**: Accounts for scale AND correlation\n",
    "   - Uses covariance matrix\n",
    "   - Most sophisticated\n",
    "\n",
    "**Practical rule**: Always standardize before matching unless you have a principled reason not to.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q2: What is the Mahalanobis distance and when would you use it?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Definition**: Mahalanobis distance accounts for feature correlations:\n",
    "\n",
    "$$d_{Mah}(x_i, x_j) = \\sqrt{(x_i - x_j)' \\Sigma^{-1} (x_i - x_j)}$$\n",
    "\n",
    "**Intuition**: It measures distance in units of standard deviations along the principal axes of the data.\n",
    "\n",
    "**When to use Mahalanobis**:\n",
    "1. **Correlated features**: When features are strongly correlated, standardized Euclidean over-counts the \"same\" information. Mahalanobis adjusts for this.\n",
    "\n",
    "2. **Example**: Education and income are correlated. A person with high education and high income isn't \"twice as different\" - they're different on one underlying dimension.\n",
    "\n",
    "**When NOT to use**:\n",
    "1. **Small samples**: Covariance matrix estimation is unstable\n",
    "2. **High dimensions**: Covariance matrix may be singular\n",
    "3. **Binary features**: Correlation structure may not be meaningful\n",
    "\n",
    "**Practical note**: With propensity scores (Chapter 11), you match on a single scalar, avoiding the distance metric choice entirely.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Q3: How do you assess matching quality?**\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Key metric: Standardized Mean Difference (SMD)**\n",
    "\n",
    "$$SMD = \\frac{\\bar{X}_{treated} - \\bar{X}_{control}}{\\sqrt{(s^2_{treated} + s^2_{control})/2}}$$\n",
    "\n",
    "**Interpretation**:\n",
    "- SMD = 0: Perfect balance\n",
    "- |SMD| < 0.1: Good balance (common threshold)\n",
    "- |SMD| < 0.25: Acceptable balance\n",
    "- |SMD| > 0.25: Poor balance, reconsider matching\n",
    "\n",
    "**Other diagnostics**:\n",
    "1. **Visual inspection**: Plot covariate distributions before/after matching\n",
    "2. **Variance ratios**: Compare treated vs matched control variances (should be close to 1)\n",
    "3. **Love plots**: Show SMD for all covariates before and after matching\n",
    "\n",
    "**What to do if balance is poor**:\n",
    "- Try different distance metrics\n",
    "- Add more covariates\n",
    "- Use caliper matching (maximum allowed distance)\n",
    "- Consider propensity score methods\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[^1]: Facure, M. (2022). *Causal Inference for the Brave and True*, Chapter 10.\n",
    "\n",
    "[^2]: Rubin, D. B. (1980). Bias reduction using Mahalanobis-metric matching. *Biometrics*, 36(2), 293-298.\n",
    "\n",
    "[^3]: Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. *Statistical Science*, 25(1), 1-21.\n",
    "\n",
    "[^4]: Cross-reference: Propensity score as dimension reduction in `11_propensity_score/01_balancing_score.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
