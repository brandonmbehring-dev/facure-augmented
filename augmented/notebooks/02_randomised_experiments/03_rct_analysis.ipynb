{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 02.3 RCT Analysis: The Online Classroom Study\n",
    "\n",
    "**Chapter**: 2 - Randomised Experiments  \n",
    "**Section**: 3 - RCT Analysis  \n",
    "**Facure Source**: 02-Randomised-Experiments.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-09\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Facure's Intuition](#1-facures-intuition)\n",
    "   - 1.1 [The Online Learning Question](#11-the-online-learning-question)\n",
    "   - 1.2 [Balance Checks](#12-balance-checks)\n",
    "2. [Formal Treatment](#2-formal-treatment)\n",
    "   - 2.1 [Inference for ATE](#21-inference-for-ate)\n",
    "   - 2.2 [Hypothesis Testing](#22-hypothesis-testing)\n",
    "3. [Numeric Demonstration](#3-numeric-demonstration)\n",
    "   - 3.1 [Analyzing the Classroom Data](#31-analyzing-the-classroom-data)\n",
    "   - 3.2 [Statistical Significance](#32-statistical-significance)\n",
    "4. [Implementation](#4-implementation)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports via common module\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import (\n",
    "    np, pd, plt, sm,\n",
    "    load_facure_data,\n",
    "    set_notebook_style,\n",
    "    create_tufte_figure,\n",
    "    TUFTE_PALETTE,\n",
    ")\n",
    "from scipy import stats\n",
    "\n",
    "set_notebook_style()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition\n",
    "\n",
    "> **Interview Relevance**: Analyzing real RCT data is a common interview task. You should be able to estimate effects, check balance, and interpret results correctly.\n",
    "\n",
    "### 1.1 The Online Learning Question\n",
    "\n",
    "Facure's question: **Does online learning affect academic performance?**\n",
    "\n",
    "Context (2020 pandemic): Schools shifted to online learning. Is this good or bad for students?\n",
    "\n",
    "**The data**: Alpert, Couch, and Harmon (2016) randomized students into:\n",
    "1. Face-to-face instruction\n",
    "2. Online only\n",
    "3. Blended format\n",
    "\n",
    "Outcome: Standardized exam score at semester end.\n",
    "\n",
    "### 1.2 Balance Checks\n",
    "\n",
    "Before estimating effects, check that randomization worked:\n",
    "- Are covariates similar across treatment groups?\n",
    "- Large imbalances suggest problems (but can happen by chance)\n",
    "\n",
    "\u2605 Insight \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "- Balance checks are a sanity check, not a requirement\n",
    "- Small imbalances are expected (randomization noise)\n",
    "- Large imbalances suggest implementation problems\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment\n",
    "\n",
    "### 2.1 Inference for ATE\n",
    "\n",
    "**Point estimate** (difference in means):\n",
    "$$\\hat{\\tau} = \\bar{Y}_1 - \\bar{Y}_0$$\n",
    "\n",
    "**Standard error** (Neyman, 1923):\n",
    "$$\\widehat{SE}(\\hat{\\tau}) = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_0^2}{n_0}}$$\n",
    "\n",
    "where $s_t^2$ is the sample variance in group $t$.\n",
    "\n",
    "**Confidence interval** (asymptotic):\n",
    "$$\\hat{\\tau} \\pm z_{\\alpha/2} \\cdot \\widehat{SE}(\\hat{\\tau})$$\n",
    "\n",
    "For 95% CI, $z_{0.025} \\approx 1.96$.\n",
    "\n",
    "### 2.2 Hypothesis Testing\n",
    "\n",
    "**Null hypothesis**: $H_0: \\tau = 0$ (no treatment effect)\n",
    "\n",
    "**Test statistic**:\n",
    "$$t = \\frac{\\hat{\\tau} - 0}{\\widehat{SE}(\\hat{\\tau})}$$\n",
    "\n",
    "**Decision rule** (two-sided, $\\alpha = 0.05$):\n",
    "- Reject $H_0$ if $|t| > 1.96$\n",
    "- Or equivalently, if CI excludes 0\n",
    "\n",
    "**P-value**: Probability of observing $|t|$ this extreme under $H_0$.\n",
    "\n",
    "| Quantity | Formula | Interpretation |\n",
    "|----------|---------|----------------|\n",
    "| Point estimate | $\\bar{Y}_1 - \\bar{Y}_0$ | Best guess of ATE |\n",
    "| Standard error | $\\sqrt{s_1^2/n_1 + s_0^2/n_0}$ | Uncertainty in estimate |\n",
    "| 95% CI | $\\hat{\\tau} \\pm 1.96 \\cdot SE$ | Range of plausible values |\n",
    "| P-value | $2 \\cdot P(|Z| > |t|)$ | Evidence against null |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration\n",
    "\n",
    "### 3.1 Analyzing the Classroom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the online classroom data\n",
    "data = load_facure_data('online_classroom.csv')\n",
    "\n",
    "print(\"ONLINE CLASSROOM STUDY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Sample size: n = {len(data)}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create treatment variable\n",
    "data['class_format'] = np.select(\n",
    "    [data['format_ol'].astype(bool), data['format_blended'].astype(bool)],\n",
    "    ['online', 'blended'],\n",
    "    default='face_to_face'\n",
    ")\n",
    "\n",
    "# Summary by treatment group\n",
    "summary = data.groupby('class_format').agg({\n",
    "    'falsexam': ['mean', 'std', 'count'],\n",
    "    'gender': 'mean',  # Proportion female\n",
    "}).round(2)\n",
    "\n",
    "print(\"SUMMARY BY TREATMENT GROUP\")\n",
    "print(\"=\"*60)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance check: Are covariates similar across groups?\n",
    "covariates = ['gender', 'asian', 'black', 'hispanic', 'white']\n",
    "\n",
    "print(\"BALANCE CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Covariate':<15} {'Face-to-Face':>12} {'Online':>12} {'Blended':>12} {'SMD (Onl)':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for cov in covariates:\n",
    "    means = data.groupby('class_format')[cov].mean()\n",
    "    pooled_sd = data[cov].std()\n",
    "    smd = (means['online'] - means['face_to_face']) / pooled_sd if pooled_sd > 0 else 0\n",
    "    print(f\"{cov:<15} {means['face_to_face']:>12.3f} {means['online']:>12.3f} \"\n",
    "          f\"{means['blended']:>12.3f} {smd:>+10.3f}\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"SMD < 0.1 suggests good balance (rule of thumb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on online vs face-to-face comparison\n",
    "online = data.query('class_format == \"online\"')['falsexam']\n",
    "face_to_face = data.query('class_format == \"face_to_face\"')['falsexam']\n",
    "\n",
    "# Point estimate\n",
    "ate = online.mean() - face_to_face.mean()\n",
    "\n",
    "# Standard error (Neyman formula)\n",
    "se = np.sqrt(online.var() / len(online) + face_to_face.var() / len(face_to_face))\n",
    "\n",
    "# Confidence interval\n",
    "ci_low = ate - 1.96 * se\n",
    "ci_high = ate + 1.96 * se\n",
    "\n",
    "# T-statistic and p-value\n",
    "t_stat = ate / se\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
    "\n",
    "print(\"ATE ESTIMATION: Online vs Face-to-Face\")\n",
    "print(\"=\"*50)\n",
    "print(f\"E[Score | Online]      = {online.mean():.2f}\")\n",
    "print(f\"E[Score | Face-to-Face] = {face_to_face.mean():.2f}\")\n",
    "print(f\"\\nATE = {ate:.2f}\")\n",
    "print(f\"SE  = {se:.2f}\")\n",
    "print(f\"95% CI = [{ci_low:.2f}, {ci_high:.2f}]\")\n",
    "print(f\"\\nT-statistic = {t_stat:.2f}\")\n",
    "print(f\"P-value     = {p_value:.4f}\")\n",
    "print(f\"\\nStatistically significant at \u03b1=0.05? {p_value < 0.05}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 3.2 Statistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Panel 1: Distribution by group\n",
    "ax = axes[0]\n",
    "groups = ['face_to_face', 'online', 'blended']\n",
    "colors = [TUFTE_PALETTE['control'], TUFTE_PALETTE['treatment'], TUFTE_PALETTE['effect']]\n",
    "labels = ['Face-to-Face', 'Online', 'Blended']\n",
    "\n",
    "for group, color, label in zip(groups, colors, labels):\n",
    "    subset = data.query(f'class_format == \"{group}\"')['falsexam']\n",
    "    ax.hist(subset, bins=15, alpha=0.5, label=f'{label} (n={len(subset)})', \n",
    "            color=color, density=True)\n",
    "    ax.axvline(subset.mean(), color=color, linestyle='--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Exam Score')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('(a) Score Distribution by Format')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Panel 2: Effect estimates with CI\n",
    "ax = axes[1]\n",
    "\n",
    "# Calculate effects for each comparison\n",
    "comparisons = [\n",
    "    ('Online vs F2F', \n",
    "     data.query('class_format == \"online\"')['falsexam'],\n",
    "     data.query('class_format == \"face_to_face\"')['falsexam']),\n",
    "    ('Blended vs F2F', \n",
    "     data.query('class_format == \"blended\"')['falsexam'],\n",
    "     data.query('class_format == \"face_to_face\"')['falsexam']),\n",
    "]\n",
    "\n",
    "effects = []\n",
    "for name, treat, ctrl in comparisons:\n",
    "    effect = treat.mean() - ctrl.mean()\n",
    "    se_eff = np.sqrt(treat.var()/len(treat) + ctrl.var()/len(ctrl))\n",
    "    effects.append((name, effect, se_eff))\n",
    "\n",
    "y_pos = np.arange(len(effects))\n",
    "ax.barh(y_pos, [e[1] for e in effects], \n",
    "        xerr=[1.96 * e[2] for e in effects],\n",
    "        color=[TUFTE_PALETTE['treatment'], TUFTE_PALETTE['effect']],\n",
    "        alpha=0.8, capsize=5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels([e[0] for e in effects])\n",
    "ax.axvline(0, color=TUFTE_PALETTE['spine'], linestyle='-', linewidth=1)\n",
    "ax.set_xlabel('Effect on Exam Score')\n",
    "ax.set_title('(b) Treatment Effects (95% CI)')\n",
    "\n",
    "# Annotate\n",
    "for i, (name, effect, se_eff) in enumerate(effects):\n",
    "    ax.text(effect + 1.96*se_eff + 0.5, i, f'{effect:.1f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression-based inference (equivalent, but gives more diagnostics)\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Binary comparison: online vs face-to-face\n",
    "data_binary = data.query('class_format != \"blended\"').copy()\n",
    "data_binary['online'] = (data_binary['class_format'] == 'online').astype(int)\n",
    "\n",
    "model = smf.ols('falsexam ~ online', data=data_binary).fit()\n",
    "\n",
    "print(\"REGRESSION OUTPUT\")\n",
    "print(\"=\"*60)\n",
    "print(model.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify regression matches our manual calculation\n",
    "print(\"\\nVERIFICATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Manual ATE:       {ate:.4f}\")\n",
    "print(f\"Regression coef:  {model.params['online']:.4f}\")\n",
    "print(f\"Match: {np.isclose(ate, model.params['online'], rtol=1e-6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation\n",
    "\n",
    "Complete RCT analysis workflow:\n",
    "\n",
    "```python\n",
    "from causal_inference.rct import simple_ate, balance_check\n",
    "from causal_inference.diagnostics import covariate_balance_plot\n",
    "\n",
    "# Step 1: Balance check\n",
    "balance = balance_check(\n",
    "    covariates=data[['gender', 'asian', 'black', 'hispanic', 'white']],\n",
    "    treatment=data['online']\n",
    ")\n",
    "print(balance.summary())  # Check SMD < 0.1\n",
    "\n",
    "# Step 2: Estimate ATE\n",
    "result = simple_ate(\n",
    "    outcome=data['falsexam'],\n",
    "    treatment=data['online'],\n",
    "    confidence_level=0.95\n",
    ")\n",
    "\n",
    "print(f\"ATE: {result.ate:.2f}\")\n",
    "print(f\"SE:  {result.se:.2f}\")\n",
    "print(f\"CI:  [{result.ci_lower:.2f}, {result.ci_upper:.2f}]\")\n",
    "print(f\"P-value: {result.p_value:.4f}\")\n",
    "\n",
    "# Step 3: Visualize\n",
    "covariate_balance_plot(balance)\n",
    "result.plot_effect()  # Forest plot with CI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Interview Appendix\n",
    "\n",
    "### Practice Questions\n",
    "\n",
    "**Q1 (Airbnb Staff, DS)**: *\"You ran an A/B test and got a p-value of 0.03. What does this mean, and what would you conclude?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**What p-value = 0.03 means**:\n",
    "- If there were truly no effect (null hypothesis), we'd see a result this extreme only 3% of the time\n",
    "- It does NOT mean there's a 97% chance the effect is real\n",
    "\n",
    "**What I would conclude**:\n",
    "\n",
    "1. **Statistically significant at \u03b1 = 0.05**: p < 0.05, so we reject the null.\n",
    "\n",
    "2. **But consider practical significance**:\n",
    "   - How large is the effect?\n",
    "   - Is it meaningful for the business?\n",
    "\n",
    "3. **Check for multiple testing**:\n",
    "   - Did we run many tests?\n",
    "   - Need Bonferroni or similar correction\n",
    "\n",
    "4. **Look at confidence interval**:\n",
    "   - How wide is the CI?\n",
    "   - Does it include effects too small to care about?\n",
    "\n",
    "5. **Consider power**:\n",
    "   - Was the sample large enough?\n",
    "   - Underpowered tests often give unreliable estimates\n",
    "\n",
    "**Never conclude**: \"There's a 97% chance the treatment works.\" (Common misinterpretation)\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q2 (Meta E5, Applied Scientist)**: *\"How would you analyze an A/B test with three treatment arms?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Option 1: Pairwise comparisons**\n",
    "- Compare each treatment to control separately\n",
    "- Adjust for multiple comparisons (Bonferroni, Holm, etc.)\n",
    "- Simple but loses power\n",
    "\n",
    "**Option 2: Regression with dummies**\n",
    "```python\n",
    "Y ~ treatment_A + treatment_B  # control is baseline\n",
    "```\n",
    "- Coefficients give effect of each vs. control\n",
    "- F-test for joint significance\n",
    "- Standard errors account for common control group\n",
    "\n",
    "**Option 3: ANOVA**\n",
    "- Test if ANY treatment differs from control\n",
    "- Follow-up with pairwise tests if significant\n",
    "\n",
    "**Key considerations**:\n",
    "1. **Pre-specify comparisons**: Decide before analyzing which comparisons matter\n",
    "2. **Control for multiplicity**: More arms = more chance of false positives\n",
    "3. **Check balance for each arm**: Randomization should work separately\n",
    "4. **Report all comparisons**: Don't cherry-pick significant results\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q3 (DoorDash L6, Economist)**: *\"An A/B test shows the treatment group has significantly different pre-treatment characteristics. What would you do?\"*\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**First: Assess the severity**\n",
    "- How large is the imbalance? (SMD > 0.1 is concerning)\n",
    "- Is it on important predictors of the outcome?\n",
    "- Is it likely due to chance or implementation error?\n",
    "\n",
    "**If likely due to chance (small imbalance)**:\n",
    "- Continue with analysis\n",
    "- Use regression adjustment to increase precision\n",
    "- Report the imbalance transparently\n",
    "\n",
    "**If likely due to implementation error**:\n",
    "- Investigate the randomization procedure\n",
    "- Check for bugs in assignment code\n",
    "- Consider discarding the experiment\n",
    "\n",
    "**Adjustment options**:\n",
    "1. **Regression adjustment** (ANCOVA):\n",
    "   - Include imbalanced covariate as control\n",
    "   - Increases precision even in RCTs\n",
    "   \n",
    "2. **Stratified analysis**:\n",
    "   - Analyze within strata of the imbalanced variable\n",
    "   - Weight by stratum size\n",
    "\n",
    "3. **Re-randomization**:\n",
    "   - If caught early, can re-randomize\n",
    "   - Some designs re-randomize until balance achieved\n",
    "\n",
    "**What NOT to do**:\n",
    "- Don't just ignore the imbalance\n",
    "- Don't selectively report (if adjustment changes results)\n",
    "- Don't claim the experiment is invalid without investigating\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Alpert, W. T., Couch, K. A., and Harmon, O. R. (2016). A Randomized Assessment of Online Learning. *American Economic Review*, 106(5), 378-382.\n",
    "\n",
    "[^2]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 2: \"In a School Far, Far Away.\"\n",
    "\n",
    "[^3]: Imbens, G. W. and Rubin, D. B. (2015). *Causal Inference for Statistics, Social, and Biomedical Sciences*. Cambridge University Press, Chapter 6.\n",
    "\n",
    "[^4]: Lin, W. (2013). Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman's Critique. *Annals of Applied Statistics*, 7(1), 295-318.\n",
    "\n",
    "---\n",
    "\n",
    "**Precision Improvement:**\n",
    "- You said: \"Build the RCT analysis notebook\"\n",
    "- Concise: \"Build 02.3 RCT analysis\"\n",
    "- Precise: `/augmented 02.3 --online-classroom --inference`\n",
    "- Pattern: [build] [chapter.section] [content-flags]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "augmented": {
   "chapter_number": 2,
   "section_number": 3,
   "title": "RCT Analysis",
   "facure_source": "02-Randomised-Experiments.ipynb",
   "version": "1.0.0",
   "last_validated": "2026-01-29"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}