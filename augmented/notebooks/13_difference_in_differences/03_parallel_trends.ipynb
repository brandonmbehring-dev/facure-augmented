{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 13.3 Parallel Trends and Pre-Trend Testing\n",
    "\n",
    "**Chapter**: 13 - Difference-in-Differences  \n",
    "**Section**: 3 - Testing and Violations  \n",
    "**Facure Source**: 13-Difference-in-Differences.ipynb  \n",
    "**Version**: 1.0.0  \n",
    "**Last Validated**: 2026-01-09\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Facure's Intuition](#1-facures-intuition)\n",
    "   - 1.1 [Non-Parallel Trends Problem](#11-non-parallel-trends-problem)\n",
    "   - 1.2 [Pre-Trend Visualization](#12-pre-trend-visualization)\n",
    "2. [Formal Treatment](#2-formal-treatment)\n",
    "   - 2.1 [Pre-Trends Testing](#21-pre-trends-testing)\n",
    "   - 2.2 [Event Study Specification](#22-event-study-specification)\n",
    "   - 2.3 [Limitations of Pre-Trend Tests](#23-limitations-of-pre-trend-tests)\n",
    "3. [Numeric Demonstration](#3-numeric-demonstration)\n",
    "   - 3.1 [Simulating Non-Parallel Trends](#31-simulating-non-parallel-trends)\n",
    "   - 3.2 [Event Study Visualization](#32-event-study-visualization)\n",
    "4. [Implementation](#4-implementation)\n",
    "5. [Interview Appendix](#5-interview-appendix)\n",
    "6. [References](#6-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports via common module\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from augmented.common import (\n",
    "    np, pd, plt, sm, smf,\n",
    "    load_facure_data,\n",
    "    set_notebook_style,\n",
    "    ols_summary_table,\n",
    "    create_tufte_figure,\n",
    "    TUFTE_PALETTE,\n",
    ")\n",
    "\n",
    "set_notebook_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Facure's Intuition\n",
    "\n",
    "> **Interview Relevance**: Parallel trends is THE assumption in DiD. Interviewers will probe whether you understand (1) why it's untestable, (2) what pre-trend tests actually tell us, and (3) what to do when it fails.\n",
    "\n",
    "### 1.1 Non-Parallel Trends Problem\n",
    "\n",
    "Facure warns: **If the growth trend from the treated is different from the control, DiD will be biased.**\n",
    "\n",
    "Common causes of non-parallel trends:\n",
    "\n",
    "1. **Selection on growth**: Treatment targeted at fast/slow-growing units\n",
    "   - Example: Marketing campaign in underperforming region\n",
    "   \n",
    "2. **Anticipation effects**: Units change behavior before treatment\n",
    "   - Example: Firms adjust before policy announcement\n",
    "   \n",
    "3. **Divergent macro trends**: Different exposure to external shocks\n",
    "   - Example: Coastal vs. inland cities during shipping crisis\n",
    "\n",
    "### 1.2 Pre-Trend Visualization\n",
    "\n",
    "Facure's key diagnostic: **Plot outcomes over multiple pre-treatment periods.**\n",
    "\n",
    "If trends differ *before* treatment, they likely differ *after* too—biasing DiD.\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Pre-trend tests are **necessary but not sufficient**\n",
    "- Parallel pre-trends ≠ parallel counterfactual trends\n",
    "- Trends could diverge exactly at treatment time\n",
    "- Still, non-parallel pre-trends are a **strong red flag**\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Formal Treatment\n",
    "\n",
    "### 2.1 Pre-Trends Testing\n",
    "\n",
    "**The parallel trends assumption**:\n",
    "\n",
    "$$E[Y_0(t) - Y_0(t-1) | D=1] = E[Y_0(t) - Y_0(t-1) | D=0] \\quad \\forall t$$\n",
    "\n",
    "**Pre-trends test**: Check if trends were parallel *before* treatment.\n",
    "\n",
    "For periods $t < t^*$ (treatment time), test:\n",
    "\n",
    "$$H_0: E[Y(t) - Y(t-1) | D=1] = E[Y(t) - Y(t-1) | D=0]$$\n",
    "\n",
    "**Regression-based pre-trends test**:\n",
    "\n",
    "$$Y_{it} = \\alpha + \\gamma D_i + \\sum_{s < t^*} \\delta_s (D_i \\times \\mathbf{1}_{t=s}) + \\lambda_t + \\varepsilon_{it}$$\n",
    "\n",
    "Test: $H_0: \\delta_s = 0$ for all $s < t^*$\n",
    "\n",
    "### 2.2 Event Study Specification\n",
    "\n",
    "The **event study** extends DiD to multiple periods:\n",
    "\n",
    "$$Y_{it} = \\alpha_i + \\gamma_t + \\sum_{k \\neq -1} \\tau_k \\cdot \\mathbf{1}_{t - t^*_i = k} + \\varepsilon_{it}$$\n",
    "\n",
    "where:\n",
    "- $t^*_i$: Treatment time for unit $i$\n",
    "- $k$: Relative time (periods from treatment)\n",
    "- $\\tau_k$: Treatment effect at relative time $k$\n",
    "- $k = -1$ is omitted (normalization)\n",
    "\n",
    "**Interpretation**:\n",
    "- $\\tau_k$ for $k < 0$: Pre-treatment \"effects\" (should be ~0 if parallel trends holds)\n",
    "- $\\tau_k$ for $k \\geq 0$: Post-treatment effects (the causal effect)\n",
    "\n",
    "### 2.3 Limitations of Pre-Trend Tests\n",
    "\n",
    "**Why pre-trend tests are imperfect**:\n",
    "\n",
    "1. **Low power**: With few pre-periods or high variance, tests may fail to reject parallel trends even when violated\n",
    "\n",
    "2. **Untestable assumption**: The assumption is about $Y_0(\\text{post})$, not $Y_0(\\text{pre})$\n",
    "\n",
    "3. **Selection on levels vs. trends**: Pre-trends can be parallel while post-trends diverge due to:\n",
    "   - Anticipation effects\n",
    "   - Time-varying confounders\n",
    "   - Mean reversion\n",
    "\n",
    "4. **Pre-testing bias**: Conditioning on passing pre-trend tests can induce bias (Roth, 2022)\n",
    "\n",
    "**Proposition (Pre-Testing Bias)**: Researchers who only report DiD when pre-trends \"look good\" systematically overestimate or underestimate treatment effects.\n",
    "\n",
    "★ Insight ─────────────────────────────────────\n",
    "- Pre-trend tests have **asymmetric value**:\n",
    "  - Fail → Strong evidence against parallel trends\n",
    "  - Pass → Does NOT prove parallel trends\n",
    "- Report pre-trends tests regardless of result\n",
    "- Consider sensitivity analysis (Rambachan & Roth, 2023)\n",
    "─────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Numeric Demonstration\n",
    "\n",
    "### 3.1 Simulating Non-Parallel Trends\n",
    "\n",
    "Let's create synthetic data to show how non-parallel trends bias DiD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate panel data with non-parallel trends\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_units = 200  # Units per group\n",
    "n_periods = 6  # Time periods\n",
    "treatment_time = 4  # Treatment starts at period 4\n",
    "true_effect = 5.0  # True treatment effect\n",
    "\n",
    "# Create panel\n",
    "units = np.repeat(np.arange(n_units * 2), n_periods)\n",
    "periods = np.tile(np.arange(n_periods), n_units * 2)\n",
    "treated = (units >= n_units).astype(int)  # Second half is treated group\n",
    "\n",
    "# Generate outcomes with DIFFERENT trends\n",
    "# Control trend: 2 per period\n",
    "# Treatment trend: 4 per period (faster growth)\n",
    "control_trend = 2.0\n",
    "treatment_trend = 4.0  # Non-parallel!\n",
    "\n",
    "baseline = 100\n",
    "y0 = baseline + np.where(treated == 0, \n",
    "                          control_trend * periods,\n",
    "                          treatment_trend * periods)\n",
    "\n",
    "# Add treatment effect post-treatment\n",
    "post = (periods >= treatment_time).astype(int)\n",
    "treatment_indicator = treated * post\n",
    "y = y0 + true_effect * treatment_indicator + np.random.normal(0, 5, len(units))\n",
    "\n",
    "# Create DataFrame\n",
    "sim_data = pd.DataFrame({\n",
    "    'unit': units,\n",
    "    'period': periods,\n",
    "    'treated': treated,\n",
    "    'post': post,\n",
    "    'y': y\n",
    "})\n",
    "\n",
    "print(f\"Simulated data: {len(sim_data):,} observations\")\n",
    "print(f\"True treatment effect: {true_effect}\")\n",
    "print(f\"Control trend: {control_trend} per period\")\n",
    "print(f\"Treatment trend: {treatment_trend} per period (NON-PARALLEL)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate group means by period\n",
    "means = sim_data.groupby(['treated', 'period'])['y'].mean().unstack(level=0)\n",
    "means.columns = ['Control', 'Treated']\n",
    "\n",
    "print(\"Average Outcomes by Group and Period:\")\n",
    "print(means.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the non-parallel trends\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Panel 1: Raw trends showing violation\n",
    "ax = axes[0]\n",
    "ax.plot(means.index, means['Control'], 'o-', \n",
    "        color=TUFTE_PALETTE['control'], linewidth=2, markersize=8,\n",
    "        label='Control')\n",
    "ax.plot(means.index, means['Treated'], 's-', \n",
    "        color=TUFTE_PALETTE['treatment'], linewidth=2, markersize=8,\n",
    "        label='Treated')\n",
    "\n",
    "# Mark treatment time\n",
    "ax.axvline(treatment_time - 0.5, color='gray', linestyle='--', linewidth=1.5,\n",
    "           label='Treatment Start')\n",
    "\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Outcome')\n",
    "ax.set_title('(a) Non-Parallel Pre-Trends')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Panel 2: What parallel trends would look like\n",
    "ax = axes[1]\n",
    "\n",
    "# Simulate parallel trends data\n",
    "y0_parallel = baseline + control_trend * periods  # Same trend for both\n",
    "y_parallel = y0_parallel + true_effect * treatment_indicator + np.random.normal(0, 5, len(units))\n",
    "sim_parallel = sim_data.copy()\n",
    "sim_parallel['y'] = y_parallel\n",
    "means_parallel = sim_parallel.groupby(['treated', 'period'])['y'].mean().unstack(level=0)\n",
    "means_parallel.columns = ['Control', 'Treated']\n",
    "\n",
    "ax.plot(means_parallel.index, means_parallel['Control'], 'o-', \n",
    "        color=TUFTE_PALETTE['control'], linewidth=2, markersize=8,\n",
    "        label='Control')\n",
    "ax.plot(means_parallel.index, means_parallel['Treated'], 's-', \n",
    "        color=TUFTE_PALETTE['treatment'], linewidth=2, markersize=8,\n",
    "        label='Treated')\n",
    "ax.axvline(treatment_time - 0.5, color='gray', linestyle='--', linewidth=1.5,\n",
    "           label='Treatment Start')\n",
    "\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Outcome')\n",
    "ax.set_title('(b) Parallel Pre-Trends (Valid DiD)')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate DiD on both datasets\n",
    "print(\"DiD ESTIMATES: Parallel vs Non-Parallel\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Non-parallel (biased)\n",
    "model_nonparallel = smf.ols('y ~ treated * post', data=sim_data).fit()\n",
    "did_nonparallel = model_nonparallel.params['treated:post']\n",
    "\n",
    "print(f\"\\n1. NON-PARALLEL TRENDS (Biased):\")\n",
    "print(f\"   DiD estimate: {did_nonparallel:.4f}\")\n",
    "print(f\"   True effect:  {true_effect:.4f}\")\n",
    "print(f\"   Bias:         {did_nonparallel - true_effect:.4f}\")\n",
    "print(f\"   ⚠️ Bias = (treatment_trend - control_trend) × post_periods\")\n",
    "print(f\"        = ({treatment_trend} - {control_trend}) × 2 = {(treatment_trend - control_trend) * 2:.1f}\")\n",
    "\n",
    "# Parallel (unbiased)\n",
    "model_parallel = smf.ols('y ~ treated * post', data=sim_parallel).fit()\n",
    "did_parallel = model_parallel.params['treated:post']\n",
    "\n",
    "print(f\"\\n2. PARALLEL TRENDS (Unbiased):\")\n",
    "print(f\"   DiD estimate: {did_parallel:.4f}\")\n",
    "print(f\"   True effect:  {true_effect:.4f}\")\n",
    "print(f\"   Bias:         {did_parallel - true_effect:.4f}\")\n",
    "print(f\"   ✓ Estimate close to true effect\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 3.2 Event Study Visualization\n",
    "\n",
    "An event study plots treatment effects by relative time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# Create event study specification\n# Relative time: periods from treatment\nsim_data['rel_time'] = sim_data['period'] - treatment_time\nsim_parallel['rel_time'] = sim_parallel['period'] - treatment_time\n\n# Create dummies for each relative time (omit -1 as reference)\ndef run_event_study(df):\n    \"\"\"Run event study regression and return coefficients.\"\"\"\n    # Create interaction dummies\n    # Use 'm' prefix for negative periods to avoid Patsy parsing issues\n    rel_times = sorted(df['rel_time'].unique())\n\n    def make_var_name(rt):\n        \"\"\"Create Patsy-safe variable name.\"\"\"\n        if rt < 0:\n            return f'rt_m{abs(rt)}'  # rt_m4 instead of rt_-4\n        else:\n            return f'rt_p{rt}'  # rt_p0, rt_p1, etc.\n\n    for rt in rel_times:\n        var_name = make_var_name(rt)\n        df[var_name] = ((df['rel_time'] == rt) & (df['treated'] == 1)).astype(int)\n\n    # Regression (omit rt_m1 as reference, corresponding to rel_time=-1)\n    rt_vars = [make_var_name(rt) for rt in rel_times if rt != -1]\n    formula = 'y ~ treated + C(period) + ' + ' + '.join(rt_vars)\n    model = smf.ols(formula, data=df).fit()\n\n    # Extract coefficients\n    coefs = []\n    for rt in rel_times:\n        if rt == -1:\n            coefs.append({'rel_time': rt, 'coef': 0, 'se': 0})  # Reference\n        else:\n            var_name = make_var_name(rt)\n            coefs.append({\n                'rel_time': rt,\n                'coef': model.params[var_name],\n                'se': model.bse[var_name]\n            })\n\n    return pd.DataFrame(coefs)\n\nes_nonparallel = run_event_study(sim_data.copy())\nes_parallel = run_event_study(sim_parallel.copy())\n\nprint(\"Event Study Coefficients (Non-Parallel):\")\nprint(es_nonparallel.round(3))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot event studies\n",
    "fig, axes = create_tufte_figure(1, 2, figsize=(12, 5))\n",
    "\n",
    "def plot_event_study(ax, es_df, title):\n",
    "    \"\"\"Plot event study with confidence intervals.\"\"\"\n",
    "    ax.errorbar(es_df['rel_time'], es_df['coef'], \n",
    "                yerr=1.96 * es_df['se'],\n",
    "                fmt='o-', color=TUFTE_PALETTE['effect'], \n",
    "                capsize=4, capthick=1.5, linewidth=2, markersize=8)\n",
    "    \n",
    "    # Reference lines\n",
    "    ax.axhline(0, color=TUFTE_PALETTE['spine'], linestyle='-', linewidth=1)\n",
    "    ax.axvline(-0.5, color='gray', linestyle='--', linewidth=1.5,\n",
    "               label='Treatment Start')\n",
    "    \n",
    "    # True effect line (post-treatment)\n",
    "    ax.axhline(true_effect, color=TUFTE_PALETTE['treatment'], \n",
    "               linestyle=':', linewidth=1.5, alpha=0.7,\n",
    "               label=f'True Effect = {true_effect}')\n",
    "    \n",
    "    ax.set_xlabel('Periods from Treatment')\n",
    "    ax.set_ylabel('Treatment Effect (τ)')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(frameon=False, loc='upper left')\n",
    "    \n",
    "    # Shade pre/post regions\n",
    "    ax.axvspan(ax.get_xlim()[0], -0.5, alpha=0.1, color='blue', label='Pre')\n",
    "    ax.axvspan(-0.5, ax.get_xlim()[1], alpha=0.1, color='red', label='Post')\n",
    "\n",
    "plot_event_study(axes[0], es_nonparallel, '(a) Non-Parallel: Pre-Trends ≠ 0')\n",
    "plot_event_study(axes[1], es_parallel, '(b) Parallel: Pre-Trends ≈ 0')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# Formal pre-trends test\nprint(\"PRE-TRENDS TEST: Joint F-test\")\nprint(\"=\" * 60)\n\ndef pretrends_test(df):\n    \"\"\"Test if pre-treatment coefficients are jointly zero.\"\"\"\n    rel_times = sorted(df['rel_time'].unique())\n\n    def make_var_name(rt):\n        \"\"\"Create Patsy-safe variable name.\"\"\"\n        if rt < 0:\n            return f'rt_m{abs(rt)}'  # rt_m4 instead of rt_-4\n        else:\n            return f'rt_p{rt}'  # rt_p0, rt_p1, etc.\n\n    for rt in rel_times:\n        var_name = make_var_name(rt)\n        df[var_name] = ((df['rel_time'] == rt) & (df['treated'] == 1)).astype(int)\n\n    # Full model\n    rt_vars = [make_var_name(rt) for rt in rel_times if rt != -1]\n    formula = 'y ~ treated + C(period) + ' + ' + '.join(rt_vars)\n    model = smf.ols(formula, data=df).fit()\n\n    # F-test for pre-treatment coefficients\n    pre_vars = [make_var_name(rt) for rt in rel_times if rt < -1]\n    if len(pre_vars) > 0:\n        restrictions = ' = '.join(pre_vars) + ' = 0'\n        f_test = model.f_test(restrictions)\n        return f_test\n    return None\n\nf_nonparallel = pretrends_test(sim_data.copy())\nf_parallel = pretrends_test(sim_parallel.copy())\n\n# Extract F-value (may be scalar or array depending on statsmodels version)\ndef get_fvalue(f_test):\n    \"\"\"Extract F-value from f_test result.\"\"\"\n    fval = f_test.fvalue\n    if hasattr(fval, '__getitem__'):\n        try:\n            return float(fval[0][0])\n        except (IndexError, TypeError):\n            return float(fval)\n    return float(fval)\n\nprint(f\"\\nNon-Parallel Trends:\")\nprint(f\"  F-statistic: {get_fvalue(f_nonparallel):.2f}\")\nprint(f\"  p-value:     {f_nonparallel.pvalue:.4f}\")\nprint(f\"  Result:      {'⚠️ REJECT H₀ - Pre-trends differ!' if f_nonparallel.pvalue < 0.05 else '✓ Fail to reject'}\")\n\nprint(f\"\\nParallel Trends:\")\nprint(f\"  F-statistic: {get_fvalue(f_parallel):.2f}\")\nprint(f\"  p-value:     {f_parallel.pvalue:.4f}\")\nprint(f\"  Result:      {'⚠️ REJECT H₀ - Pre-trends differ!' if f_parallel.pvalue < 0.05 else '✓ Fail to reject'}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "**Key takeaways**:\n",
    "\n",
    "1. **Non-parallel case**: Pre-treatment coefficients are significantly different from zero → DiD is biased\n",
    "2. **Parallel case**: Pre-treatment coefficients are ~0 → DiD is valid\n",
    "3. **Event study** visualizes both the pre-trends test AND the dynamic treatment effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementation\n",
    "\n",
    "The `causal_inference_mastery` library provides event study infrastructure:\n",
    "\n",
    "```python\n",
    "from causal_inference.did import event_study, EventStudyResult\n",
    "\n",
    "# Run event study\n",
    "result = event_study(\n",
    "    data=panel_data,\n",
    "    outcome='y',\n",
    "    unit='unit_id',\n",
    "    time='period',\n",
    "    treatment='treated',\n",
    "    treatment_time='treatment_period',\n",
    "    ref_period=-1,  # Reference period\n",
    "    cluster='unit_id'\n",
    ")\n",
    "\n",
    "# Pre-trends test\n",
    "print(f\"Pre-trends F-stat: {result.pretrends_f:.2f}\")\n",
    "print(f\"Pre-trends p-value: {result.pretrends_pval:.4f}\")\n",
    "\n",
    "# Plot\n",
    "result.plot(title='Event Study', figsize=(10, 6))\n",
    "```\n",
    "\n",
    "For settings with staggered adoption, use:\n",
    "- `callaway_santanna()`: Group-time ATT estimation\n",
    "- `sun_abraham()`: Interaction-weighted estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "---\n\n## Additional Content: Sensitivity Analysis for Parallel Trends\n\n### Rambachan and Roth (2023) Sensitivity Analysis\n\n**The core problem**: Pre-trend tests have low power and don't validate the identifying assumption.\n\n**Rambachan-Roth approach**: Instead of testing parallel trends, ask:\n> \"How much could trends differ for my results to be meaningless?\"\n\n**Key concept**: Allow for violations of parallel trends bounded by:\n$$|\\delta_{\\text{post}} - \\delta_{\\text{pre}}| \\leq \\bar{M}$$\n\nwhere $\\bar{M}$ measures the maximum trend deviation.\n\n**Implementation**:\n1. Estimate the event study\n2. For each $\\bar{M} \\in [0, M_{\\text{max}}]$:\n   - Compute bounds on treatment effect allowing for trend violations up to $\\bar{M}$\n   - Report whether bounds include zero\n3. Find the **breakdown value**: smallest $\\bar{M}$ where CI includes zero\n\n### Interpreting Sensitivity Results\n\n**Breakdown value interpretation**:\n- High breakdown value → Robust (needs large violation to overturn)\n- Low breakdown value → Fragile (small violation overturns)\n\n**Example**: If breakdown value is $\\bar{M} = 0.5$ and pre-period trends differ by at most 0.2:\n- Violation would need to be 2.5× larger than observed pre-trends\n- Provides moderate evidence for causal interpretation\n\n**Reporting guidelines**:\n1. Always report pre-trends test (with power caveat)\n2. Report sensitivity analysis with breakdown value\n3. Benchmark $\\bar{M}$ against observed pre-period variation\n4. Acknowledge if results are sensitive\n\n### HonestDiD Implementation\n\n```r\n# R code for HonestDiD package\nlibrary(HonestDiD)\n\n# After estimating event study\nhonest_results <- createSensitivityResults(\n    betahat = event_study_coefs,\n    sigma = event_study_vcov,\n    numPrePeriods = 3,\n    numPostPeriods = 2,\n    Mbarvec = seq(0, 0.5, by = 0.05)\n)\n\n# Plot sensitivity\ncreateSensitivityPlot(honest_results)\n```\n\n★ Insight ─────────────────────────────────────\n- Pre-trend tests tell you IF assumption violated, not BY HOW MUCH\n- Sensitivity analysis asks: \"How robust is my conclusion?\"\n- Report breakdown value—it's more informative than p-values\n- Benchmark against pre-period variation for interpretability\n─────────────────────────────────────────────────\n\n---\n\n## 5. Interview Appendix\n\n### Practice Questions\n\n**Q1 (Meta E5, DS)**: *\"Your DiD analysis shows flat pre-trends but your colleague is still skeptical. What could still go wrong?\"*\n\n<details>\n<summary>Solution</summary>\n\n**Valid concerns even with flat pre-trends**:\n\n1. **Anticipation effects**:\n   - Units may change behavior before treatment\n   - Pre-trends look flat but treatment effect is contaminated\n   - Example: Firms adjust hiring before minimum wage increase\n\n2. **Compositional changes**:\n   - Sample composition changes at treatment time\n   - Selection into/out of sample correlated with treatment\n   \n3. **Treatment-correlated shocks**:\n   - A third factor causes both treatment and outcome change\n   - Parallel pre-trends doesn't rule out time-varying confounders\n   \n4. **Mean reversion**:\n   - Treatment targeted at units with temporarily high/low outcomes\n   - Pre-trends might be flat overall but treatment timing is endogenous\n   \n5. **Low power in pre-trends test**:\n   - Few pre-periods or high variance\n   - Failure to reject ≠ parallel trends hold\n\n**Responses**:\n- Add more pre-periods if available\n- Test for anticipation (lead effects)\n- Conduct placebo tests (fake treatment times)\n- Sensitivity analysis (Rambachan & Roth bounds)\n- Acknowledge limitation in write-up\n\n</details>\n\n---\n\n**Q2 (Google L5, Quant)**: *\"What is an event study? How does it relate to DiD?\"*\n\n<details>\n<summary>Solution</summary>\n\n**Event Study**:\n\nA regression specification that estimates treatment effects for each period relative to treatment time:\n\n$$Y_{it} = \\alpha_i + \\gamma_t + \\sum_{k \\neq -1} \\tau_k \\cdot D_{it}^k + \\varepsilon_{it}$$\n\nwhere $D_{it}^k = 1$ if unit $i$ is $k$ periods from treatment at time $t$.\n\n**Relationship to DiD**:\n\n1. **DiD is a special case**: Pool all post-periods into one coefficient\n   - Event study: $\\tau_{-2}, \\tau_{-1} = 0, \\tau_0, \\tau_1, \\tau_2$\n   - DiD: $\\tau_{\\text{post}} = $ average of $\\tau_0, \\tau_1, \\tau_2$\n\n2. **Event study is more informative**:\n   - Shows dynamic effects (does effect grow, fade?)\n   - Tests parallel trends visually (pre-treatment $\\tau_k \\approx 0$?)\n   - Detects anticipation effects ($\\tau_{-1}, \\tau_{-2} \\neq 0$?)\n\n3. **Interpretation**:\n   - Pre-treatment coefficients: Should be ~0 (parallel trends check)\n   - Post-treatment coefficients: Treatment effect dynamics\n   - Reference period ($k = -1$): Normalized to zero\n\n**Key point**: Event studies are DiD's diagnostic and presentation tool, not a different method.\n\n</details>\n\n---\n\n**Q3 (Amazon L6, Econ)**: *\"You have only 2 pre-treatment periods and the pre-trends test fails to reject. Should you proceed with DiD?\"*\n\n<details>\n<summary>Solution</summary>\n\n**Proceed with caution, acknowledge limitations**:\n\n1. **Low power concern**:\n   - 2 pre-periods = 1 testable pre-trend coefficient\n   - Very low power to detect violations\n   - \"Failure to reject\" is weak evidence FOR parallel trends\n\n2. **What to do**:\n   - Report the pre-trends test with caveat about power\n   - Calculate power: What violation could you detect?\n   - Seek additional pre-periods if possible\n   - Use sensitivity analysis (Rambachan & Roth bounds)\n   - Consider alternative methods (synthetic control)\n\n3. **Sensitivity analysis**:\n   - \"If trends could diverge by X, how would that affect my estimate?\"\n   - Report range of estimates under different trend assumptions\n   - Tools: `HonestDiD` package in R\n\n4. **When to NOT proceed**:\n   - Prior knowledge suggests trends differ\n   - Treatment assignment correlated with growth\n   - Stakeholders won't accept weak evidence\n\n**Key point**: Pre-trends tests with few periods have terrible power. Report honestly and use sensitivity analysis.\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. References\n",
    "\n",
    "[^1]: Facure, M. (2023). *Causal Inference for the Brave and True*. Chapter 13: \"Difference-in-Differences.\"\n",
    "\n",
    "[^2]: Roth, J. (2022). Pretest with Caution: Event-Study Estimates after Testing for Parallel Trends. *American Economic Review: Insights*, 4(3), 305-322.\n",
    "\n",
    "[^3]: Rambachan, A. and Roth, J. (2023). A More Credible Approach to Parallel Trends. *Review of Economic Studies*, 90(5), 2555-2591.\n",
    "\n",
    "[^4]: Freyaldenhoven, S., Hansen, C., and Shapiro, J. M. (2019). Pre-Event Trends in the Panel Event-Study Design. *American Economic Review*, 109(9), 3307-3338.\n",
    "\n",
    "[^5]: Angrist, J. D. and Pischke, J.-S. (2009). *Mostly Harmless Econometrics*. Princeton University Press, Chapter 5.\n",
    "\n",
    "---\n",
    "\n",
    "**Precision Improvement:**\n",
    "- You said: \"Build parallel trends notebook\"\n",
    "- Concise: \"Build 03_parallel_trends.ipynb\"\n",
    "- Precise: `/facure_augment 13.3 --event-study --pretrends-test --sensitivity`\n",
    "- Pattern: [build] [target] [content-flags]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}